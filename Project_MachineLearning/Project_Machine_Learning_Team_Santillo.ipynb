{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project - Machine Learning - Team Santillo",
      "provenance": [],
      "collapsed_sections": [
        "8r9yCWFp45MC",
        "-RPWXYgF4TjT",
        "J-9XrITp47G2",
        "KUDP8Mbg9nwg",
        "P4fgmqZnXrmi",
        "XKYWnvVQZ13z",
        "FprRFaF7bV9G",
        "BYoUQZ9Tj2s1",
        "OKdtYDUskeJL",
        "kxbpAcgjlAip",
        "diuvrIux8lHZ",
        "wD6HgdYcqXHx",
        "HnpF3MGLr2Xt",
        "pFxWp3Pr-JER",
        "sEJCYYUrT3-U",
        "Jn4bXiZL_Bv3",
        "IdZtq85klHFU",
        "BqYncKPCxFCd",
        "iDGWwUZOyvPI",
        "x9TjsE8RUG2E",
        "zYjJqr-RUG2M",
        "AqwT4J_PsZqD",
        "xOOl7dc8UrXF",
        "Z88e7g_f_yV2",
        "eSnp2VlKU0jr",
        "prPey0Nh2IIw",
        "pltsOd-BBQjM",
        "11Ai8RyqU9Hh",
        "sbE6cr_ZBXH7",
        "cfAIA9F9VAwq",
        "kAjiRNjFVAws",
        "FQGMgRqbBqMd",
        "1fyd7LslJr4o",
        "UR4iSSABM4-4",
        "YPUj09r9OHHT",
        "vgcB9HhVOJK5",
        "Rvxt-QI_7DlN",
        "QuIWP2vAzaXY"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbc9ed05c6e146fb8943dbd4de897cbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8d79ef30a34c4c1b9da64701b46baa05",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_79a719b7fc4f482a84ae421571913429",
              "IPY_MODEL_da2dc85624a34867ae98a072cb00c99f"
            ]
          }
        },
        "8d79ef30a34c4c1b9da64701b46baa05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "79a719b7fc4f482a84ae421571913429": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a6ae734fc35481d8f0e7244e9a8cee6",
            "_dom_classes": [],
            "description": "Optimization Progress: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 12,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93093641b42841bba062d4770440d839"
          }
        },
        "da2dc85624a34867ae98a072cb00c99f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8976a6e2a8a9425fa602dd018cd10dba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:06&lt;00:00,  1.39pipeline/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0de6b9d8e2246faaa9db00847589f34"
          }
        },
        "5a6ae734fc35481d8f0e7244e9a8cee6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93093641b42841bba062d4770440d839": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8976a6e2a8a9425fa602dd018cd10dba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0de6b9d8e2246faaa9db00847589f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0dcce498317b4309a86bca2484b9f366": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1256fb41e5574fa5a8912e55f39cc3b4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd8af728e358495885827d5f45b9e494",
              "IPY_MODEL_52f4766dcaa54e8c92c434d9b98c1dd8"
            ]
          }
        },
        "1256fb41e5574fa5a8912e55f39cc3b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd8af728e358495885827d5f45b9e494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f5b8a5fa313b46e39fa51654019c12d6",
            "_dom_classes": [],
            "description": "Optimization Progress: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 12,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 12,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e74bf8ecce247c0b7e8816ad07ee22d"
          }
        },
        "52f4766dcaa54e8c92c434d9b98c1dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_546744817c7247ec91c4d202155c6d29",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 12/12 [00:24&lt;00:00,  2.47s/pipeline]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1d91d24886843b4a7372132b6659b71"
          }
        },
        "f5b8a5fa313b46e39fa51654019c12d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e74bf8ecce247c0b7e8816ad07ee22d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "546744817c7247ec91c4d202155c6d29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1d91d24886843b4a7372132b6659b71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhMN7IUu3kS6"
      },
      "source": [
        "# Selecting the best performing classifier with forward selection and PCA \n",
        "by Abdallah Daaboul and Jordan Santillo "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yetZfFqh4C49"
      },
      "source": [
        "### Contents  \n",
        "\n",
        "**Part 1:** Load and prepare the dataset  \n",
        "**Part 2:** Binary Classification (class2)  \n",
        "1. Random forest \n",
        "2. SVM \n",
        "3. K nearest neighbor \n",
        "4. Logistic regression \n",
        "5. Naive Bayes\n",
        "6. Gradient boosting \n",
        "**Part 3:** Multiclass Classification (class4) with forward boosting and PCA  \n",
        "K best  \n",
        "PCA  \n",
        "Models  \n",
        "  \n",
        "**Part 4:** Predictions  \n",
        "**Part 5:** Overview and Summary "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8r9yCWFp45MC"
      },
      "source": [
        "## Part 1: Load and prepare the dataset "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RPWXYgF4TjT"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-CBKoZDR3bmc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn import decomposition\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "from matplotlib import pyplot as plt\n",
        "from prettytable import PrettyTable\n",
        "import math\n",
        "import statistics as stat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-9XrITp47G2"
      },
      "source": [
        "### Load the data from Github Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmrZSprV3c16"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/AbdallahDaaboul/Project_MachineLearning/main/npf_train.csv\"\n",
        "df_train = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWm6e80q7aCS"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/AbdallahDaaboul/Project_MachineLearning/main/npf_test_hidden.csv\"\n",
        "df_test = pd.read_csv(url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0RfSAy3x4N2h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "487a6995-d0c9-45d2-d6d3-331960e15571"
      },
      "source": [
        "df_train.head(3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>class4</th>\n",
              "      <th>partlybad</th>\n",
              "      <th>CO2168.mean</th>\n",
              "      <th>CO2168.std</th>\n",
              "      <th>CO2336.mean</th>\n",
              "      <th>CO2336.std</th>\n",
              "      <th>CO242.mean</th>\n",
              "      <th>CO242.std</th>\n",
              "      <th>CO2504.mean</th>\n",
              "      <th>CO2504.std</th>\n",
              "      <th>Glob.mean</th>\n",
              "      <th>Glob.std</th>\n",
              "      <th>H2O168.mean</th>\n",
              "      <th>H2O168.std</th>\n",
              "      <th>H2O336.mean</th>\n",
              "      <th>H2O336.std</th>\n",
              "      <th>H2O42.mean</th>\n",
              "      <th>H2O42.std</th>\n",
              "      <th>H2O504.mean</th>\n",
              "      <th>H2O504.std</th>\n",
              "      <th>H2O672.mean</th>\n",
              "      <th>H2O672.std</th>\n",
              "      <th>H2O84.mean</th>\n",
              "      <th>H2O84.std</th>\n",
              "      <th>NET.mean</th>\n",
              "      <th>NET.std</th>\n",
              "      <th>NO168.mean</th>\n",
              "      <th>NO168.std</th>\n",
              "      <th>NO336.mean</th>\n",
              "      <th>NO336.std</th>\n",
              "      <th>NO42.mean</th>\n",
              "      <th>NO42.std</th>\n",
              "      <th>NO504.mean</th>\n",
              "      <th>NO504.std</th>\n",
              "      <th>NO672.mean</th>\n",
              "      <th>NO672.std</th>\n",
              "      <th>NO84.mean</th>\n",
              "      <th>NO84.std</th>\n",
              "      <th>...</th>\n",
              "      <th>PAR.mean</th>\n",
              "      <th>PAR.std</th>\n",
              "      <th>PTG.mean</th>\n",
              "      <th>PTG.std</th>\n",
              "      <th>RGlob.mean</th>\n",
              "      <th>RGlob.std</th>\n",
              "      <th>RHIRGA168.mean</th>\n",
              "      <th>RHIRGA168.std</th>\n",
              "      <th>RHIRGA336.mean</th>\n",
              "      <th>RHIRGA336.std</th>\n",
              "      <th>RHIRGA42.mean</th>\n",
              "      <th>RHIRGA42.std</th>\n",
              "      <th>RHIRGA504.mean</th>\n",
              "      <th>RHIRGA504.std</th>\n",
              "      <th>RHIRGA672.mean</th>\n",
              "      <th>RHIRGA672.std</th>\n",
              "      <th>RHIRGA84.mean</th>\n",
              "      <th>RHIRGA84.std</th>\n",
              "      <th>RPAR.mean</th>\n",
              "      <th>RPAR.std</th>\n",
              "      <th>SO2168.mean</th>\n",
              "      <th>SO2168.std</th>\n",
              "      <th>SWS.mean</th>\n",
              "      <th>SWS.std</th>\n",
              "      <th>T168.mean</th>\n",
              "      <th>T168.std</th>\n",
              "      <th>T42.mean</th>\n",
              "      <th>T42.std</th>\n",
              "      <th>T504.mean</th>\n",
              "      <th>T504.std</th>\n",
              "      <th>T672.mean</th>\n",
              "      <th>T672.std</th>\n",
              "      <th>T84.mean</th>\n",
              "      <th>T84.std</th>\n",
              "      <th>UV_A.mean</th>\n",
              "      <th>UV_A.std</th>\n",
              "      <th>UV_B.mean</th>\n",
              "      <th>UV_B.std</th>\n",
              "      <th>CS.mean</th>\n",
              "      <th>CS.std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2000-02-23</td>\n",
              "      <td>nonevent</td>\n",
              "      <td>False</td>\n",
              "      <td>380.528120</td>\n",
              "      <td>0.802001</td>\n",
              "      <td>380.371466</td>\n",
              "      <td>0.889550</td>\n",
              "      <td>381.816207</td>\n",
              "      <td>1.292593</td>\n",
              "      <td>380.296466</td>\n",
              "      <td>0.968884</td>\n",
              "      <td>236.605353</td>\n",
              "      <td>145.160571</td>\n",
              "      <td>2.663504</td>\n",
              "      <td>0.319427</td>\n",
              "      <td>2.695603</td>\n",
              "      <td>0.304894</td>\n",
              "      <td>2.548879</td>\n",
              "      <td>0.382813</td>\n",
              "      <td>2.694138</td>\n",
              "      <td>0.306606</td>\n",
              "      <td>2.771071</td>\n",
              "      <td>0.366386</td>\n",
              "      <td>2.613362</td>\n",
              "      <td>0.348996</td>\n",
              "      <td>81.699876</td>\n",
              "      <td>109.164607</td>\n",
              "      <td>0.319316</td>\n",
              "      <td>0.179649</td>\n",
              "      <td>0.336724</td>\n",
              "      <td>0.183974</td>\n",
              "      <td>0.235517</td>\n",
              "      <td>0.157543</td>\n",
              "      <td>0.332500</td>\n",
              "      <td>0.183478</td>\n",
              "      <td>0.287241</td>\n",
              "      <td>0.172559</td>\n",
              "      <td>0.286638</td>\n",
              "      <td>0.160141</td>\n",
              "      <td>...</td>\n",
              "      <td>339.171515</td>\n",
              "      <td>211.125658</td>\n",
              "      <td>0.000964</td>\n",
              "      <td>0.007481</td>\n",
              "      <td>67.500843</td>\n",
              "      <td>30.529852</td>\n",
              "      <td>95.104103</td>\n",
              "      <td>1.612618</td>\n",
              "      <td>96.532586</td>\n",
              "      <td>2.382040</td>\n",
              "      <td>92.189052</td>\n",
              "      <td>1.781872</td>\n",
              "      <td>96.752672</td>\n",
              "      <td>2.326736</td>\n",
              "      <td>101.351071</td>\n",
              "      <td>4.571036</td>\n",
              "      <td>93.293534</td>\n",
              "      <td>1.981996</td>\n",
              "      <td>84.476919</td>\n",
              "      <td>49.764321</td>\n",
              "      <td>0.559316</td>\n",
              "      <td>0.374688</td>\n",
              "      <td>936.605263</td>\n",
              "      <td>0.916500</td>\n",
              "      <td>-10.272530</td>\n",
              "      <td>1.575415</td>\n",
              "      <td>-10.489828</td>\n",
              "      <td>2.085275</td>\n",
              "      <td>-10.346540</td>\n",
              "      <td>1.347401</td>\n",
              "      <td>-10.730843</td>\n",
              "      <td>1.381815</td>\n",
              "      <td>-10.282754</td>\n",
              "      <td>1.870056</td>\n",
              "      <td>8.356761</td>\n",
              "      <td>4.534937</td>\n",
              "      <td>0.178084</td>\n",
              "      <td>0.123402</td>\n",
              "      <td>0.002546</td>\n",
              "      <td>0.000686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2000-03-25</td>\n",
              "      <td>Ib</td>\n",
              "      <td>False</td>\n",
              "      <td>373.128684</td>\n",
              "      <td>1.096617</td>\n",
              "      <td>372.980000</td>\n",
              "      <td>1.047750</td>\n",
              "      <td>373.701830</td>\n",
              "      <td>1.259198</td>\n",
              "      <td>372.910000</td>\n",
              "      <td>1.004164</td>\n",
              "      <td>252.480327</td>\n",
              "      <td>138.921953</td>\n",
              "      <td>3.253684</td>\n",
              "      <td>0.299728</td>\n",
              "      <td>3.232222</td>\n",
              "      <td>0.308108</td>\n",
              "      <td>3.299150</td>\n",
              "      <td>0.290206</td>\n",
              "      <td>3.228039</td>\n",
              "      <td>0.310416</td>\n",
              "      <td>3.227712</td>\n",
              "      <td>0.307517</td>\n",
              "      <td>3.267582</td>\n",
              "      <td>0.298119</td>\n",
              "      <td>142.534162</td>\n",
              "      <td>115.885107</td>\n",
              "      <td>0.023618</td>\n",
              "      <td>0.040306</td>\n",
              "      <td>0.028105</td>\n",
              "      <td>0.042142</td>\n",
              "      <td>0.025294</td>\n",
              "      <td>0.045379</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.046759</td>\n",
              "      <td>0.030458</td>\n",
              "      <td>0.042894</td>\n",
              "      <td>0.025425</td>\n",
              "      <td>0.094298</td>\n",
              "      <td>...</td>\n",
              "      <td>487.596401</td>\n",
              "      <td>268.860550</td>\n",
              "      <td>-0.005340</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>41.090445</td>\n",
              "      <td>21.317089</td>\n",
              "      <td>59.672237</td>\n",
              "      <td>14.625643</td>\n",
              "      <td>60.119150</td>\n",
              "      <td>14.369137</td>\n",
              "      <td>59.535033</td>\n",
              "      <td>15.592649</td>\n",
              "      <td>60.910915</td>\n",
              "      <td>14.122225</td>\n",
              "      <td>62.475294</td>\n",
              "      <td>14.217269</td>\n",
              "      <td>59.184771</td>\n",
              "      <td>15.260717</td>\n",
              "      <td>32.421126</td>\n",
              "      <td>19.516104</td>\n",
              "      <td>0.138289</td>\n",
              "      <td>0.115293</td>\n",
              "      <td>923.450980</td>\n",
              "      <td>2.062171</td>\n",
              "      <td>-1.330589</td>\n",
              "      <td>1.947330</td>\n",
              "      <td>-1.037435</td>\n",
              "      <td>2.231552</td>\n",
              "      <td>-1.738455</td>\n",
              "      <td>1.748079</td>\n",
              "      <td>-2.095641</td>\n",
              "      <td>1.695622</td>\n",
              "      <td>-1.095864</td>\n",
              "      <td>2.090111</td>\n",
              "      <td>12.906779</td>\n",
              "      <td>7.022300</td>\n",
              "      <td>0.333523</td>\n",
              "      <td>0.239981</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>0.000210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2000-04-06</td>\n",
              "      <td>Ib</td>\n",
              "      <td>False</td>\n",
              "      <td>372.363293</td>\n",
              "      <td>0.626329</td>\n",
              "      <td>372.245689</td>\n",
              "      <td>0.615803</td>\n",
              "      <td>372.847246</td>\n",
              "      <td>0.647279</td>\n",
              "      <td>372.193952</td>\n",
              "      <td>0.596289</td>\n",
              "      <td>269.981547</td>\n",
              "      <td>200.826676</td>\n",
              "      <td>4.459042</td>\n",
              "      <td>0.367894</td>\n",
              "      <td>4.422874</td>\n",
              "      <td>0.365105</td>\n",
              "      <td>4.509760</td>\n",
              "      <td>0.360563</td>\n",
              "      <td>4.409401</td>\n",
              "      <td>0.359296</td>\n",
              "      <td>4.395988</td>\n",
              "      <td>0.357929</td>\n",
              "      <td>4.462515</td>\n",
              "      <td>0.362899</td>\n",
              "      <td>156.409709</td>\n",
              "      <td>173.191387</td>\n",
              "      <td>0.030898</td>\n",
              "      <td>0.047893</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.046062</td>\n",
              "      <td>0.028802</td>\n",
              "      <td>0.047107</td>\n",
              "      <td>0.024910</td>\n",
              "      <td>0.045468</td>\n",
              "      <td>0.029940</td>\n",
              "      <td>0.052406</td>\n",
              "      <td>0.028802</td>\n",
              "      <td>0.050870</td>\n",
              "      <td>...</td>\n",
              "      <td>515.622611</td>\n",
              "      <td>392.245819</td>\n",
              "      <td>-0.002910</td>\n",
              "      <td>0.006699</td>\n",
              "      <td>41.006814</td>\n",
              "      <td>29.483793</td>\n",
              "      <td>65.047844</td>\n",
              "      <td>13.978114</td>\n",
              "      <td>65.240539</td>\n",
              "      <td>14.181466</td>\n",
              "      <td>64.822395</td>\n",
              "      <td>13.827617</td>\n",
              "      <td>65.872216</td>\n",
              "      <td>14.174827</td>\n",
              "      <td>67.481018</td>\n",
              "      <td>14.652811</td>\n",
              "      <td>64.301856</td>\n",
              "      <td>13.820666</td>\n",
              "      <td>32.940216</td>\n",
              "      <td>25.385709</td>\n",
              "      <td>0.107066</td>\n",
              "      <td>0.122741</td>\n",
              "      <td>923.410714</td>\n",
              "      <td>2.647653</td>\n",
              "      <td>1.672108</td>\n",
              "      <td>1.942941</td>\n",
              "      <td>1.893257</td>\n",
              "      <td>1.960102</td>\n",
              "      <td>1.354012</td>\n",
              "      <td>1.910314</td>\n",
              "      <td>0.991521</td>\n",
              "      <td>1.914186</td>\n",
              "      <td>1.846503</td>\n",
              "      <td>1.954748</td>\n",
              "      <td>14.286261</td>\n",
              "      <td>9.572444</td>\n",
              "      <td>0.418313</td>\n",
              "      <td>0.344386</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.000072</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 104 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   id        date    class4  partlybad  ...  UV_B.mean  UV_B.std   CS.mean    CS.std\n",
              "0   1  2000-02-23  nonevent      False  ...   0.178084  0.123402  0.002546  0.000686\n",
              "1   2  2000-03-25        Ib      False  ...   0.333523  0.239981  0.000662  0.000210\n",
              "2   3  2000-04-06        Ib      False  ...   0.418313  0.344386  0.000541  0.000072\n",
              "\n",
              "[3 rows x 104 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeKwQMy54ohd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fddef53d-5d43-401a-9a00-6ec616937803"
      },
      "source": [
        "df_train.isna().sum()  #no missing values."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id             0\n",
              "date           0\n",
              "class4         0\n",
              "partlybad      0\n",
              "CO2168.mean    0\n",
              "              ..\n",
              "UV_A.std       0\n",
              "UV_B.mean      0\n",
              "UV_B.std       0\n",
              "CS.mean        0\n",
              "CS.std         0\n",
              "Length: 104, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvhwtkYW45GE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "794cd74a-e89f-4a4a-cf4a-9e83038555cd"
      },
      "source": [
        "df_train.shape #Get the shape of our data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(430, 104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBVdlaet5OAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7bd4fd-424d-4a8e-d715-1f8e66dec825"
      },
      "source": [
        "df_test.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>class4</th>\n",
              "      <th>partlybad</th>\n",
              "      <th>CO2168.mean</th>\n",
              "      <th>CO2168.std</th>\n",
              "      <th>CO2336.mean</th>\n",
              "      <th>CO2336.std</th>\n",
              "      <th>CO242.mean</th>\n",
              "      <th>CO242.std</th>\n",
              "      <th>CO2504.mean</th>\n",
              "      <th>CO2504.std</th>\n",
              "      <th>Glob.mean</th>\n",
              "      <th>Glob.std</th>\n",
              "      <th>H2O168.mean</th>\n",
              "      <th>H2O168.std</th>\n",
              "      <th>H2O336.mean</th>\n",
              "      <th>H2O336.std</th>\n",
              "      <th>H2O42.mean</th>\n",
              "      <th>H2O42.std</th>\n",
              "      <th>H2O504.mean</th>\n",
              "      <th>H2O504.std</th>\n",
              "      <th>H2O672.mean</th>\n",
              "      <th>H2O672.std</th>\n",
              "      <th>H2O84.mean</th>\n",
              "      <th>H2O84.std</th>\n",
              "      <th>NET.mean</th>\n",
              "      <th>NET.std</th>\n",
              "      <th>NO168.mean</th>\n",
              "      <th>NO168.std</th>\n",
              "      <th>NO336.mean</th>\n",
              "      <th>NO336.std</th>\n",
              "      <th>NO42.mean</th>\n",
              "      <th>NO42.std</th>\n",
              "      <th>NO504.mean</th>\n",
              "      <th>NO504.std</th>\n",
              "      <th>NO672.mean</th>\n",
              "      <th>NO672.std</th>\n",
              "      <th>NO84.mean</th>\n",
              "      <th>NO84.std</th>\n",
              "      <th>...</th>\n",
              "      <th>PAR.mean</th>\n",
              "      <th>PAR.std</th>\n",
              "      <th>PTG.mean</th>\n",
              "      <th>PTG.std</th>\n",
              "      <th>RGlob.mean</th>\n",
              "      <th>RGlob.std</th>\n",
              "      <th>RHIRGA168.mean</th>\n",
              "      <th>RHIRGA168.std</th>\n",
              "      <th>RHIRGA336.mean</th>\n",
              "      <th>RHIRGA336.std</th>\n",
              "      <th>RHIRGA42.mean</th>\n",
              "      <th>RHIRGA42.std</th>\n",
              "      <th>RHIRGA504.mean</th>\n",
              "      <th>RHIRGA504.std</th>\n",
              "      <th>RHIRGA672.mean</th>\n",
              "      <th>RHIRGA672.std</th>\n",
              "      <th>RHIRGA84.mean</th>\n",
              "      <th>RHIRGA84.std</th>\n",
              "      <th>RPAR.mean</th>\n",
              "      <th>RPAR.std</th>\n",
              "      <th>SO2168.mean</th>\n",
              "      <th>SO2168.std</th>\n",
              "      <th>SWS.mean</th>\n",
              "      <th>SWS.std</th>\n",
              "      <th>T168.mean</th>\n",
              "      <th>T168.std</th>\n",
              "      <th>T42.mean</th>\n",
              "      <th>T42.std</th>\n",
              "      <th>T504.mean</th>\n",
              "      <th>T504.std</th>\n",
              "      <th>T672.mean</th>\n",
              "      <th>T672.std</th>\n",
              "      <th>T84.mean</th>\n",
              "      <th>T84.std</th>\n",
              "      <th>UV_A.mean</th>\n",
              "      <th>UV_A.std</th>\n",
              "      <th>UV_B.mean</th>\n",
              "      <th>UV_B.std</th>\n",
              "      <th>CS.mean</th>\n",
              "      <th>CS.std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>431</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>377.448880</td>\n",
              "      <td>2.920241</td>\n",
              "      <td>377.632640</td>\n",
              "      <td>2.666835</td>\n",
              "      <td>377.908080</td>\n",
              "      <td>3.440430</td>\n",
              "      <td>377.708240</td>\n",
              "      <td>2.543418</td>\n",
              "      <td>210.851946</td>\n",
              "      <td>179.668211</td>\n",
              "      <td>13.516160</td>\n",
              "      <td>0.503071</td>\n",
              "      <td>13.448640</td>\n",
              "      <td>0.496249</td>\n",
              "      <td>13.674790</td>\n",
              "      <td>0.530696</td>\n",
              "      <td>13.394640</td>\n",
              "      <td>0.498479</td>\n",
              "      <td>13.363040</td>\n",
              "      <td>0.497949</td>\n",
              "      <td>13.594444</td>\n",
              "      <td>0.521267</td>\n",
              "      <td>150.196036</td>\n",
              "      <td>150.388580</td>\n",
              "      <td>0.027333</td>\n",
              "      <td>0.059314</td>\n",
              "      <td>0.025333</td>\n",
              "      <td>0.060505</td>\n",
              "      <td>0.013309</td>\n",
              "      <td>0.055271</td>\n",
              "      <td>0.026444</td>\n",
              "      <td>0.060477</td>\n",
              "      <td>0.031630</td>\n",
              "      <td>0.059778</td>\n",
              "      <td>0.012059</td>\n",
              "      <td>0.059952</td>\n",
              "      <td>...</td>\n",
              "      <td>462.288867</td>\n",
              "      <td>395.186100</td>\n",
              "      <td>-0.002204</td>\n",
              "      <td>0.004148</td>\n",
              "      <td>27.684027</td>\n",
              "      <td>24.408845</td>\n",
              "      <td>61.929200</td>\n",
              "      <td>8.972139</td>\n",
              "      <td>62.429200</td>\n",
              "      <td>9.055263</td>\n",
              "      <td>62.922101</td>\n",
              "      <td>9.302637</td>\n",
              "      <td>62.818960</td>\n",
              "      <td>9.081988</td>\n",
              "      <td>63.571440</td>\n",
              "      <td>9.160430</td>\n",
              "      <td>62.301746</td>\n",
              "      <td>9.121943</td>\n",
              "      <td>16.461909</td>\n",
              "      <td>14.679380</td>\n",
              "      <td>0.462741</td>\n",
              "      <td>0.196812</td>\n",
              "      <td>911.833333</td>\n",
              "      <td>24.361855</td>\n",
              "      <td>19.019520</td>\n",
              "      <td>2.306049</td>\n",
              "      <td>19.033461</td>\n",
              "      <td>2.316664</td>\n",
              "      <td>18.649187</td>\n",
              "      <td>2.278480</td>\n",
              "      <td>18.421232</td>\n",
              "      <td>2.267065</td>\n",
              "      <td>19.059027</td>\n",
              "      <td>2.320316</td>\n",
              "      <td>12.572064</td>\n",
              "      <td>9.623161</td>\n",
              "      <td>0.645959</td>\n",
              "      <td>0.558320</td>\n",
              "      <td>0.006159</td>\n",
              "      <td>0.000797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>369.589091</td>\n",
              "      <td>0.210402</td>\n",
              "      <td>369.632955</td>\n",
              "      <td>0.201409</td>\n",
              "      <td>369.904200</td>\n",
              "      <td>0.252167</td>\n",
              "      <td>369.601600</td>\n",
              "      <td>0.184727</td>\n",
              "      <td>25.017625</td>\n",
              "      <td>15.296680</td>\n",
              "      <td>4.339091</td>\n",
              "      <td>0.035360</td>\n",
              "      <td>4.307045</td>\n",
              "      <td>0.037203</td>\n",
              "      <td>4.376000</td>\n",
              "      <td>0.045535</td>\n",
              "      <td>4.299600</td>\n",
              "      <td>0.034639</td>\n",
              "      <td>4.290400</td>\n",
              "      <td>0.033317</td>\n",
              "      <td>4.334400</td>\n",
              "      <td>0.040816</td>\n",
              "      <td>2.613875</td>\n",
              "      <td>15.499577</td>\n",
              "      <td>0.003396</td>\n",
              "      <td>0.036052</td>\n",
              "      <td>0.016481</td>\n",
              "      <td>0.037121</td>\n",
              "      <td>0.012642</td>\n",
              "      <td>0.075706</td>\n",
              "      <td>0.008519</td>\n",
              "      <td>0.036879</td>\n",
              "      <td>0.018679</td>\n",
              "      <td>0.046162</td>\n",
              "      <td>0.006226</td>\n",
              "      <td>0.049077</td>\n",
              "      <td>...</td>\n",
              "      <td>46.884312</td>\n",
              "      <td>26.235043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.799594</td>\n",
              "      <td>3.225846</td>\n",
              "      <td>67.663636</td>\n",
              "      <td>1.291898</td>\n",
              "      <td>68.085682</td>\n",
              "      <td>1.441290</td>\n",
              "      <td>68.073200</td>\n",
              "      <td>1.258270</td>\n",
              "      <td>68.340600</td>\n",
              "      <td>1.344173</td>\n",
              "      <td>69.213400</td>\n",
              "      <td>1.354032</td>\n",
              "      <td>67.448000</td>\n",
              "      <td>1.359301</td>\n",
              "      <td>3.155625</td>\n",
              "      <td>2.131279</td>\n",
              "      <td>0.026038</td>\n",
              "      <td>0.061530</td>\n",
              "      <td>922.333333</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.462844</td>\n",
              "      <td>0.194671</td>\n",
              "      <td>0.480250</td>\n",
              "      <td>0.195631</td>\n",
              "      <td>0.178000</td>\n",
              "      <td>0.185177</td>\n",
              "      <td>-0.036312</td>\n",
              "      <td>0.180361</td>\n",
              "      <td>0.476219</td>\n",
              "      <td>0.192571</td>\n",
              "      <td>1.479447</td>\n",
              "      <td>0.640776</td>\n",
              "      <td>0.028665</td>\n",
              "      <td>0.013506</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.000031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>433</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>380.338929</td>\n",
              "      <td>0.928028</td>\n",
              "      <td>380.315833</td>\n",
              "      <td>0.917636</td>\n",
              "      <td>380.550119</td>\n",
              "      <td>0.936683</td>\n",
              "      <td>380.301446</td>\n",
              "      <td>0.916970</td>\n",
              "      <td>8.283964</td>\n",
              "      <td>5.107894</td>\n",
              "      <td>6.543333</td>\n",
              "      <td>0.191992</td>\n",
              "      <td>6.497143</td>\n",
              "      <td>0.197768</td>\n",
              "      <td>6.629167</td>\n",
              "      <td>0.184255</td>\n",
              "      <td>6.479639</td>\n",
              "      <td>0.198681</td>\n",
              "      <td>6.528193</td>\n",
              "      <td>0.204993</td>\n",
              "      <td>6.592143</td>\n",
              "      <td>0.181520</td>\n",
              "      <td>11.419841</td>\n",
              "      <td>4.875628</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.026155</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.027060</td>\n",
              "      <td>0.013810</td>\n",
              "      <td>0.027061</td>\n",
              "      <td>0.011084</td>\n",
              "      <td>0.027542</td>\n",
              "      <td>0.006988</td>\n",
              "      <td>0.023098</td>\n",
              "      <td>0.011429</td>\n",
              "      <td>0.026304</td>\n",
              "      <td>...</td>\n",
              "      <td>18.128247</td>\n",
              "      <td>11.574338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065139</td>\n",
              "      <td>0.646427</td>\n",
              "      <td>92.853214</td>\n",
              "      <td>0.804013</td>\n",
              "      <td>93.415238</td>\n",
              "      <td>0.760399</td>\n",
              "      <td>93.546786</td>\n",
              "      <td>0.760492</td>\n",
              "      <td>93.668072</td>\n",
              "      <td>0.758113</td>\n",
              "      <td>95.544337</td>\n",
              "      <td>1.356642</td>\n",
              "      <td>93.334524</td>\n",
              "      <td>0.738239</td>\n",
              "      <td>0.028685</td>\n",
              "      <td>0.212517</td>\n",
              "      <td>0.112143</td>\n",
              "      <td>0.100697</td>\n",
              "      <td>770.735294</td>\n",
              "      <td>142.420698</td>\n",
              "      <td>1.705657</td>\n",
              "      <td>0.363461</td>\n",
              "      <td>1.790637</td>\n",
              "      <td>0.364509</td>\n",
              "      <td>1.453287</td>\n",
              "      <td>0.372461</td>\n",
              "      <td>1.284980</td>\n",
              "      <td>0.379219</td>\n",
              "      <td>1.737849</td>\n",
              "      <td>0.365878</td>\n",
              "      <td>0.720849</td>\n",
              "      <td>0.427279</td>\n",
              "      <td>0.015179</td>\n",
              "      <td>0.010471</td>\n",
              "      <td>0.002334</td>\n",
              "      <td>0.000347</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 104 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  date  class4  partlybad  ...  UV_B.mean  UV_B.std   CS.mean    CS.std\n",
              "0  431   NaN     NaN      False  ...   0.645959  0.558320  0.006159  0.000797\n",
              "1  432   NaN     NaN      False  ...   0.028665  0.013506  0.000361  0.000031\n",
              "2  433   NaN     NaN      False  ...   0.015179  0.010471  0.002334  0.000347\n",
              "\n",
              "[3 rows x 104 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYa3Mhlm8DXW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8921d17-29ad-4e58-bac1-30e3c00cbf02"
      },
      "source": [
        "df_test.isna().sum()  #no values for date and class4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id               0\n",
              "date           965\n",
              "class4         965\n",
              "partlybad        0\n",
              "CO2168.mean      0\n",
              "              ... \n",
              "UV_A.std         0\n",
              "UV_B.mean        0\n",
              "UV_B.std         0\n",
              "CS.mean          0\n",
              "CS.std           0\n",
              "Length: 104, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_yIQ_eh8UAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c74da7da-e913-43cd-e859-90d9b23d285a"
      },
      "source": [
        "df_test.shape #Get the shape of our data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(965, 104)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUDP8Mbg9nwg"
      },
      "source": [
        "### Add class2 column\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2BgIPLq9sw6"
      },
      "source": [
        "df_train[\"class2\"] = df_train[\"class4\"].apply(lambda x: \"nonevent\" if x == \"nonevent\" else \"event\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkw6-f0W-M4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8eea878-6b91-453e-f0c1-727bc8ec72ce"
      },
      "source": [
        "df_train[[\"class2\",\"class4\"]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class2</th>\n",
              "      <th>class4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nonevent</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>event</td>\n",
              "      <td>Ib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>event</td>\n",
              "      <td>Ib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>nonevent</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>event</td>\n",
              "      <td>II</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>nonevent</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>nonevent</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>event</td>\n",
              "      <td>Ib</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>nonevent</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>nonevent</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>430 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       class2    class4\n",
              "0    nonevent  nonevent\n",
              "1       event        Ib\n",
              "2       event        Ib\n",
              "3    nonevent  nonevent\n",
              "4       event        II\n",
              "..        ...       ...\n",
              "425  nonevent  nonevent\n",
              "426  nonevent  nonevent\n",
              "427     event        Ib\n",
              "428  nonevent  nonevent\n",
              "429  nonevent  nonevent\n",
              "\n",
              "[430 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFvllS4dW6s7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7442d5b4-ecb7-4662-a49a-d32dc5254797"
      },
      "source": [
        "df_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>class4</th>\n",
              "      <th>partlybad</th>\n",
              "      <th>CO2168.mean</th>\n",
              "      <th>CO2168.std</th>\n",
              "      <th>CO2336.mean</th>\n",
              "      <th>CO2336.std</th>\n",
              "      <th>CO242.mean</th>\n",
              "      <th>CO242.std</th>\n",
              "      <th>CO2504.mean</th>\n",
              "      <th>CO2504.std</th>\n",
              "      <th>Glob.mean</th>\n",
              "      <th>Glob.std</th>\n",
              "      <th>H2O168.mean</th>\n",
              "      <th>H2O168.std</th>\n",
              "      <th>H2O336.mean</th>\n",
              "      <th>H2O336.std</th>\n",
              "      <th>H2O42.mean</th>\n",
              "      <th>H2O42.std</th>\n",
              "      <th>H2O504.mean</th>\n",
              "      <th>H2O504.std</th>\n",
              "      <th>H2O672.mean</th>\n",
              "      <th>H2O672.std</th>\n",
              "      <th>H2O84.mean</th>\n",
              "      <th>H2O84.std</th>\n",
              "      <th>NET.mean</th>\n",
              "      <th>NET.std</th>\n",
              "      <th>NO168.mean</th>\n",
              "      <th>NO168.std</th>\n",
              "      <th>NO336.mean</th>\n",
              "      <th>NO336.std</th>\n",
              "      <th>NO42.mean</th>\n",
              "      <th>NO42.std</th>\n",
              "      <th>NO504.mean</th>\n",
              "      <th>NO504.std</th>\n",
              "      <th>NO672.mean</th>\n",
              "      <th>NO672.std</th>\n",
              "      <th>NO84.mean</th>\n",
              "      <th>NO84.std</th>\n",
              "      <th>...</th>\n",
              "      <th>PAR.std</th>\n",
              "      <th>PTG.mean</th>\n",
              "      <th>PTG.std</th>\n",
              "      <th>RGlob.mean</th>\n",
              "      <th>RGlob.std</th>\n",
              "      <th>RHIRGA168.mean</th>\n",
              "      <th>RHIRGA168.std</th>\n",
              "      <th>RHIRGA336.mean</th>\n",
              "      <th>RHIRGA336.std</th>\n",
              "      <th>RHIRGA42.mean</th>\n",
              "      <th>RHIRGA42.std</th>\n",
              "      <th>RHIRGA504.mean</th>\n",
              "      <th>RHIRGA504.std</th>\n",
              "      <th>RHIRGA672.mean</th>\n",
              "      <th>RHIRGA672.std</th>\n",
              "      <th>RHIRGA84.mean</th>\n",
              "      <th>RHIRGA84.std</th>\n",
              "      <th>RPAR.mean</th>\n",
              "      <th>RPAR.std</th>\n",
              "      <th>SO2168.mean</th>\n",
              "      <th>SO2168.std</th>\n",
              "      <th>SWS.mean</th>\n",
              "      <th>SWS.std</th>\n",
              "      <th>T168.mean</th>\n",
              "      <th>T168.std</th>\n",
              "      <th>T42.mean</th>\n",
              "      <th>T42.std</th>\n",
              "      <th>T504.mean</th>\n",
              "      <th>T504.std</th>\n",
              "      <th>T672.mean</th>\n",
              "      <th>T672.std</th>\n",
              "      <th>T84.mean</th>\n",
              "      <th>T84.std</th>\n",
              "      <th>UV_A.mean</th>\n",
              "      <th>UV_A.std</th>\n",
              "      <th>UV_B.mean</th>\n",
              "      <th>UV_B.std</th>\n",
              "      <th>CS.mean</th>\n",
              "      <th>CS.std</th>\n",
              "      <th>class2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2000-02-23</td>\n",
              "      <td>nonevent</td>\n",
              "      <td>False</td>\n",
              "      <td>380.528120</td>\n",
              "      <td>0.802001</td>\n",
              "      <td>380.371466</td>\n",
              "      <td>0.889550</td>\n",
              "      <td>381.816207</td>\n",
              "      <td>1.292593</td>\n",
              "      <td>380.296466</td>\n",
              "      <td>0.968884</td>\n",
              "      <td>236.605353</td>\n",
              "      <td>145.160571</td>\n",
              "      <td>2.663504</td>\n",
              "      <td>0.319427</td>\n",
              "      <td>2.695603</td>\n",
              "      <td>0.304894</td>\n",
              "      <td>2.548879</td>\n",
              "      <td>0.382813</td>\n",
              "      <td>2.694138</td>\n",
              "      <td>0.306606</td>\n",
              "      <td>2.771071</td>\n",
              "      <td>0.366386</td>\n",
              "      <td>2.613362</td>\n",
              "      <td>0.348996</td>\n",
              "      <td>81.699876</td>\n",
              "      <td>109.164607</td>\n",
              "      <td>0.319316</td>\n",
              "      <td>0.179649</td>\n",
              "      <td>0.336724</td>\n",
              "      <td>0.183974</td>\n",
              "      <td>0.235517</td>\n",
              "      <td>0.157543</td>\n",
              "      <td>0.332500</td>\n",
              "      <td>0.183478</td>\n",
              "      <td>0.287241</td>\n",
              "      <td>0.172559</td>\n",
              "      <td>0.286638</td>\n",
              "      <td>0.160141</td>\n",
              "      <td>...</td>\n",
              "      <td>211.125658</td>\n",
              "      <td>0.000964</td>\n",
              "      <td>0.007481</td>\n",
              "      <td>67.500843</td>\n",
              "      <td>30.529852</td>\n",
              "      <td>95.104103</td>\n",
              "      <td>1.612618</td>\n",
              "      <td>96.532586</td>\n",
              "      <td>2.382040</td>\n",
              "      <td>92.189052</td>\n",
              "      <td>1.781872</td>\n",
              "      <td>96.752672</td>\n",
              "      <td>2.326736</td>\n",
              "      <td>101.351071</td>\n",
              "      <td>4.571036</td>\n",
              "      <td>93.293534</td>\n",
              "      <td>1.981996</td>\n",
              "      <td>84.476919</td>\n",
              "      <td>49.764321</td>\n",
              "      <td>0.559316</td>\n",
              "      <td>0.374688</td>\n",
              "      <td>936.605263</td>\n",
              "      <td>0.916500</td>\n",
              "      <td>-10.272530</td>\n",
              "      <td>1.575415</td>\n",
              "      <td>-10.489828</td>\n",
              "      <td>2.085275</td>\n",
              "      <td>-10.346540</td>\n",
              "      <td>1.347401</td>\n",
              "      <td>-10.730843</td>\n",
              "      <td>1.381815</td>\n",
              "      <td>-10.282754</td>\n",
              "      <td>1.870056</td>\n",
              "      <td>8.356761</td>\n",
              "      <td>4.534937</td>\n",
              "      <td>0.178084</td>\n",
              "      <td>0.123402</td>\n",
              "      <td>0.002546</td>\n",
              "      <td>0.000686</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2000-03-25</td>\n",
              "      <td>Ib</td>\n",
              "      <td>False</td>\n",
              "      <td>373.128684</td>\n",
              "      <td>1.096617</td>\n",
              "      <td>372.980000</td>\n",
              "      <td>1.047750</td>\n",
              "      <td>373.701830</td>\n",
              "      <td>1.259198</td>\n",
              "      <td>372.910000</td>\n",
              "      <td>1.004164</td>\n",
              "      <td>252.480327</td>\n",
              "      <td>138.921953</td>\n",
              "      <td>3.253684</td>\n",
              "      <td>0.299728</td>\n",
              "      <td>3.232222</td>\n",
              "      <td>0.308108</td>\n",
              "      <td>3.299150</td>\n",
              "      <td>0.290206</td>\n",
              "      <td>3.228039</td>\n",
              "      <td>0.310416</td>\n",
              "      <td>3.227712</td>\n",
              "      <td>0.307517</td>\n",
              "      <td>3.267582</td>\n",
              "      <td>0.298119</td>\n",
              "      <td>142.534162</td>\n",
              "      <td>115.885107</td>\n",
              "      <td>0.023618</td>\n",
              "      <td>0.040306</td>\n",
              "      <td>0.028105</td>\n",
              "      <td>0.042142</td>\n",
              "      <td>0.025294</td>\n",
              "      <td>0.045379</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.046759</td>\n",
              "      <td>0.030458</td>\n",
              "      <td>0.042894</td>\n",
              "      <td>0.025425</td>\n",
              "      <td>0.094298</td>\n",
              "      <td>...</td>\n",
              "      <td>268.860550</td>\n",
              "      <td>-0.005340</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>41.090445</td>\n",
              "      <td>21.317089</td>\n",
              "      <td>59.672237</td>\n",
              "      <td>14.625643</td>\n",
              "      <td>60.119150</td>\n",
              "      <td>14.369137</td>\n",
              "      <td>59.535033</td>\n",
              "      <td>15.592649</td>\n",
              "      <td>60.910915</td>\n",
              "      <td>14.122225</td>\n",
              "      <td>62.475294</td>\n",
              "      <td>14.217269</td>\n",
              "      <td>59.184771</td>\n",
              "      <td>15.260717</td>\n",
              "      <td>32.421126</td>\n",
              "      <td>19.516104</td>\n",
              "      <td>0.138289</td>\n",
              "      <td>0.115293</td>\n",
              "      <td>923.450980</td>\n",
              "      <td>2.062171</td>\n",
              "      <td>-1.330589</td>\n",
              "      <td>1.947330</td>\n",
              "      <td>-1.037435</td>\n",
              "      <td>2.231552</td>\n",
              "      <td>-1.738455</td>\n",
              "      <td>1.748079</td>\n",
              "      <td>-2.095641</td>\n",
              "      <td>1.695622</td>\n",
              "      <td>-1.095864</td>\n",
              "      <td>2.090111</td>\n",
              "      <td>12.906779</td>\n",
              "      <td>7.022300</td>\n",
              "      <td>0.333523</td>\n",
              "      <td>0.239981</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>0.000210</td>\n",
              "      <td>event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2000-04-06</td>\n",
              "      <td>Ib</td>\n",
              "      <td>False</td>\n",
              "      <td>372.363293</td>\n",
              "      <td>0.626329</td>\n",
              "      <td>372.245689</td>\n",
              "      <td>0.615803</td>\n",
              "      <td>372.847246</td>\n",
              "      <td>0.647279</td>\n",
              "      <td>372.193952</td>\n",
              "      <td>0.596289</td>\n",
              "      <td>269.981547</td>\n",
              "      <td>200.826676</td>\n",
              "      <td>4.459042</td>\n",
              "      <td>0.367894</td>\n",
              "      <td>4.422874</td>\n",
              "      <td>0.365105</td>\n",
              "      <td>4.509760</td>\n",
              "      <td>0.360563</td>\n",
              "      <td>4.409401</td>\n",
              "      <td>0.359296</td>\n",
              "      <td>4.395988</td>\n",
              "      <td>0.357929</td>\n",
              "      <td>4.462515</td>\n",
              "      <td>0.362899</td>\n",
              "      <td>156.409709</td>\n",
              "      <td>173.191387</td>\n",
              "      <td>0.030898</td>\n",
              "      <td>0.047893</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.046062</td>\n",
              "      <td>0.028802</td>\n",
              "      <td>0.047107</td>\n",
              "      <td>0.024910</td>\n",
              "      <td>0.045468</td>\n",
              "      <td>0.029940</td>\n",
              "      <td>0.052406</td>\n",
              "      <td>0.028802</td>\n",
              "      <td>0.050870</td>\n",
              "      <td>...</td>\n",
              "      <td>392.245819</td>\n",
              "      <td>-0.002910</td>\n",
              "      <td>0.006699</td>\n",
              "      <td>41.006814</td>\n",
              "      <td>29.483793</td>\n",
              "      <td>65.047844</td>\n",
              "      <td>13.978114</td>\n",
              "      <td>65.240539</td>\n",
              "      <td>14.181466</td>\n",
              "      <td>64.822395</td>\n",
              "      <td>13.827617</td>\n",
              "      <td>65.872216</td>\n",
              "      <td>14.174827</td>\n",
              "      <td>67.481018</td>\n",
              "      <td>14.652811</td>\n",
              "      <td>64.301856</td>\n",
              "      <td>13.820666</td>\n",
              "      <td>32.940216</td>\n",
              "      <td>25.385709</td>\n",
              "      <td>0.107066</td>\n",
              "      <td>0.122741</td>\n",
              "      <td>923.410714</td>\n",
              "      <td>2.647653</td>\n",
              "      <td>1.672108</td>\n",
              "      <td>1.942941</td>\n",
              "      <td>1.893257</td>\n",
              "      <td>1.960102</td>\n",
              "      <td>1.354012</td>\n",
              "      <td>1.910314</td>\n",
              "      <td>0.991521</td>\n",
              "      <td>1.914186</td>\n",
              "      <td>1.846503</td>\n",
              "      <td>1.954748</td>\n",
              "      <td>14.286261</td>\n",
              "      <td>9.572444</td>\n",
              "      <td>0.418313</td>\n",
              "      <td>0.344386</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2000-04-11</td>\n",
              "      <td>nonevent</td>\n",
              "      <td>False</td>\n",
              "      <td>381.437442</td>\n",
              "      <td>7.281159</td>\n",
              "      <td>381.380405</td>\n",
              "      <td>7.236002</td>\n",
              "      <td>381.926532</td>\n",
              "      <td>7.294374</td>\n",
              "      <td>381.381156</td>\n",
              "      <td>7.208287</td>\n",
              "      <td>68.364653</td>\n",
              "      <td>48.560722</td>\n",
              "      <td>6.613430</td>\n",
              "      <td>0.508011</td>\n",
              "      <td>6.568035</td>\n",
              "      <td>0.498439</td>\n",
              "      <td>6.627225</td>\n",
              "      <td>0.517847</td>\n",
              "      <td>6.579017</td>\n",
              "      <td>0.469558</td>\n",
              "      <td>6.566474</td>\n",
              "      <td>0.454360</td>\n",
              "      <td>6.620694</td>\n",
              "      <td>0.527051</td>\n",
              "      <td>53.752882</td>\n",
              "      <td>44.480753</td>\n",
              "      <td>0.717442</td>\n",
              "      <td>1.046600</td>\n",
              "      <td>0.763642</td>\n",
              "      <td>1.119467</td>\n",
              "      <td>0.601387</td>\n",
              "      <td>0.923043</td>\n",
              "      <td>0.800925</td>\n",
              "      <td>1.168399</td>\n",
              "      <td>0.822428</td>\n",
              "      <td>1.205617</td>\n",
              "      <td>0.663006</td>\n",
              "      <td>0.987611</td>\n",
              "      <td>...</td>\n",
              "      <td>103.352511</td>\n",
              "      <td>-0.000718</td>\n",
              "      <td>0.004928</td>\n",
              "      <td>10.616065</td>\n",
              "      <td>6.538927</td>\n",
              "      <td>90.906221</td>\n",
              "      <td>8.723910</td>\n",
              "      <td>91.022775</td>\n",
              "      <td>8.508574</td>\n",
              "      <td>89.268844</td>\n",
              "      <td>8.521074</td>\n",
              "      <td>91.875780</td>\n",
              "      <td>8.113524</td>\n",
              "      <td>93.993988</td>\n",
              "      <td>7.917405</td>\n",
              "      <td>89.774162</td>\n",
              "      <td>8.896734</td>\n",
              "      <td>11.890787</td>\n",
              "      <td>7.737403</td>\n",
              "      <td>0.323605</td>\n",
              "      <td>0.226767</td>\n",
              "      <td>918.862069</td>\n",
              "      <td>17.331088</td>\n",
              "      <td>2.321829</td>\n",
              "      <td>0.374436</td>\n",
              "      <td>2.610683</td>\n",
              "      <td>0.392255</td>\n",
              "      <td>2.105324</td>\n",
              "      <td>0.338427</td>\n",
              "      <td>1.753414</td>\n",
              "      <td>0.340565</td>\n",
              "      <td>2.524931</td>\n",
              "      <td>0.414255</td>\n",
              "      <td>4.945162</td>\n",
              "      <td>3.405652</td>\n",
              "      <td>0.224159</td>\n",
              "      <td>0.192014</td>\n",
              "      <td>0.003710</td>\n",
              "      <td>0.001209</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>2000-04-23</td>\n",
              "      <td>II</td>\n",
              "      <td>False</td>\n",
              "      <td>375.426310</td>\n",
              "      <td>3.264246</td>\n",
              "      <td>375.436524</td>\n",
              "      <td>3.110886</td>\n",
              "      <td>375.740215</td>\n",
              "      <td>3.274924</td>\n",
              "      <td>375.337059</td>\n",
              "      <td>2.903780</td>\n",
              "      <td>242.192619</td>\n",
              "      <td>190.952026</td>\n",
              "      <td>7.934171</td>\n",
              "      <td>0.326185</td>\n",
              "      <td>7.882727</td>\n",
              "      <td>0.302425</td>\n",
              "      <td>8.106183</td>\n",
              "      <td>0.368029</td>\n",
              "      <td>7.859840</td>\n",
              "      <td>0.299242</td>\n",
              "      <td>7.843690</td>\n",
              "      <td>0.295740</td>\n",
              "      <td>7.997957</td>\n",
              "      <td>0.350785</td>\n",
              "      <td>160.373121</td>\n",
              "      <td>149.664508</td>\n",
              "      <td>0.068877</td>\n",
              "      <td>0.114949</td>\n",
              "      <td>0.066043</td>\n",
              "      <td>0.117777</td>\n",
              "      <td>0.044011</td>\n",
              "      <td>0.082263</td>\n",
              "      <td>0.070856</td>\n",
              "      <td>0.114935</td>\n",
              "      <td>0.060695</td>\n",
              "      <td>0.102049</td>\n",
              "      <td>0.055615</td>\n",
              "      <td>0.104491</td>\n",
              "      <td>...</td>\n",
              "      <td>372.252005</td>\n",
              "      <td>0.005027</td>\n",
              "      <td>0.022413</td>\n",
              "      <td>28.190856</td>\n",
              "      <td>22.321519</td>\n",
              "      <td>60.907326</td>\n",
              "      <td>13.539642</td>\n",
              "      <td>60.474385</td>\n",
              "      <td>12.681657</td>\n",
              "      <td>61.444785</td>\n",
              "      <td>14.618152</td>\n",
              "      <td>60.320374</td>\n",
              "      <td>11.790057</td>\n",
              "      <td>60.756257</td>\n",
              "      <td>10.476841</td>\n",
              "      <td>60.506720</td>\n",
              "      <td>13.973508</td>\n",
              "      <td>17.840791</td>\n",
              "      <td>14.732266</td>\n",
              "      <td>0.366150</td>\n",
              "      <td>0.324216</td>\n",
              "      <td>919.629032</td>\n",
              "      <td>40.316874</td>\n",
              "      <td>11.210545</td>\n",
              "      <td>2.933483</td>\n",
              "      <td>11.415176</td>\n",
              "      <td>3.199418</td>\n",
              "      <td>11.139711</td>\n",
              "      <td>2.455458</td>\n",
              "      <td>10.940107</td>\n",
              "      <td>2.179821</td>\n",
              "      <td>11.441893</td>\n",
              "      <td>3.048699</td>\n",
              "      <td>13.087014</td>\n",
              "      <td>9.771415</td>\n",
              "      <td>0.525591</td>\n",
              "      <td>0.476821</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.002160</td>\n",
              "      <td>event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>426</td>\n",
              "      <td>2004-01-31</td>\n",
              "      <td>nonevent</td>\n",
              "      <td>False</td>\n",
              "      <td>389.310533</td>\n",
              "      <td>1.384881</td>\n",
              "      <td>389.320933</td>\n",
              "      <td>1.372439</td>\n",
              "      <td>389.411333</td>\n",
              "      <td>1.372157</td>\n",
              "      <td>389.308133</td>\n",
              "      <td>1.363886</td>\n",
              "      <td>11.828822</td>\n",
              "      <td>7.455036</td>\n",
              "      <td>3.564667</td>\n",
              "      <td>0.176408</td>\n",
              "      <td>3.565600</td>\n",
              "      <td>0.181214</td>\n",
              "      <td>3.580667</td>\n",
              "      <td>0.192026</td>\n",
              "      <td>3.584533</td>\n",
              "      <td>0.214629</td>\n",
              "      <td>3.555600</td>\n",
              "      <td>0.224826</td>\n",
              "      <td>3.569067</td>\n",
              "      <td>0.186476</td>\n",
              "      <td>10.906111</td>\n",
              "      <td>10.265953</td>\n",
              "      <td>0.016933</td>\n",
              "      <td>0.031493</td>\n",
              "      <td>0.019600</td>\n",
              "      <td>0.031212</td>\n",
              "      <td>0.012933</td>\n",
              "      <td>0.025510</td>\n",
              "      <td>0.018267</td>\n",
              "      <td>0.039331</td>\n",
              "      <td>0.021067</td>\n",
              "      <td>0.028024</td>\n",
              "      <td>0.021333</td>\n",
              "      <td>0.029744</td>\n",
              "      <td>...</td>\n",
              "      <td>16.863619</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.888244</td>\n",
              "      <td>2.621408</td>\n",
              "      <td>96.931200</td>\n",
              "      <td>0.787028</td>\n",
              "      <td>98.564267</td>\n",
              "      <td>0.535608</td>\n",
              "      <td>96.242133</td>\n",
              "      <td>0.610986</td>\n",
              "      <td>99.120400</td>\n",
              "      <td>0.696321</td>\n",
              "      <td>99.693600</td>\n",
              "      <td>0.874254</td>\n",
              "      <td>96.522000</td>\n",
              "      <td>0.684887</td>\n",
              "      <td>6.332711</td>\n",
              "      <td>4.558416</td>\n",
              "      <td>2.072133</td>\n",
              "      <td>0.297895</td>\n",
              "      <td>919.233333</td>\n",
              "      <td>3.979979</td>\n",
              "      <td>-7.070356</td>\n",
              "      <td>0.672087</td>\n",
              "      <td>-6.937178</td>\n",
              "      <td>0.673440</td>\n",
              "      <td>-7.318444</td>\n",
              "      <td>0.664420</td>\n",
              "      <td>-7.496622</td>\n",
              "      <td>0.669413</td>\n",
              "      <td>-7.008933</td>\n",
              "      <td>0.691314</td>\n",
              "      <td>1.021069</td>\n",
              "      <td>0.591618</td>\n",
              "      <td>0.018869</td>\n",
              "      <td>0.011991</td>\n",
              "      <td>0.006578</td>\n",
              "      <td>0.001036</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>427</td>\n",
              "      <td>2008-08-20</td>\n",
              "      <td>nonevent</td>\n",
              "      <td>False</td>\n",
              "      <td>380.048926</td>\n",
              "      <td>6.127866</td>\n",
              "      <td>380.105533</td>\n",
              "      <td>5.658127</td>\n",
              "      <td>381.673758</td>\n",
              "      <td>6.835401</td>\n",
              "      <td>379.888400</td>\n",
              "      <td>5.485305</td>\n",
              "      <td>108.429644</td>\n",
              "      <td>105.019275</td>\n",
              "      <td>14.532819</td>\n",
              "      <td>0.896484</td>\n",
              "      <td>14.401400</td>\n",
              "      <td>0.801472</td>\n",
              "      <td>14.754122</td>\n",
              "      <td>1.046930</td>\n",
              "      <td>14.328067</td>\n",
              "      <td>0.785613</td>\n",
              "      <td>14.248467</td>\n",
              "      <td>0.767428</td>\n",
              "      <td>14.699122</td>\n",
              "      <td>1.025178</td>\n",
              "      <td>80.665563</td>\n",
              "      <td>98.303398</td>\n",
              "      <td>0.044805</td>\n",
              "      <td>0.068887</td>\n",
              "      <td>0.046710</td>\n",
              "      <td>0.074373</td>\n",
              "      <td>0.057922</td>\n",
              "      <td>0.070067</td>\n",
              "      <td>0.049032</td>\n",
              "      <td>0.079510</td>\n",
              "      <td>0.051290</td>\n",
              "      <td>0.066885</td>\n",
              "      <td>0.033117</td>\n",
              "      <td>0.072161</td>\n",
              "      <td>...</td>\n",
              "      <td>217.986894</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.006354</td>\n",
              "      <td>12.544272</td>\n",
              "      <td>11.507249</td>\n",
              "      <td>82.448792</td>\n",
              "      <td>5.015215</td>\n",
              "      <td>82.909200</td>\n",
              "      <td>4.968426</td>\n",
              "      <td>82.968243</td>\n",
              "      <td>4.935353</td>\n",
              "      <td>83.148467</td>\n",
              "      <td>4.826225</td>\n",
              "      <td>83.687467</td>\n",
              "      <td>4.766537</td>\n",
              "      <td>82.733851</td>\n",
              "      <td>5.186590</td>\n",
              "      <td>6.092470</td>\n",
              "      <td>6.071200</td>\n",
              "      <td>0.046039</td>\n",
              "      <td>0.068499</td>\n",
              "      <td>886.806452</td>\n",
              "      <td>95.579482</td>\n",
              "      <td>15.323398</td>\n",
              "      <td>1.460131</td>\n",
              "      <td>15.469342</td>\n",
              "      <td>1.476389</td>\n",
              "      <td>14.987379</td>\n",
              "      <td>1.413248</td>\n",
              "      <td>14.797012</td>\n",
              "      <td>1.392316</td>\n",
              "      <td>15.460086</td>\n",
              "      <td>1.495813</td>\n",
              "      <td>7.786232</td>\n",
              "      <td>6.612248</td>\n",
              "      <td>0.380976</td>\n",
              "      <td>0.368811</td>\n",
              "      <td>0.004581</td>\n",
              "      <td>0.000499</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>428</td>\n",
              "      <td>2009-04-22</td>\n",
              "      <td>Ib</td>\n",
              "      <td>False</td>\n",
              "      <td>392.901308</td>\n",
              "      <td>2.236589</td>\n",
              "      <td>392.738372</td>\n",
              "      <td>2.830582</td>\n",
              "      <td>393.167054</td>\n",
              "      <td>2.196588</td>\n",
              "      <td>392.839690</td>\n",
              "      <td>2.071452</td>\n",
              "      <td>297.594773</td>\n",
              "      <td>221.092740</td>\n",
              "      <td>3.581154</td>\n",
              "      <td>0.293127</td>\n",
              "      <td>3.561860</td>\n",
              "      <td>0.282524</td>\n",
              "      <td>3.616504</td>\n",
              "      <td>0.277875</td>\n",
              "      <td>3.562791</td>\n",
              "      <td>0.282082</td>\n",
              "      <td>3.557385</td>\n",
              "      <td>0.265294</td>\n",
              "      <td>3.588077</td>\n",
              "      <td>0.284899</td>\n",
              "      <td>202.029804</td>\n",
              "      <td>195.138133</td>\n",
              "      <td>0.112387</td>\n",
              "      <td>0.133193</td>\n",
              "      <td>0.124967</td>\n",
              "      <td>0.137827</td>\n",
              "      <td>0.067355</td>\n",
              "      <td>0.091949</td>\n",
              "      <td>0.116364</td>\n",
              "      <td>0.135954</td>\n",
              "      <td>0.107806</td>\n",
              "      <td>0.119747</td>\n",
              "      <td>0.085484</td>\n",
              "      <td>0.111064</td>\n",
              "      <td>...</td>\n",
              "      <td>439.884042</td>\n",
              "      <td>-0.004153</td>\n",
              "      <td>0.011023</td>\n",
              "      <td>34.941933</td>\n",
              "      <td>25.175854</td>\n",
              "      <td>43.097000</td>\n",
              "      <td>12.711806</td>\n",
              "      <td>43.801016</td>\n",
              "      <td>12.658951</td>\n",
              "      <td>42.269756</td>\n",
              "      <td>12.461383</td>\n",
              "      <td>43.981473</td>\n",
              "      <td>12.649683</td>\n",
              "      <td>44.579692</td>\n",
              "      <td>12.559669</td>\n",
              "      <td>42.498231</td>\n",
              "      <td>12.745170</td>\n",
              "      <td>23.924192</td>\n",
              "      <td>17.639455</td>\n",
              "      <td>0.366194</td>\n",
              "      <td>0.204146</td>\n",
              "      <td>920.532258</td>\n",
              "      <td>1.339412</td>\n",
              "      <td>4.375232</td>\n",
              "      <td>3.792356</td>\n",
              "      <td>4.608015</td>\n",
              "      <td>3.865457</td>\n",
              "      <td>3.910895</td>\n",
              "      <td>3.663162</td>\n",
              "      <td>3.663074</td>\n",
              "      <td>3.578209</td>\n",
              "      <td>4.659234</td>\n",
              "      <td>3.888751</td>\n",
              "      <td>16.759945</td>\n",
              "      <td>11.549429</td>\n",
              "      <td>0.731519</td>\n",
              "      <td>0.616226</td>\n",
              "      <td>0.002233</td>\n",
              "      <td>0.000316</td>\n",
              "      <td>event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>429</td>\n",
              "      <td>2006-12-12</td>\n",
              "      <td>nonevent</td>\n",
              "      <td>False</td>\n",
              "      <td>387.960192</td>\n",
              "      <td>0.409426</td>\n",
              "      <td>388.007500</td>\n",
              "      <td>0.417034</td>\n",
              "      <td>388.179412</td>\n",
              "      <td>0.463350</td>\n",
              "      <td>387.972308</td>\n",
              "      <td>0.322141</td>\n",
              "      <td>10.355311</td>\n",
              "      <td>6.557353</td>\n",
              "      <td>6.281731</td>\n",
              "      <td>0.128272</td>\n",
              "      <td>6.254808</td>\n",
              "      <td>0.122178</td>\n",
              "      <td>6.394510</td>\n",
              "      <td>0.158345</td>\n",
              "      <td>6.232115</td>\n",
              "      <td>0.122544</td>\n",
              "      <td>6.212692</td>\n",
              "      <td>0.108051</td>\n",
              "      <td>6.320980</td>\n",
              "      <td>0.125956</td>\n",
              "      <td>-3.641491</td>\n",
              "      <td>11.360723</td>\n",
              "      <td>0.189074</td>\n",
              "      <td>0.367933</td>\n",
              "      <td>0.223889</td>\n",
              "      <td>0.396120</td>\n",
              "      <td>0.251132</td>\n",
              "      <td>0.521878</td>\n",
              "      <td>0.096226</td>\n",
              "      <td>0.164273</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.061460</td>\n",
              "      <td>0.137547</td>\n",
              "      <td>0.223984</td>\n",
              "      <td>...</td>\n",
              "      <td>14.410629</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.288634</td>\n",
              "      <td>0.922698</td>\n",
              "      <td>79.133269</td>\n",
              "      <td>1.048734</td>\n",
              "      <td>79.767115</td>\n",
              "      <td>1.209087</td>\n",
              "      <td>80.626275</td>\n",
              "      <td>1.129525</td>\n",
              "      <td>79.944423</td>\n",
              "      <td>1.249513</td>\n",
              "      <td>80.828077</td>\n",
              "      <td>1.413270</td>\n",
              "      <td>79.624510</td>\n",
              "      <td>1.042705</td>\n",
              "      <td>0.097826</td>\n",
              "      <td>0.402653</td>\n",
              "      <td>0.002593</td>\n",
              "      <td>0.050252</td>\n",
              "      <td>922.190476</td>\n",
              "      <td>0.749603</td>\n",
              "      <td>3.362174</td>\n",
              "      <td>0.356684</td>\n",
              "      <td>3.348292</td>\n",
              "      <td>0.330918</td>\n",
              "      <td>3.099441</td>\n",
              "      <td>0.379461</td>\n",
              "      <td>2.895652</td>\n",
              "      <td>0.386139</td>\n",
              "      <td>3.355248</td>\n",
              "      <td>0.342563</td>\n",
              "      <td>1.173183</td>\n",
              "      <td>0.678359</td>\n",
              "      <td>0.019306</td>\n",
              "      <td>0.012448</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>430</td>\n",
              "      <td>2009-11-19</td>\n",
              "      <td>nonevent</td>\n",
              "      <td>False</td>\n",
              "      <td>401.640476</td>\n",
              "      <td>2.052212</td>\n",
              "      <td>400.852097</td>\n",
              "      <td>2.884182</td>\n",
              "      <td>402.276032</td>\n",
              "      <td>2.138372</td>\n",
              "      <td>399.988095</td>\n",
              "      <td>3.766850</td>\n",
              "      <td>23.973636</td>\n",
              "      <td>15.873459</td>\n",
              "      <td>7.282063</td>\n",
              "      <td>0.124475</td>\n",
              "      <td>7.255968</td>\n",
              "      <td>0.109056</td>\n",
              "      <td>7.276667</td>\n",
              "      <td>0.186175</td>\n",
              "      <td>7.234286</td>\n",
              "      <td>0.089798</td>\n",
              "      <td>7.264444</td>\n",
              "      <td>0.080217</td>\n",
              "      <td>7.280952</td>\n",
              "      <td>0.156584</td>\n",
              "      <td>25.789554</td>\n",
              "      <td>20.438398</td>\n",
              "      <td>0.075882</td>\n",
              "      <td>0.098817</td>\n",
              "      <td>0.077612</td>\n",
              "      <td>0.120140</td>\n",
              "      <td>0.055882</td>\n",
              "      <td>0.071367</td>\n",
              "      <td>0.076324</td>\n",
              "      <td>0.095977</td>\n",
              "      <td>0.079706</td>\n",
              "      <td>0.107578</td>\n",
              "      <td>0.056029</td>\n",
              "      <td>0.075846</td>\n",
              "      <td>...</td>\n",
              "      <td>32.389768</td>\n",
              "      <td>0.007641</td>\n",
              "      <td>0.009717</td>\n",
              "      <td>4.949853</td>\n",
              "      <td>2.818664</td>\n",
              "      <td>93.052698</td>\n",
              "      <td>0.459285</td>\n",
              "      <td>93.185323</td>\n",
              "      <td>1.067821</td>\n",
              "      <td>92.862540</td>\n",
              "      <td>0.672007</td>\n",
              "      <td>92.602381</td>\n",
              "      <td>1.663037</td>\n",
              "      <td>93.300952</td>\n",
              "      <td>2.637512</td>\n",
              "      <td>92.714762</td>\n",
              "      <td>0.494714</td>\n",
              "      <td>4.368133</td>\n",
              "      <td>3.959107</td>\n",
              "      <td>0.043235</td>\n",
              "      <td>0.083227</td>\n",
              "      <td>907.428571</td>\n",
              "      <td>0.503953</td>\n",
              "      <td>3.229828</td>\n",
              "      <td>0.263632</td>\n",
              "      <td>3.259558</td>\n",
              "      <td>0.399445</td>\n",
              "      <td>3.190246</td>\n",
              "      <td>0.131051</td>\n",
              "      <td>3.131204</td>\n",
              "      <td>0.248498</td>\n",
              "      <td>3.287346</td>\n",
              "      <td>0.327367</td>\n",
              "      <td>1.978373</td>\n",
              "      <td>1.107727</td>\n",
              "      <td>0.050131</td>\n",
              "      <td>0.030889</td>\n",
              "      <td>0.002569</td>\n",
              "      <td>0.005078</td>\n",
              "      <td>nonevent</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>430 rows Ã— 105 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      id        date    class4  ...   CS.mean    CS.std    class2\n",
              "0      1  2000-02-23  nonevent  ...  0.002546  0.000686  nonevent\n",
              "1      2  2000-03-25        Ib  ...  0.000662  0.000210     event\n",
              "2      3  2000-04-06        Ib  ...  0.000541  0.000072     event\n",
              "3      4  2000-04-11  nonevent  ...  0.003710  0.001209  nonevent\n",
              "4      5  2000-04-23        II  ...  0.003680  0.002160     event\n",
              "..   ...         ...       ...  ...       ...       ...       ...\n",
              "425  426  2004-01-31  nonevent  ...  0.006578  0.001036  nonevent\n",
              "426  427  2008-08-20  nonevent  ...  0.004581  0.000499  nonevent\n",
              "427  428  2009-04-22        Ib  ...  0.002233  0.000316     event\n",
              "428  429  2006-12-12  nonevent  ...  0.000809  0.000029  nonevent\n",
              "429  430  2009-11-19  nonevent  ...  0.002569  0.005078  nonevent\n",
              "\n",
              "[430 rows x 105 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4fgmqZnXrmi"
      },
      "source": [
        "### Check for correlation \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwsStyMjWsQE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "bdbcb913-d971-40cd-c042-cc4db5778bef"
      },
      "source": [
        "# calculate the correlation matrix \n",
        "corr = df_train.corr()\n",
        "# display the correlation matrix\n",
        "display(corr) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>partlybad</th>\n",
              "      <th>CO2168.mean</th>\n",
              "      <th>CO2168.std</th>\n",
              "      <th>CO2336.mean</th>\n",
              "      <th>CO2336.std</th>\n",
              "      <th>CO242.mean</th>\n",
              "      <th>CO242.std</th>\n",
              "      <th>CO2504.mean</th>\n",
              "      <th>CO2504.std</th>\n",
              "      <th>Glob.mean</th>\n",
              "      <th>Glob.std</th>\n",
              "      <th>H2O168.mean</th>\n",
              "      <th>H2O168.std</th>\n",
              "      <th>H2O336.mean</th>\n",
              "      <th>H2O336.std</th>\n",
              "      <th>H2O42.mean</th>\n",
              "      <th>H2O42.std</th>\n",
              "      <th>H2O504.mean</th>\n",
              "      <th>H2O504.std</th>\n",
              "      <th>H2O672.mean</th>\n",
              "      <th>H2O672.std</th>\n",
              "      <th>H2O84.mean</th>\n",
              "      <th>H2O84.std</th>\n",
              "      <th>NET.mean</th>\n",
              "      <th>NET.std</th>\n",
              "      <th>NO168.mean</th>\n",
              "      <th>NO168.std</th>\n",
              "      <th>NO336.mean</th>\n",
              "      <th>NO336.std</th>\n",
              "      <th>NO42.mean</th>\n",
              "      <th>NO42.std</th>\n",
              "      <th>NO504.mean</th>\n",
              "      <th>NO504.std</th>\n",
              "      <th>NO672.mean</th>\n",
              "      <th>NO672.std</th>\n",
              "      <th>NO84.mean</th>\n",
              "      <th>NO84.std</th>\n",
              "      <th>NOx168.mean</th>\n",
              "      <th>NOx168.std</th>\n",
              "      <th>...</th>\n",
              "      <th>PAR.mean</th>\n",
              "      <th>PAR.std</th>\n",
              "      <th>PTG.mean</th>\n",
              "      <th>PTG.std</th>\n",
              "      <th>RGlob.mean</th>\n",
              "      <th>RGlob.std</th>\n",
              "      <th>RHIRGA168.mean</th>\n",
              "      <th>RHIRGA168.std</th>\n",
              "      <th>RHIRGA336.mean</th>\n",
              "      <th>RHIRGA336.std</th>\n",
              "      <th>RHIRGA42.mean</th>\n",
              "      <th>RHIRGA42.std</th>\n",
              "      <th>RHIRGA504.mean</th>\n",
              "      <th>RHIRGA504.std</th>\n",
              "      <th>RHIRGA672.mean</th>\n",
              "      <th>RHIRGA672.std</th>\n",
              "      <th>RHIRGA84.mean</th>\n",
              "      <th>RHIRGA84.std</th>\n",
              "      <th>RPAR.mean</th>\n",
              "      <th>RPAR.std</th>\n",
              "      <th>SO2168.mean</th>\n",
              "      <th>SO2168.std</th>\n",
              "      <th>SWS.mean</th>\n",
              "      <th>SWS.std</th>\n",
              "      <th>T168.mean</th>\n",
              "      <th>T168.std</th>\n",
              "      <th>T42.mean</th>\n",
              "      <th>T42.std</th>\n",
              "      <th>T504.mean</th>\n",
              "      <th>T504.std</th>\n",
              "      <th>T672.mean</th>\n",
              "      <th>T672.std</th>\n",
              "      <th>T84.mean</th>\n",
              "      <th>T84.std</th>\n",
              "      <th>UV_A.mean</th>\n",
              "      <th>UV_A.std</th>\n",
              "      <th>UV_B.mean</th>\n",
              "      <th>UV_B.std</th>\n",
              "      <th>CS.mean</th>\n",
              "      <th>CS.std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.228443</td>\n",
              "      <td>-0.045147</td>\n",
              "      <td>0.229670</td>\n",
              "      <td>-0.043585</td>\n",
              "      <td>0.231927</td>\n",
              "      <td>-0.030203</td>\n",
              "      <td>0.229788</td>\n",
              "      <td>-0.042568</td>\n",
              "      <td>-0.053369</td>\n",
              "      <td>-0.059534</td>\n",
              "      <td>-0.044611</td>\n",
              "      <td>-0.113334</td>\n",
              "      <td>-0.044537</td>\n",
              "      <td>-0.106625</td>\n",
              "      <td>-0.045141</td>\n",
              "      <td>-0.118510</td>\n",
              "      <td>-0.044421</td>\n",
              "      <td>-0.105757</td>\n",
              "      <td>-0.044756</td>\n",
              "      <td>-0.103955</td>\n",
              "      <td>-0.044539</td>\n",
              "      <td>-0.116195</td>\n",
              "      <td>-0.029111</td>\n",
              "      <td>-0.046993</td>\n",
              "      <td>0.021024</td>\n",
              "      <td>0.012831</td>\n",
              "      <td>0.019324</td>\n",
              "      <td>-0.033034</td>\n",
              "      <td>0.028222</td>\n",
              "      <td>0.027789</td>\n",
              "      <td>0.016739</td>\n",
              "      <td>-0.030805</td>\n",
              "      <td>0.016338</td>\n",
              "      <td>-0.020611</td>\n",
              "      <td>0.022843</td>\n",
              "      <td>0.015734</td>\n",
              "      <td>-0.015861</td>\n",
              "      <td>-0.030269</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038747</td>\n",
              "      <td>-0.046260</td>\n",
              "      <td>-0.024011</td>\n",
              "      <td>-0.135890</td>\n",
              "      <td>-0.070228</td>\n",
              "      <td>-0.084552</td>\n",
              "      <td>0.028028</td>\n",
              "      <td>-0.097316</td>\n",
              "      <td>0.032216</td>\n",
              "      <td>-0.091688</td>\n",
              "      <td>0.026055</td>\n",
              "      <td>-0.105942</td>\n",
              "      <td>0.032004</td>\n",
              "      <td>-0.086588</td>\n",
              "      <td>0.029500</td>\n",
              "      <td>-0.083706</td>\n",
              "      <td>0.027282</td>\n",
              "      <td>-0.098096</td>\n",
              "      <td>-0.053281</td>\n",
              "      <td>-0.068451</td>\n",
              "      <td>0.027422</td>\n",
              "      <td>-0.034811</td>\n",
              "      <td>0.010521</td>\n",
              "      <td>-0.088205</td>\n",
              "      <td>-0.043435</td>\n",
              "      <td>-0.098522</td>\n",
              "      <td>-0.042924</td>\n",
              "      <td>-0.106342</td>\n",
              "      <td>-0.045010</td>\n",
              "      <td>-0.084135</td>\n",
              "      <td>-0.045075</td>\n",
              "      <td>-0.074804</td>\n",
              "      <td>-0.042971</td>\n",
              "      <td>-0.100541</td>\n",
              "      <td>-0.039990</td>\n",
              "      <td>-0.044586</td>\n",
              "      <td>-0.012763</td>\n",
              "      <td>-0.018951</td>\n",
              "      <td>-0.027982</td>\n",
              "      <td>-0.076633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>partlybad</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CO2168.mean</th>\n",
              "      <td>0.228443</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.396889</td>\n",
              "      <td>0.999534</td>\n",
              "      <td>-0.386911</td>\n",
              "      <td>0.990738</td>\n",
              "      <td>-0.380015</td>\n",
              "      <td>0.997810</td>\n",
              "      <td>-0.381883</td>\n",
              "      <td>-0.470361</td>\n",
              "      <td>-0.516343</td>\n",
              "      <td>-0.444091</td>\n",
              "      <td>-0.400277</td>\n",
              "      <td>-0.439809</td>\n",
              "      <td>-0.398847</td>\n",
              "      <td>-0.452034</td>\n",
              "      <td>-0.409742</td>\n",
              "      <td>-0.437152</td>\n",
              "      <td>-0.399857</td>\n",
              "      <td>-0.435265</td>\n",
              "      <td>-0.395419</td>\n",
              "      <td>-0.447572</td>\n",
              "      <td>-0.403316</td>\n",
              "      <td>-0.446553</td>\n",
              "      <td>-0.504338</td>\n",
              "      <td>0.356344</td>\n",
              "      <td>0.327890</td>\n",
              "      <td>0.355423</td>\n",
              "      <td>0.326969</td>\n",
              "      <td>0.328038</td>\n",
              "      <td>0.293359</td>\n",
              "      <td>0.344204</td>\n",
              "      <td>0.294911</td>\n",
              "      <td>0.341815</td>\n",
              "      <td>0.314788</td>\n",
              "      <td>0.340702</td>\n",
              "      <td>0.286646</td>\n",
              "      <td>0.406666</td>\n",
              "      <td>0.318581</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.460990</td>\n",
              "      <td>-0.503253</td>\n",
              "      <td>0.140705</td>\n",
              "      <td>-0.303658</td>\n",
              "      <td>-0.355585</td>\n",
              "      <td>-0.444298</td>\n",
              "      <td>0.468207</td>\n",
              "      <td>-0.430023</td>\n",
              "      <td>0.484998</td>\n",
              "      <td>-0.414249</td>\n",
              "      <td>0.455220</td>\n",
              "      <td>-0.465799</td>\n",
              "      <td>0.483552</td>\n",
              "      <td>-0.401395</td>\n",
              "      <td>0.481473</td>\n",
              "      <td>-0.388297</td>\n",
              "      <td>0.459231</td>\n",
              "      <td>-0.447152</td>\n",
              "      <td>-0.014386</td>\n",
              "      <td>-0.106127</td>\n",
              "      <td>0.314747</td>\n",
              "      <td>0.043167</td>\n",
              "      <td>-0.236720</td>\n",
              "      <td>0.055569</td>\n",
              "      <td>-0.581504</td>\n",
              "      <td>-0.386636</td>\n",
              "      <td>-0.581257</td>\n",
              "      <td>-0.410272</td>\n",
              "      <td>-0.582925</td>\n",
              "      <td>-0.378302</td>\n",
              "      <td>-0.582367</td>\n",
              "      <td>-0.382505</td>\n",
              "      <td>-0.581240</td>\n",
              "      <td>-0.397168</td>\n",
              "      <td>-0.486662</td>\n",
              "      <td>-0.510008</td>\n",
              "      <td>-0.487536</td>\n",
              "      <td>-0.500662</td>\n",
              "      <td>-0.120773</td>\n",
              "      <td>-0.121059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CO2168.std</th>\n",
              "      <td>-0.045147</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.396889</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.402300</td>\n",
              "      <td>0.993389</td>\n",
              "      <td>-0.332370</td>\n",
              "      <td>0.900384</td>\n",
              "      <td>-0.410831</td>\n",
              "      <td>0.978829</td>\n",
              "      <td>0.297979</td>\n",
              "      <td>0.382078</td>\n",
              "      <td>0.750780</td>\n",
              "      <td>0.522732</td>\n",
              "      <td>0.747667</td>\n",
              "      <td>0.523087</td>\n",
              "      <td>0.755248</td>\n",
              "      <td>0.536171</td>\n",
              "      <td>0.745248</td>\n",
              "      <td>0.531161</td>\n",
              "      <td>0.743139</td>\n",
              "      <td>0.534905</td>\n",
              "      <td>0.753785</td>\n",
              "      <td>0.530436</td>\n",
              "      <td>0.338834</td>\n",
              "      <td>0.377074</td>\n",
              "      <td>-0.127587</td>\n",
              "      <td>-0.071399</td>\n",
              "      <td>-0.131543</td>\n",
              "      <td>-0.069052</td>\n",
              "      <td>-0.078542</td>\n",
              "      <td>0.049552</td>\n",
              "      <td>-0.125948</td>\n",
              "      <td>-0.047260</td>\n",
              "      <td>-0.125230</td>\n",
              "      <td>-0.058830</td>\n",
              "      <td>-0.121561</td>\n",
              "      <td>-0.019488</td>\n",
              "      <td>-0.230797</td>\n",
              "      <td>-0.098305</td>\n",
              "      <td>...</td>\n",
              "      <td>0.324922</td>\n",
              "      <td>0.400603</td>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.276331</td>\n",
              "      <td>0.170094</td>\n",
              "      <td>0.294872</td>\n",
              "      <td>-0.230182</td>\n",
              "      <td>0.341398</td>\n",
              "      <td>-0.246650</td>\n",
              "      <td>0.330927</td>\n",
              "      <td>-0.211054</td>\n",
              "      <td>0.345824</td>\n",
              "      <td>-0.252693</td>\n",
              "      <td>0.320987</td>\n",
              "      <td>-0.259628</td>\n",
              "      <td>0.307950</td>\n",
              "      <td>-0.216773</td>\n",
              "      <td>0.351259</td>\n",
              "      <td>-0.089738</td>\n",
              "      <td>0.002182</td>\n",
              "      <td>-0.129903</td>\n",
              "      <td>-0.012933</td>\n",
              "      <td>0.003614</td>\n",
              "      <td>0.104514</td>\n",
              "      <td>0.660586</td>\n",
              "      <td>0.271731</td>\n",
              "      <td>0.659522</td>\n",
              "      <td>0.280499</td>\n",
              "      <td>0.665943</td>\n",
              "      <td>0.252961</td>\n",
              "      <td>0.668039</td>\n",
              "      <td>0.248533</td>\n",
              "      <td>0.659502</td>\n",
              "      <td>0.282120</td>\n",
              "      <td>0.369696</td>\n",
              "      <td>0.421507</td>\n",
              "      <td>0.470896</td>\n",
              "      <td>0.492944</td>\n",
              "      <td>0.383044</td>\n",
              "      <td>0.326825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CO2336.mean</th>\n",
              "      <td>0.229670</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.999534</td>\n",
              "      <td>-0.402300</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.391874</td>\n",
              "      <td>0.988514</td>\n",
              "      <td>-0.388099</td>\n",
              "      <td>0.999282</td>\n",
              "      <td>-0.385438</td>\n",
              "      <td>-0.465756</td>\n",
              "      <td>-0.511792</td>\n",
              "      <td>-0.445790</td>\n",
              "      <td>-0.400224</td>\n",
              "      <td>-0.441492</td>\n",
              "      <td>-0.398578</td>\n",
              "      <td>-0.453707</td>\n",
              "      <td>-0.410213</td>\n",
              "      <td>-0.438848</td>\n",
              "      <td>-0.399807</td>\n",
              "      <td>-0.436962</td>\n",
              "      <td>-0.395566</td>\n",
              "      <td>-0.449267</td>\n",
              "      <td>-0.403640</td>\n",
              "      <td>-0.441461</td>\n",
              "      <td>-0.499438</td>\n",
              "      <td>0.354273</td>\n",
              "      <td>0.324564</td>\n",
              "      <td>0.355124</td>\n",
              "      <td>0.325026</td>\n",
              "      <td>0.325797</td>\n",
              "      <td>0.288044</td>\n",
              "      <td>0.344916</td>\n",
              "      <td>0.294558</td>\n",
              "      <td>0.342516</td>\n",
              "      <td>0.314334</td>\n",
              "      <td>0.338663</td>\n",
              "      <td>0.282651</td>\n",
              "      <td>0.402955</td>\n",
              "      <td>0.316292</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.456081</td>\n",
              "      <td>-0.498548</td>\n",
              "      <td>0.120456</td>\n",
              "      <td>-0.308832</td>\n",
              "      <td>-0.352862</td>\n",
              "      <td>-0.441319</td>\n",
              "      <td>0.463324</td>\n",
              "      <td>-0.426003</td>\n",
              "      <td>0.480439</td>\n",
              "      <td>-0.410083</td>\n",
              "      <td>0.450387</td>\n",
              "      <td>-0.462362</td>\n",
              "      <td>0.479569</td>\n",
              "      <td>-0.396887</td>\n",
              "      <td>0.477923</td>\n",
              "      <td>-0.383890</td>\n",
              "      <td>0.454353</td>\n",
              "      <td>-0.443492</td>\n",
              "      <td>-0.014118</td>\n",
              "      <td>-0.105245</td>\n",
              "      <td>0.311935</td>\n",
              "      <td>0.040967</td>\n",
              "      <td>-0.236541</td>\n",
              "      <td>0.055029</td>\n",
              "      <td>-0.578631</td>\n",
              "      <td>-0.383918</td>\n",
              "      <td>-0.578247</td>\n",
              "      <td>-0.408431</td>\n",
              "      <td>-0.580686</td>\n",
              "      <td>-0.374869</td>\n",
              "      <td>-0.580293</td>\n",
              "      <td>-0.378439</td>\n",
              "      <td>-0.578258</td>\n",
              "      <td>-0.394951</td>\n",
              "      <td>-0.482059</td>\n",
              "      <td>-0.505697</td>\n",
              "      <td>-0.483683</td>\n",
              "      <td>-0.497147</td>\n",
              "      <td>-0.123735</td>\n",
              "      <td>-0.124156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UV_A.std</th>\n",
              "      <td>-0.044586</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.510008</td>\n",
              "      <td>0.421507</td>\n",
              "      <td>-0.505697</td>\n",
              "      <td>0.415647</td>\n",
              "      <td>-0.494550</td>\n",
              "      <td>0.414289</td>\n",
              "      <td>-0.502440</td>\n",
              "      <td>0.412523</td>\n",
              "      <td>0.953449</td>\n",
              "      <td>0.987889</td>\n",
              "      <td>0.379941</td>\n",
              "      <td>0.565569</td>\n",
              "      <td>0.374708</td>\n",
              "      <td>0.572535</td>\n",
              "      <td>0.390523</td>\n",
              "      <td>0.561599</td>\n",
              "      <td>0.371101</td>\n",
              "      <td>0.574456</td>\n",
              "      <td>0.368295</td>\n",
              "      <td>0.569707</td>\n",
              "      <td>0.385071</td>\n",
              "      <td>0.560102</td>\n",
              "      <td>0.951007</td>\n",
              "      <td>0.980378</td>\n",
              "      <td>-0.234128</td>\n",
              "      <td>-0.208908</td>\n",
              "      <td>-0.237921</td>\n",
              "      <td>-0.242572</td>\n",
              "      <td>-0.197050</td>\n",
              "      <td>-0.160559</td>\n",
              "      <td>-0.229538</td>\n",
              "      <td>-0.210092</td>\n",
              "      <td>-0.229201</td>\n",
              "      <td>-0.214999</td>\n",
              "      <td>-0.223095</td>\n",
              "      <td>-0.179498</td>\n",
              "      <td>-0.429317</td>\n",
              "      <td>-0.240088</td>\n",
              "      <td>...</td>\n",
              "      <td>0.963645</td>\n",
              "      <td>0.992891</td>\n",
              "      <td>-0.284108</td>\n",
              "      <td>0.546079</td>\n",
              "      <td>0.801440</td>\n",
              "      <td>0.889290</td>\n",
              "      <td>-0.864812</td>\n",
              "      <td>0.759223</td>\n",
              "      <td>-0.868487</td>\n",
              "      <td>0.736979</td>\n",
              "      <td>-0.859991</td>\n",
              "      <td>0.809748</td>\n",
              "      <td>-0.867614</td>\n",
              "      <td>0.711109</td>\n",
              "      <td>-0.865268</td>\n",
              "      <td>0.684789</td>\n",
              "      <td>-0.862727</td>\n",
              "      <td>0.787684</td>\n",
              "      <td>0.400433</td>\n",
              "      <td>0.514671</td>\n",
              "      <td>-0.229589</td>\n",
              "      <td>-0.040740</td>\n",
              "      <td>0.262088</td>\n",
              "      <td>-0.190524</td>\n",
              "      <td>0.733270</td>\n",
              "      <td>0.784553</td>\n",
              "      <td>0.733230</td>\n",
              "      <td>0.813593</td>\n",
              "      <td>0.730756</td>\n",
              "      <td>0.772847</td>\n",
              "      <td>0.729751</td>\n",
              "      <td>0.773761</td>\n",
              "      <td>0.735114</td>\n",
              "      <td>0.806244</td>\n",
              "      <td>0.982402</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.962746</td>\n",
              "      <td>0.970029</td>\n",
              "      <td>0.166854</td>\n",
              "      <td>0.244797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UV_B.mean</th>\n",
              "      <td>-0.012763</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.487536</td>\n",
              "      <td>0.470896</td>\n",
              "      <td>-0.483683</td>\n",
              "      <td>0.466853</td>\n",
              "      <td>-0.464142</td>\n",
              "      <td>0.471424</td>\n",
              "      <td>-0.481447</td>\n",
              "      <td>0.461199</td>\n",
              "      <td>0.932337</td>\n",
              "      <td>0.940529</td>\n",
              "      <td>0.427487</td>\n",
              "      <td>0.570760</td>\n",
              "      <td>0.422128</td>\n",
              "      <td>0.578737</td>\n",
              "      <td>0.438290</td>\n",
              "      <td>0.566180</td>\n",
              "      <td>0.418386</td>\n",
              "      <td>0.581617</td>\n",
              "      <td>0.415489</td>\n",
              "      <td>0.577596</td>\n",
              "      <td>0.432944</td>\n",
              "      <td>0.563975</td>\n",
              "      <td>0.940850</td>\n",
              "      <td>0.946397</td>\n",
              "      <td>-0.226075</td>\n",
              "      <td>-0.209517</td>\n",
              "      <td>-0.230232</td>\n",
              "      <td>-0.234892</td>\n",
              "      <td>-0.185940</td>\n",
              "      <td>-0.145161</td>\n",
              "      <td>-0.221898</td>\n",
              "      <td>-0.200463</td>\n",
              "      <td>-0.221804</td>\n",
              "      <td>-0.207915</td>\n",
              "      <td>-0.215080</td>\n",
              "      <td>-0.170921</td>\n",
              "      <td>-0.426402</td>\n",
              "      <td>-0.236436</td>\n",
              "      <td>...</td>\n",
              "      <td>0.948623</td>\n",
              "      <td>0.950274</td>\n",
              "      <td>-0.251787</td>\n",
              "      <td>0.552929</td>\n",
              "      <td>0.766803</td>\n",
              "      <td>0.816658</td>\n",
              "      <td>-0.854254</td>\n",
              "      <td>0.694240</td>\n",
              "      <td>-0.858684</td>\n",
              "      <td>0.670499</td>\n",
              "      <td>-0.846275</td>\n",
              "      <td>0.753203</td>\n",
              "      <td>-0.859426</td>\n",
              "      <td>0.642162</td>\n",
              "      <td>-0.859132</td>\n",
              "      <td>0.613154</td>\n",
              "      <td>-0.849899</td>\n",
              "      <td>0.726953</td>\n",
              "      <td>0.345410</td>\n",
              "      <td>0.429415</td>\n",
              "      <td>-0.226492</td>\n",
              "      <td>-0.061520</td>\n",
              "      <td>0.240783</td>\n",
              "      <td>-0.215177</td>\n",
              "      <td>0.773516</td>\n",
              "      <td>0.775498</td>\n",
              "      <td>0.772156</td>\n",
              "      <td>0.806501</td>\n",
              "      <td>0.771995</td>\n",
              "      <td>0.763768</td>\n",
              "      <td>0.771871</td>\n",
              "      <td>0.763715</td>\n",
              "      <td>0.774521</td>\n",
              "      <td>0.798056</td>\n",
              "      <td>0.962615</td>\n",
              "      <td>0.962746</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.991335</td>\n",
              "      <td>0.204079</td>\n",
              "      <td>0.250528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UV_B.std</th>\n",
              "      <td>-0.018951</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.500662</td>\n",
              "      <td>0.492944</td>\n",
              "      <td>-0.497147</td>\n",
              "      <td>0.487943</td>\n",
              "      <td>-0.475829</td>\n",
              "      <td>0.491044</td>\n",
              "      <td>-0.494875</td>\n",
              "      <td>0.483850</td>\n",
              "      <td>0.907605</td>\n",
              "      <td>0.942940</td>\n",
              "      <td>0.469795</td>\n",
              "      <td>0.607247</td>\n",
              "      <td>0.464544</td>\n",
              "      <td>0.614704</td>\n",
              "      <td>0.480426</td>\n",
              "      <td>0.603777</td>\n",
              "      <td>0.460867</td>\n",
              "      <td>0.617443</td>\n",
              "      <td>0.457999</td>\n",
              "      <td>0.613571</td>\n",
              "      <td>0.475107</td>\n",
              "      <td>0.601371</td>\n",
              "      <td>0.922088</td>\n",
              "      <td>0.940778</td>\n",
              "      <td>-0.230681</td>\n",
              "      <td>-0.214050</td>\n",
              "      <td>-0.235321</td>\n",
              "      <td>-0.245276</td>\n",
              "      <td>-0.187581</td>\n",
              "      <td>-0.148372</td>\n",
              "      <td>-0.226943</td>\n",
              "      <td>-0.212230</td>\n",
              "      <td>-0.226478</td>\n",
              "      <td>-0.218002</td>\n",
              "      <td>-0.218643</td>\n",
              "      <td>-0.173264</td>\n",
              "      <td>-0.424289</td>\n",
              "      <td>-0.236574</td>\n",
              "      <td>...</td>\n",
              "      <td>0.924759</td>\n",
              "      <td>0.952620</td>\n",
              "      <td>-0.250677</td>\n",
              "      <td>0.523251</td>\n",
              "      <td>0.726418</td>\n",
              "      <td>0.808404</td>\n",
              "      <td>-0.825330</td>\n",
              "      <td>0.690524</td>\n",
              "      <td>-0.831160</td>\n",
              "      <td>0.667173</td>\n",
              "      <td>-0.816913</td>\n",
              "      <td>0.747919</td>\n",
              "      <td>-0.832030</td>\n",
              "      <td>0.640474</td>\n",
              "      <td>-0.831794</td>\n",
              "      <td>0.613734</td>\n",
              "      <td>-0.820305</td>\n",
              "      <td>0.722681</td>\n",
              "      <td>0.296124</td>\n",
              "      <td>0.398569</td>\n",
              "      <td>-0.242613</td>\n",
              "      <td>-0.071209</td>\n",
              "      <td>0.220354</td>\n",
              "      <td>-0.175900</td>\n",
              "      <td>0.790726</td>\n",
              "      <td>0.749783</td>\n",
              "      <td>0.790028</td>\n",
              "      <td>0.781466</td>\n",
              "      <td>0.789575</td>\n",
              "      <td>0.739279</td>\n",
              "      <td>0.789320</td>\n",
              "      <td>0.741294</td>\n",
              "      <td>0.791815</td>\n",
              "      <td>0.772751</td>\n",
              "      <td>0.947009</td>\n",
              "      <td>0.970029</td>\n",
              "      <td>0.991335</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.214929</td>\n",
              "      <td>0.269773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS.mean</th>\n",
              "      <td>-0.027982</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.120773</td>\n",
              "      <td>0.383044</td>\n",
              "      <td>-0.123735</td>\n",
              "      <td>0.393562</td>\n",
              "      <td>-0.100798</td>\n",
              "      <td>0.315988</td>\n",
              "      <td>-0.127522</td>\n",
              "      <td>0.404171</td>\n",
              "      <td>0.127784</td>\n",
              "      <td>0.147409</td>\n",
              "      <td>0.463826</td>\n",
              "      <td>0.280217</td>\n",
              "      <td>0.465726</td>\n",
              "      <td>0.268504</td>\n",
              "      <td>0.460040</td>\n",
              "      <td>0.296996</td>\n",
              "      <td>0.467179</td>\n",
              "      <td>0.262762</td>\n",
              "      <td>0.467832</td>\n",
              "      <td>0.261697</td>\n",
              "      <td>0.461628</td>\n",
              "      <td>0.292038</td>\n",
              "      <td>0.175218</td>\n",
              "      <td>0.150062</td>\n",
              "      <td>0.035937</td>\n",
              "      <td>0.047035</td>\n",
              "      <td>0.042919</td>\n",
              "      <td>0.091918</td>\n",
              "      <td>0.029431</td>\n",
              "      <td>0.032658</td>\n",
              "      <td>0.047966</td>\n",
              "      <td>0.108109</td>\n",
              "      <td>0.048788</td>\n",
              "      <td>0.107519</td>\n",
              "      <td>0.027347</td>\n",
              "      <td>0.029617</td>\n",
              "      <td>0.241482</td>\n",
              "      <td>0.096257</td>\n",
              "      <td>...</td>\n",
              "      <td>0.134968</td>\n",
              "      <td>0.150256</td>\n",
              "      <td>0.052899</td>\n",
              "      <td>0.174499</td>\n",
              "      <td>0.062184</td>\n",
              "      <td>0.114402</td>\n",
              "      <td>-0.116533</td>\n",
              "      <td>0.059679</td>\n",
              "      <td>-0.120405</td>\n",
              "      <td>0.043951</td>\n",
              "      <td>-0.119876</td>\n",
              "      <td>0.078715</td>\n",
              "      <td>-0.121407</td>\n",
              "      <td>0.032813</td>\n",
              "      <td>-0.123704</td>\n",
              "      <td>0.023089</td>\n",
              "      <td>-0.117332</td>\n",
              "      <td>0.074703</td>\n",
              "      <td>-0.015764</td>\n",
              "      <td>0.020730</td>\n",
              "      <td>0.333869</td>\n",
              "      <td>0.203944</td>\n",
              "      <td>0.043264</td>\n",
              "      <td>0.035451</td>\n",
              "      <td>0.386580</td>\n",
              "      <td>0.238340</td>\n",
              "      <td>0.387446</td>\n",
              "      <td>0.232026</td>\n",
              "      <td>0.390600</td>\n",
              "      <td>0.226188</td>\n",
              "      <td>0.393076</td>\n",
              "      <td>0.223991</td>\n",
              "      <td>0.386809</td>\n",
              "      <td>0.237444</td>\n",
              "      <td>0.148617</td>\n",
              "      <td>0.166854</td>\n",
              "      <td>0.204079</td>\n",
              "      <td>0.214929</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.517692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CS.std</th>\n",
              "      <td>-0.076633</td>\n",
              "      <td>NaN</td>\n",
              "      <td>-0.121059</td>\n",
              "      <td>0.326825</td>\n",
              "      <td>-0.124156</td>\n",
              "      <td>0.335386</td>\n",
              "      <td>-0.109411</td>\n",
              "      <td>0.268022</td>\n",
              "      <td>-0.127359</td>\n",
              "      <td>0.346976</td>\n",
              "      <td>0.208277</td>\n",
              "      <td>0.231690</td>\n",
              "      <td>0.317360</td>\n",
              "      <td>0.379917</td>\n",
              "      <td>0.318280</td>\n",
              "      <td>0.369949</td>\n",
              "      <td>0.315717</td>\n",
              "      <td>0.392872</td>\n",
              "      <td>0.318852</td>\n",
              "      <td>0.364640</td>\n",
              "      <td>0.319221</td>\n",
              "      <td>0.360257</td>\n",
              "      <td>0.316185</td>\n",
              "      <td>0.388783</td>\n",
              "      <td>0.237271</td>\n",
              "      <td>0.231407</td>\n",
              "      <td>-0.055861</td>\n",
              "      <td>-0.009981</td>\n",
              "      <td>-0.053138</td>\n",
              "      <td>0.025680</td>\n",
              "      <td>-0.051258</td>\n",
              "      <td>-0.021888</td>\n",
              "      <td>-0.050660</td>\n",
              "      <td>0.014536</td>\n",
              "      <td>-0.052012</td>\n",
              "      <td>0.011572</td>\n",
              "      <td>-0.058039</td>\n",
              "      <td>-0.019130</td>\n",
              "      <td>0.012814</td>\n",
              "      <td>0.126511</td>\n",
              "      <td>...</td>\n",
              "      <td>0.207194</td>\n",
              "      <td>0.234656</td>\n",
              "      <td>0.016636</td>\n",
              "      <td>0.213319</td>\n",
              "      <td>0.117550</td>\n",
              "      <td>0.179829</td>\n",
              "      <td>-0.184874</td>\n",
              "      <td>0.201361</td>\n",
              "      <td>-0.189884</td>\n",
              "      <td>0.189785</td>\n",
              "      <td>-0.186469</td>\n",
              "      <td>0.219774</td>\n",
              "      <td>-0.190858</td>\n",
              "      <td>0.179902</td>\n",
              "      <td>-0.193024</td>\n",
              "      <td>0.172628</td>\n",
              "      <td>-0.185234</td>\n",
              "      <td>0.214271</td>\n",
              "      <td>0.001221</td>\n",
              "      <td>0.055578</td>\n",
              "      <td>0.038867</td>\n",
              "      <td>0.201191</td>\n",
              "      <td>-0.001834</td>\n",
              "      <td>0.081041</td>\n",
              "      <td>0.344211</td>\n",
              "      <td>0.256800</td>\n",
              "      <td>0.344890</td>\n",
              "      <td>0.260877</td>\n",
              "      <td>0.347034</td>\n",
              "      <td>0.235805</td>\n",
              "      <td>0.348770</td>\n",
              "      <td>0.230958</td>\n",
              "      <td>0.344755</td>\n",
              "      <td>0.262085</td>\n",
              "      <td>0.215018</td>\n",
              "      <td>0.244797</td>\n",
              "      <td>0.250528</td>\n",
              "      <td>0.269773</td>\n",
              "      <td>0.517692</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102 rows Ã— 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   id  partlybad  CO2168.mean  ...  UV_B.std   CS.mean    CS.std\n",
              "id           1.000000        NaN     0.228443  ... -0.018951 -0.027982 -0.076633\n",
              "partlybad         NaN        NaN          NaN  ...       NaN       NaN       NaN\n",
              "CO2168.mean  0.228443        NaN     1.000000  ... -0.500662 -0.120773 -0.121059\n",
              "CO2168.std  -0.045147        NaN    -0.396889  ...  0.492944  0.383044  0.326825\n",
              "CO2336.mean  0.229670        NaN     0.999534  ... -0.497147 -0.123735 -0.124156\n",
              "...               ...        ...          ...  ...       ...       ...       ...\n",
              "UV_A.std    -0.044586        NaN    -0.510008  ...  0.970029  0.166854  0.244797\n",
              "UV_B.mean   -0.012763        NaN    -0.487536  ...  0.991335  0.204079  0.250528\n",
              "UV_B.std    -0.018951        NaN    -0.500662  ...  1.000000  0.214929  0.269773\n",
              "CS.mean     -0.027982        NaN    -0.120773  ...  0.214929  1.000000  0.517692\n",
              "CS.std      -0.076633        NaN    -0.121059  ...  0.269773  0.517692  1.000000\n",
              "\n",
              "[102 rows x 102 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "id": "tUbpHW-mJr3m",
        "outputId": "3248162a-3fe8-4f1c-ceb7-31fde2dd129d"
      },
      "source": [
        "corr_df = df_train.corr()\n",
        "corr_best = corr_df.index\n",
        "plt.figure(figsize=(15,15))\n",
        "corr_map=sns.heatmap(df_train[corr_best].corr(),annot=False,cmap=\"BuPu\")\n",
        "plt.savefig('corrmap', format='png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKYWnvVQZ13z"
      },
      "source": [
        "### Split the train data into training and validation sets\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6PpKDovZzdE"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = df_train[\"class2\"]\n",
        "X = df_train.drop([\"class4\",\"class2\",\"id\",\"date\"],axis = 1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnxtwamnbUcP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "600780ad-37ef-4f04-ef79-f4507df15261"
      },
      "source": [
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>partlybad</th>\n",
              "      <th>CO2168.mean</th>\n",
              "      <th>CO2168.std</th>\n",
              "      <th>CO2336.mean</th>\n",
              "      <th>CO2336.std</th>\n",
              "      <th>CO242.mean</th>\n",
              "      <th>CO242.std</th>\n",
              "      <th>CO2504.mean</th>\n",
              "      <th>CO2504.std</th>\n",
              "      <th>Glob.mean</th>\n",
              "      <th>Glob.std</th>\n",
              "      <th>H2O168.mean</th>\n",
              "      <th>H2O168.std</th>\n",
              "      <th>H2O336.mean</th>\n",
              "      <th>H2O336.std</th>\n",
              "      <th>H2O42.mean</th>\n",
              "      <th>H2O42.std</th>\n",
              "      <th>H2O504.mean</th>\n",
              "      <th>H2O504.std</th>\n",
              "      <th>H2O672.mean</th>\n",
              "      <th>H2O672.std</th>\n",
              "      <th>H2O84.mean</th>\n",
              "      <th>H2O84.std</th>\n",
              "      <th>NET.mean</th>\n",
              "      <th>NET.std</th>\n",
              "      <th>NO168.mean</th>\n",
              "      <th>NO168.std</th>\n",
              "      <th>NO336.mean</th>\n",
              "      <th>NO336.std</th>\n",
              "      <th>NO42.mean</th>\n",
              "      <th>NO42.std</th>\n",
              "      <th>NO504.mean</th>\n",
              "      <th>NO504.std</th>\n",
              "      <th>NO672.mean</th>\n",
              "      <th>NO672.std</th>\n",
              "      <th>NO84.mean</th>\n",
              "      <th>NO84.std</th>\n",
              "      <th>NOx168.mean</th>\n",
              "      <th>NOx168.std</th>\n",
              "      <th>NOx336.mean</th>\n",
              "      <th>...</th>\n",
              "      <th>PAR.mean</th>\n",
              "      <th>PAR.std</th>\n",
              "      <th>PTG.mean</th>\n",
              "      <th>PTG.std</th>\n",
              "      <th>RGlob.mean</th>\n",
              "      <th>RGlob.std</th>\n",
              "      <th>RHIRGA168.mean</th>\n",
              "      <th>RHIRGA168.std</th>\n",
              "      <th>RHIRGA336.mean</th>\n",
              "      <th>RHIRGA336.std</th>\n",
              "      <th>RHIRGA42.mean</th>\n",
              "      <th>RHIRGA42.std</th>\n",
              "      <th>RHIRGA504.mean</th>\n",
              "      <th>RHIRGA504.std</th>\n",
              "      <th>RHIRGA672.mean</th>\n",
              "      <th>RHIRGA672.std</th>\n",
              "      <th>RHIRGA84.mean</th>\n",
              "      <th>RHIRGA84.std</th>\n",
              "      <th>RPAR.mean</th>\n",
              "      <th>RPAR.std</th>\n",
              "      <th>SO2168.mean</th>\n",
              "      <th>SO2168.std</th>\n",
              "      <th>SWS.mean</th>\n",
              "      <th>SWS.std</th>\n",
              "      <th>T168.mean</th>\n",
              "      <th>T168.std</th>\n",
              "      <th>T42.mean</th>\n",
              "      <th>T42.std</th>\n",
              "      <th>T504.mean</th>\n",
              "      <th>T504.std</th>\n",
              "      <th>T672.mean</th>\n",
              "      <th>T672.std</th>\n",
              "      <th>T84.mean</th>\n",
              "      <th>T84.std</th>\n",
              "      <th>UV_A.mean</th>\n",
              "      <th>UV_A.std</th>\n",
              "      <th>UV_B.mean</th>\n",
              "      <th>UV_B.std</th>\n",
              "      <th>CS.mean</th>\n",
              "      <th>CS.std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>False</td>\n",
              "      <td>380.528120</td>\n",
              "      <td>0.802001</td>\n",
              "      <td>380.371466</td>\n",
              "      <td>0.889550</td>\n",
              "      <td>381.816207</td>\n",
              "      <td>1.292593</td>\n",
              "      <td>380.296466</td>\n",
              "      <td>0.968884</td>\n",
              "      <td>236.605353</td>\n",
              "      <td>145.160571</td>\n",
              "      <td>2.663504</td>\n",
              "      <td>0.319427</td>\n",
              "      <td>2.695603</td>\n",
              "      <td>0.304894</td>\n",
              "      <td>2.548879</td>\n",
              "      <td>0.382813</td>\n",
              "      <td>2.694138</td>\n",
              "      <td>0.306606</td>\n",
              "      <td>2.771071</td>\n",
              "      <td>0.366386</td>\n",
              "      <td>2.613362</td>\n",
              "      <td>0.348996</td>\n",
              "      <td>81.699876</td>\n",
              "      <td>109.164607</td>\n",
              "      <td>0.319316</td>\n",
              "      <td>0.179649</td>\n",
              "      <td>0.336724</td>\n",
              "      <td>0.183974</td>\n",
              "      <td>0.235517</td>\n",
              "      <td>0.157543</td>\n",
              "      <td>0.332500</td>\n",
              "      <td>0.183478</td>\n",
              "      <td>0.287241</td>\n",
              "      <td>0.172559</td>\n",
              "      <td>0.286638</td>\n",
              "      <td>0.160141</td>\n",
              "      <td>2.657949</td>\n",
              "      <td>0.672278</td>\n",
              "      <td>2.650259</td>\n",
              "      <td>...</td>\n",
              "      <td>339.171515</td>\n",
              "      <td>211.125658</td>\n",
              "      <td>0.000964</td>\n",
              "      <td>0.007481</td>\n",
              "      <td>67.500843</td>\n",
              "      <td>30.529852</td>\n",
              "      <td>95.104103</td>\n",
              "      <td>1.612618</td>\n",
              "      <td>96.532586</td>\n",
              "      <td>2.382040</td>\n",
              "      <td>92.189052</td>\n",
              "      <td>1.781872</td>\n",
              "      <td>96.752672</td>\n",
              "      <td>2.326736</td>\n",
              "      <td>101.351071</td>\n",
              "      <td>4.571036</td>\n",
              "      <td>93.293534</td>\n",
              "      <td>1.981996</td>\n",
              "      <td>84.476919</td>\n",
              "      <td>49.764321</td>\n",
              "      <td>0.559316</td>\n",
              "      <td>0.374688</td>\n",
              "      <td>936.605263</td>\n",
              "      <td>0.916500</td>\n",
              "      <td>-10.272530</td>\n",
              "      <td>1.575415</td>\n",
              "      <td>-10.489828</td>\n",
              "      <td>2.085275</td>\n",
              "      <td>-10.346540</td>\n",
              "      <td>1.347401</td>\n",
              "      <td>-10.730843</td>\n",
              "      <td>1.381815</td>\n",
              "      <td>-10.282754</td>\n",
              "      <td>1.870056</td>\n",
              "      <td>8.356761</td>\n",
              "      <td>4.534937</td>\n",
              "      <td>0.178084</td>\n",
              "      <td>0.123402</td>\n",
              "      <td>0.002546</td>\n",
              "      <td>0.000686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>False</td>\n",
              "      <td>373.128684</td>\n",
              "      <td>1.096617</td>\n",
              "      <td>372.980000</td>\n",
              "      <td>1.047750</td>\n",
              "      <td>373.701830</td>\n",
              "      <td>1.259198</td>\n",
              "      <td>372.910000</td>\n",
              "      <td>1.004164</td>\n",
              "      <td>252.480327</td>\n",
              "      <td>138.921953</td>\n",
              "      <td>3.253684</td>\n",
              "      <td>0.299728</td>\n",
              "      <td>3.232222</td>\n",
              "      <td>0.308108</td>\n",
              "      <td>3.299150</td>\n",
              "      <td>0.290206</td>\n",
              "      <td>3.228039</td>\n",
              "      <td>0.310416</td>\n",
              "      <td>3.227712</td>\n",
              "      <td>0.307517</td>\n",
              "      <td>3.267582</td>\n",
              "      <td>0.298119</td>\n",
              "      <td>142.534162</td>\n",
              "      <td>115.885107</td>\n",
              "      <td>0.023618</td>\n",
              "      <td>0.040306</td>\n",
              "      <td>0.028105</td>\n",
              "      <td>0.042142</td>\n",
              "      <td>0.025294</td>\n",
              "      <td>0.045379</td>\n",
              "      <td>0.027908</td>\n",
              "      <td>0.046759</td>\n",
              "      <td>0.030458</td>\n",
              "      <td>0.042894</td>\n",
              "      <td>0.025425</td>\n",
              "      <td>0.094298</td>\n",
              "      <td>0.843355</td>\n",
              "      <td>0.159896</td>\n",
              "      <td>0.829739</td>\n",
              "      <td>...</td>\n",
              "      <td>487.596401</td>\n",
              "      <td>268.860550</td>\n",
              "      <td>-0.005340</td>\n",
              "      <td>0.008779</td>\n",
              "      <td>41.090445</td>\n",
              "      <td>21.317089</td>\n",
              "      <td>59.672237</td>\n",
              "      <td>14.625643</td>\n",
              "      <td>60.119150</td>\n",
              "      <td>14.369137</td>\n",
              "      <td>59.535033</td>\n",
              "      <td>15.592649</td>\n",
              "      <td>60.910915</td>\n",
              "      <td>14.122225</td>\n",
              "      <td>62.475294</td>\n",
              "      <td>14.217269</td>\n",
              "      <td>59.184771</td>\n",
              "      <td>15.260717</td>\n",
              "      <td>32.421126</td>\n",
              "      <td>19.516104</td>\n",
              "      <td>0.138289</td>\n",
              "      <td>0.115293</td>\n",
              "      <td>923.450980</td>\n",
              "      <td>2.062171</td>\n",
              "      <td>-1.330589</td>\n",
              "      <td>1.947330</td>\n",
              "      <td>-1.037435</td>\n",
              "      <td>2.231552</td>\n",
              "      <td>-1.738455</td>\n",
              "      <td>1.748079</td>\n",
              "      <td>-2.095641</td>\n",
              "      <td>1.695622</td>\n",
              "      <td>-1.095864</td>\n",
              "      <td>2.090111</td>\n",
              "      <td>12.906779</td>\n",
              "      <td>7.022300</td>\n",
              "      <td>0.333523</td>\n",
              "      <td>0.239981</td>\n",
              "      <td>0.000662</td>\n",
              "      <td>0.000210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>False</td>\n",
              "      <td>372.363293</td>\n",
              "      <td>0.626329</td>\n",
              "      <td>372.245689</td>\n",
              "      <td>0.615803</td>\n",
              "      <td>372.847246</td>\n",
              "      <td>0.647279</td>\n",
              "      <td>372.193952</td>\n",
              "      <td>0.596289</td>\n",
              "      <td>269.981547</td>\n",
              "      <td>200.826676</td>\n",
              "      <td>4.459042</td>\n",
              "      <td>0.367894</td>\n",
              "      <td>4.422874</td>\n",
              "      <td>0.365105</td>\n",
              "      <td>4.509760</td>\n",
              "      <td>0.360563</td>\n",
              "      <td>4.409401</td>\n",
              "      <td>0.359296</td>\n",
              "      <td>4.395988</td>\n",
              "      <td>0.357929</td>\n",
              "      <td>4.462515</td>\n",
              "      <td>0.362899</td>\n",
              "      <td>156.409709</td>\n",
              "      <td>173.191387</td>\n",
              "      <td>0.030898</td>\n",
              "      <td>0.047893</td>\n",
              "      <td>0.030000</td>\n",
              "      <td>0.046062</td>\n",
              "      <td>0.028802</td>\n",
              "      <td>0.047107</td>\n",
              "      <td>0.024910</td>\n",
              "      <td>0.045468</td>\n",
              "      <td>0.029940</td>\n",
              "      <td>0.052406</td>\n",
              "      <td>0.028802</td>\n",
              "      <td>0.050870</td>\n",
              "      <td>0.747545</td>\n",
              "      <td>0.207766</td>\n",
              "      <td>0.736407</td>\n",
              "      <td>...</td>\n",
              "      <td>515.622611</td>\n",
              "      <td>392.245819</td>\n",
              "      <td>-0.002910</td>\n",
              "      <td>0.006699</td>\n",
              "      <td>41.006814</td>\n",
              "      <td>29.483793</td>\n",
              "      <td>65.047844</td>\n",
              "      <td>13.978114</td>\n",
              "      <td>65.240539</td>\n",
              "      <td>14.181466</td>\n",
              "      <td>64.822395</td>\n",
              "      <td>13.827617</td>\n",
              "      <td>65.872216</td>\n",
              "      <td>14.174827</td>\n",
              "      <td>67.481018</td>\n",
              "      <td>14.652811</td>\n",
              "      <td>64.301856</td>\n",
              "      <td>13.820666</td>\n",
              "      <td>32.940216</td>\n",
              "      <td>25.385709</td>\n",
              "      <td>0.107066</td>\n",
              "      <td>0.122741</td>\n",
              "      <td>923.410714</td>\n",
              "      <td>2.647653</td>\n",
              "      <td>1.672108</td>\n",
              "      <td>1.942941</td>\n",
              "      <td>1.893257</td>\n",
              "      <td>1.960102</td>\n",
              "      <td>1.354012</td>\n",
              "      <td>1.910314</td>\n",
              "      <td>0.991521</td>\n",
              "      <td>1.914186</td>\n",
              "      <td>1.846503</td>\n",
              "      <td>1.954748</td>\n",
              "      <td>14.286261</td>\n",
              "      <td>9.572444</td>\n",
              "      <td>0.418313</td>\n",
              "      <td>0.344386</td>\n",
              "      <td>0.000541</td>\n",
              "      <td>0.000072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>False</td>\n",
              "      <td>381.437442</td>\n",
              "      <td>7.281159</td>\n",
              "      <td>381.380405</td>\n",
              "      <td>7.236002</td>\n",
              "      <td>381.926532</td>\n",
              "      <td>7.294374</td>\n",
              "      <td>381.381156</td>\n",
              "      <td>7.208287</td>\n",
              "      <td>68.364653</td>\n",
              "      <td>48.560722</td>\n",
              "      <td>6.613430</td>\n",
              "      <td>0.508011</td>\n",
              "      <td>6.568035</td>\n",
              "      <td>0.498439</td>\n",
              "      <td>6.627225</td>\n",
              "      <td>0.517847</td>\n",
              "      <td>6.579017</td>\n",
              "      <td>0.469558</td>\n",
              "      <td>6.566474</td>\n",
              "      <td>0.454360</td>\n",
              "      <td>6.620694</td>\n",
              "      <td>0.527051</td>\n",
              "      <td>53.752882</td>\n",
              "      <td>44.480753</td>\n",
              "      <td>0.717442</td>\n",
              "      <td>1.046600</td>\n",
              "      <td>0.763642</td>\n",
              "      <td>1.119467</td>\n",
              "      <td>0.601387</td>\n",
              "      <td>0.923043</td>\n",
              "      <td>0.800925</td>\n",
              "      <td>1.168399</td>\n",
              "      <td>0.822428</td>\n",
              "      <td>1.205617</td>\n",
              "      <td>0.663006</td>\n",
              "      <td>0.987611</td>\n",
              "      <td>5.320233</td>\n",
              "      <td>3.781138</td>\n",
              "      <td>5.338671</td>\n",
              "      <td>...</td>\n",
              "      <td>147.485058</td>\n",
              "      <td>103.352511</td>\n",
              "      <td>-0.000718</td>\n",
              "      <td>0.004928</td>\n",
              "      <td>10.616065</td>\n",
              "      <td>6.538927</td>\n",
              "      <td>90.906221</td>\n",
              "      <td>8.723910</td>\n",
              "      <td>91.022775</td>\n",
              "      <td>8.508574</td>\n",
              "      <td>89.268844</td>\n",
              "      <td>8.521074</td>\n",
              "      <td>91.875780</td>\n",
              "      <td>8.113524</td>\n",
              "      <td>93.993988</td>\n",
              "      <td>7.917405</td>\n",
              "      <td>89.774162</td>\n",
              "      <td>8.896734</td>\n",
              "      <td>11.890787</td>\n",
              "      <td>7.737403</td>\n",
              "      <td>0.323605</td>\n",
              "      <td>0.226767</td>\n",
              "      <td>918.862069</td>\n",
              "      <td>17.331088</td>\n",
              "      <td>2.321829</td>\n",
              "      <td>0.374436</td>\n",
              "      <td>2.610683</td>\n",
              "      <td>0.392255</td>\n",
              "      <td>2.105324</td>\n",
              "      <td>0.338427</td>\n",
              "      <td>1.753414</td>\n",
              "      <td>0.340565</td>\n",
              "      <td>2.524931</td>\n",
              "      <td>0.414255</td>\n",
              "      <td>4.945162</td>\n",
              "      <td>3.405652</td>\n",
              "      <td>0.224159</td>\n",
              "      <td>0.192014</td>\n",
              "      <td>0.003710</td>\n",
              "      <td>0.001209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>False</td>\n",
              "      <td>375.426310</td>\n",
              "      <td>3.264246</td>\n",
              "      <td>375.436524</td>\n",
              "      <td>3.110886</td>\n",
              "      <td>375.740215</td>\n",
              "      <td>3.274924</td>\n",
              "      <td>375.337059</td>\n",
              "      <td>2.903780</td>\n",
              "      <td>242.192619</td>\n",
              "      <td>190.952026</td>\n",
              "      <td>7.934171</td>\n",
              "      <td>0.326185</td>\n",
              "      <td>7.882727</td>\n",
              "      <td>0.302425</td>\n",
              "      <td>8.106183</td>\n",
              "      <td>0.368029</td>\n",
              "      <td>7.859840</td>\n",
              "      <td>0.299242</td>\n",
              "      <td>7.843690</td>\n",
              "      <td>0.295740</td>\n",
              "      <td>7.997957</td>\n",
              "      <td>0.350785</td>\n",
              "      <td>160.373121</td>\n",
              "      <td>149.664508</td>\n",
              "      <td>0.068877</td>\n",
              "      <td>0.114949</td>\n",
              "      <td>0.066043</td>\n",
              "      <td>0.117777</td>\n",
              "      <td>0.044011</td>\n",
              "      <td>0.082263</td>\n",
              "      <td>0.070856</td>\n",
              "      <td>0.114935</td>\n",
              "      <td>0.060695</td>\n",
              "      <td>0.102049</td>\n",
              "      <td>0.055615</td>\n",
              "      <td>0.104491</td>\n",
              "      <td>1.790267</td>\n",
              "      <td>0.550229</td>\n",
              "      <td>1.795455</td>\n",
              "      <td>...</td>\n",
              "      <td>472.855914</td>\n",
              "      <td>372.252005</td>\n",
              "      <td>0.005027</td>\n",
              "      <td>0.022413</td>\n",
              "      <td>28.190856</td>\n",
              "      <td>22.321519</td>\n",
              "      <td>60.907326</td>\n",
              "      <td>13.539642</td>\n",
              "      <td>60.474385</td>\n",
              "      <td>12.681657</td>\n",
              "      <td>61.444785</td>\n",
              "      <td>14.618152</td>\n",
              "      <td>60.320374</td>\n",
              "      <td>11.790057</td>\n",
              "      <td>60.756257</td>\n",
              "      <td>10.476841</td>\n",
              "      <td>60.506720</td>\n",
              "      <td>13.973508</td>\n",
              "      <td>17.840791</td>\n",
              "      <td>14.732266</td>\n",
              "      <td>0.366150</td>\n",
              "      <td>0.324216</td>\n",
              "      <td>919.629032</td>\n",
              "      <td>40.316874</td>\n",
              "      <td>11.210545</td>\n",
              "      <td>2.933483</td>\n",
              "      <td>11.415176</td>\n",
              "      <td>3.199418</td>\n",
              "      <td>11.139711</td>\n",
              "      <td>2.455458</td>\n",
              "      <td>10.940107</td>\n",
              "      <td>2.179821</td>\n",
              "      <td>11.441893</td>\n",
              "      <td>3.048699</td>\n",
              "      <td>13.087014</td>\n",
              "      <td>9.771415</td>\n",
              "      <td>0.525591</td>\n",
              "      <td>0.476821</td>\n",
              "      <td>0.003680</td>\n",
              "      <td>0.002160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>False</td>\n",
              "      <td>389.310533</td>\n",
              "      <td>1.384881</td>\n",
              "      <td>389.320933</td>\n",
              "      <td>1.372439</td>\n",
              "      <td>389.411333</td>\n",
              "      <td>1.372157</td>\n",
              "      <td>389.308133</td>\n",
              "      <td>1.363886</td>\n",
              "      <td>11.828822</td>\n",
              "      <td>7.455036</td>\n",
              "      <td>3.564667</td>\n",
              "      <td>0.176408</td>\n",
              "      <td>3.565600</td>\n",
              "      <td>0.181214</td>\n",
              "      <td>3.580667</td>\n",
              "      <td>0.192026</td>\n",
              "      <td>3.584533</td>\n",
              "      <td>0.214629</td>\n",
              "      <td>3.555600</td>\n",
              "      <td>0.224826</td>\n",
              "      <td>3.569067</td>\n",
              "      <td>0.186476</td>\n",
              "      <td>10.906111</td>\n",
              "      <td>10.265953</td>\n",
              "      <td>0.016933</td>\n",
              "      <td>0.031493</td>\n",
              "      <td>0.019600</td>\n",
              "      <td>0.031212</td>\n",
              "      <td>0.012933</td>\n",
              "      <td>0.025510</td>\n",
              "      <td>0.018267</td>\n",
              "      <td>0.039331</td>\n",
              "      <td>0.021067</td>\n",
              "      <td>0.028024</td>\n",
              "      <td>0.021333</td>\n",
              "      <td>0.029744</td>\n",
              "      <td>2.001867</td>\n",
              "      <td>0.277697</td>\n",
              "      <td>2.003467</td>\n",
              "      <td>...</td>\n",
              "      <td>26.818489</td>\n",
              "      <td>16.863619</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.888244</td>\n",
              "      <td>2.621408</td>\n",
              "      <td>96.931200</td>\n",
              "      <td>0.787028</td>\n",
              "      <td>98.564267</td>\n",
              "      <td>0.535608</td>\n",
              "      <td>96.242133</td>\n",
              "      <td>0.610986</td>\n",
              "      <td>99.120400</td>\n",
              "      <td>0.696321</td>\n",
              "      <td>99.693600</td>\n",
              "      <td>0.874254</td>\n",
              "      <td>96.522000</td>\n",
              "      <td>0.684887</td>\n",
              "      <td>6.332711</td>\n",
              "      <td>4.558416</td>\n",
              "      <td>2.072133</td>\n",
              "      <td>0.297895</td>\n",
              "      <td>919.233333</td>\n",
              "      <td>3.979979</td>\n",
              "      <td>-7.070356</td>\n",
              "      <td>0.672087</td>\n",
              "      <td>-6.937178</td>\n",
              "      <td>0.673440</td>\n",
              "      <td>-7.318444</td>\n",
              "      <td>0.664420</td>\n",
              "      <td>-7.496622</td>\n",
              "      <td>0.669413</td>\n",
              "      <td>-7.008933</td>\n",
              "      <td>0.691314</td>\n",
              "      <td>1.021069</td>\n",
              "      <td>0.591618</td>\n",
              "      <td>0.018869</td>\n",
              "      <td>0.011991</td>\n",
              "      <td>0.006578</td>\n",
              "      <td>0.001036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>False</td>\n",
              "      <td>380.048926</td>\n",
              "      <td>6.127866</td>\n",
              "      <td>380.105533</td>\n",
              "      <td>5.658127</td>\n",
              "      <td>381.673758</td>\n",
              "      <td>6.835401</td>\n",
              "      <td>379.888400</td>\n",
              "      <td>5.485305</td>\n",
              "      <td>108.429644</td>\n",
              "      <td>105.019275</td>\n",
              "      <td>14.532819</td>\n",
              "      <td>0.896484</td>\n",
              "      <td>14.401400</td>\n",
              "      <td>0.801472</td>\n",
              "      <td>14.754122</td>\n",
              "      <td>1.046930</td>\n",
              "      <td>14.328067</td>\n",
              "      <td>0.785613</td>\n",
              "      <td>14.248467</td>\n",
              "      <td>0.767428</td>\n",
              "      <td>14.699122</td>\n",
              "      <td>1.025178</td>\n",
              "      <td>80.665563</td>\n",
              "      <td>98.303398</td>\n",
              "      <td>0.044805</td>\n",
              "      <td>0.068887</td>\n",
              "      <td>0.046710</td>\n",
              "      <td>0.074373</td>\n",
              "      <td>0.057922</td>\n",
              "      <td>0.070067</td>\n",
              "      <td>0.049032</td>\n",
              "      <td>0.079510</td>\n",
              "      <td>0.051290</td>\n",
              "      <td>0.066885</td>\n",
              "      <td>0.033117</td>\n",
              "      <td>0.072161</td>\n",
              "      <td>0.885714</td>\n",
              "      <td>0.302465</td>\n",
              "      <td>0.881032</td>\n",
              "      <td>...</td>\n",
              "      <td>233.242567</td>\n",
              "      <td>217.986894</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>0.006354</td>\n",
              "      <td>12.544272</td>\n",
              "      <td>11.507249</td>\n",
              "      <td>82.448792</td>\n",
              "      <td>5.015215</td>\n",
              "      <td>82.909200</td>\n",
              "      <td>4.968426</td>\n",
              "      <td>82.968243</td>\n",
              "      <td>4.935353</td>\n",
              "      <td>83.148467</td>\n",
              "      <td>4.826225</td>\n",
              "      <td>83.687467</td>\n",
              "      <td>4.766537</td>\n",
              "      <td>82.733851</td>\n",
              "      <td>5.186590</td>\n",
              "      <td>6.092470</td>\n",
              "      <td>6.071200</td>\n",
              "      <td>0.046039</td>\n",
              "      <td>0.068499</td>\n",
              "      <td>886.806452</td>\n",
              "      <td>95.579482</td>\n",
              "      <td>15.323398</td>\n",
              "      <td>1.460131</td>\n",
              "      <td>15.469342</td>\n",
              "      <td>1.476389</td>\n",
              "      <td>14.987379</td>\n",
              "      <td>1.413248</td>\n",
              "      <td>14.797012</td>\n",
              "      <td>1.392316</td>\n",
              "      <td>15.460086</td>\n",
              "      <td>1.495813</td>\n",
              "      <td>7.786232</td>\n",
              "      <td>6.612248</td>\n",
              "      <td>0.380976</td>\n",
              "      <td>0.368811</td>\n",
              "      <td>0.004581</td>\n",
              "      <td>0.000499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>False</td>\n",
              "      <td>392.901308</td>\n",
              "      <td>2.236589</td>\n",
              "      <td>392.738372</td>\n",
              "      <td>2.830582</td>\n",
              "      <td>393.167054</td>\n",
              "      <td>2.196588</td>\n",
              "      <td>392.839690</td>\n",
              "      <td>2.071452</td>\n",
              "      <td>297.594773</td>\n",
              "      <td>221.092740</td>\n",
              "      <td>3.581154</td>\n",
              "      <td>0.293127</td>\n",
              "      <td>3.561860</td>\n",
              "      <td>0.282524</td>\n",
              "      <td>3.616504</td>\n",
              "      <td>0.277875</td>\n",
              "      <td>3.562791</td>\n",
              "      <td>0.282082</td>\n",
              "      <td>3.557385</td>\n",
              "      <td>0.265294</td>\n",
              "      <td>3.588077</td>\n",
              "      <td>0.284899</td>\n",
              "      <td>202.029804</td>\n",
              "      <td>195.138133</td>\n",
              "      <td>0.112387</td>\n",
              "      <td>0.133193</td>\n",
              "      <td>0.124967</td>\n",
              "      <td>0.137827</td>\n",
              "      <td>0.067355</td>\n",
              "      <td>0.091949</td>\n",
              "      <td>0.116364</td>\n",
              "      <td>0.135954</td>\n",
              "      <td>0.107806</td>\n",
              "      <td>0.119747</td>\n",
              "      <td>0.085484</td>\n",
              "      <td>0.111064</td>\n",
              "      <td>1.560903</td>\n",
              "      <td>1.426243</td>\n",
              "      <td>1.494545</td>\n",
              "      <td>...</td>\n",
              "      <td>602.649622</td>\n",
              "      <td>439.884042</td>\n",
              "      <td>-0.004153</td>\n",
              "      <td>0.011023</td>\n",
              "      <td>34.941933</td>\n",
              "      <td>25.175854</td>\n",
              "      <td>43.097000</td>\n",
              "      <td>12.711806</td>\n",
              "      <td>43.801016</td>\n",
              "      <td>12.658951</td>\n",
              "      <td>42.269756</td>\n",
              "      <td>12.461383</td>\n",
              "      <td>43.981473</td>\n",
              "      <td>12.649683</td>\n",
              "      <td>44.579692</td>\n",
              "      <td>12.559669</td>\n",
              "      <td>42.498231</td>\n",
              "      <td>12.745170</td>\n",
              "      <td>23.924192</td>\n",
              "      <td>17.639455</td>\n",
              "      <td>0.366194</td>\n",
              "      <td>0.204146</td>\n",
              "      <td>920.532258</td>\n",
              "      <td>1.339412</td>\n",
              "      <td>4.375232</td>\n",
              "      <td>3.792356</td>\n",
              "      <td>4.608015</td>\n",
              "      <td>3.865457</td>\n",
              "      <td>3.910895</td>\n",
              "      <td>3.663162</td>\n",
              "      <td>3.663074</td>\n",
              "      <td>3.578209</td>\n",
              "      <td>4.659234</td>\n",
              "      <td>3.888751</td>\n",
              "      <td>16.759945</td>\n",
              "      <td>11.549429</td>\n",
              "      <td>0.731519</td>\n",
              "      <td>0.616226</td>\n",
              "      <td>0.002233</td>\n",
              "      <td>0.000316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>False</td>\n",
              "      <td>387.960192</td>\n",
              "      <td>0.409426</td>\n",
              "      <td>388.007500</td>\n",
              "      <td>0.417034</td>\n",
              "      <td>388.179412</td>\n",
              "      <td>0.463350</td>\n",
              "      <td>387.972308</td>\n",
              "      <td>0.322141</td>\n",
              "      <td>10.355311</td>\n",
              "      <td>6.557353</td>\n",
              "      <td>6.281731</td>\n",
              "      <td>0.128272</td>\n",
              "      <td>6.254808</td>\n",
              "      <td>0.122178</td>\n",
              "      <td>6.394510</td>\n",
              "      <td>0.158345</td>\n",
              "      <td>6.232115</td>\n",
              "      <td>0.122544</td>\n",
              "      <td>6.212692</td>\n",
              "      <td>0.108051</td>\n",
              "      <td>6.320980</td>\n",
              "      <td>0.125956</td>\n",
              "      <td>-3.641491</td>\n",
              "      <td>11.360723</td>\n",
              "      <td>0.189074</td>\n",
              "      <td>0.367933</td>\n",
              "      <td>0.223889</td>\n",
              "      <td>0.396120</td>\n",
              "      <td>0.251132</td>\n",
              "      <td>0.521878</td>\n",
              "      <td>0.096226</td>\n",
              "      <td>0.164273</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>0.061460</td>\n",
              "      <td>0.137547</td>\n",
              "      <td>0.223984</td>\n",
              "      <td>2.123333</td>\n",
              "      <td>1.332930</td>\n",
              "      <td>2.430556</td>\n",
              "      <td>...</td>\n",
              "      <td>23.872950</td>\n",
              "      <td>14.410629</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.288634</td>\n",
              "      <td>0.922698</td>\n",
              "      <td>79.133269</td>\n",
              "      <td>1.048734</td>\n",
              "      <td>79.767115</td>\n",
              "      <td>1.209087</td>\n",
              "      <td>80.626275</td>\n",
              "      <td>1.129525</td>\n",
              "      <td>79.944423</td>\n",
              "      <td>1.249513</td>\n",
              "      <td>80.828077</td>\n",
              "      <td>1.413270</td>\n",
              "      <td>79.624510</td>\n",
              "      <td>1.042705</td>\n",
              "      <td>0.097826</td>\n",
              "      <td>0.402653</td>\n",
              "      <td>0.002593</td>\n",
              "      <td>0.050252</td>\n",
              "      <td>922.190476</td>\n",
              "      <td>0.749603</td>\n",
              "      <td>3.362174</td>\n",
              "      <td>0.356684</td>\n",
              "      <td>3.348292</td>\n",
              "      <td>0.330918</td>\n",
              "      <td>3.099441</td>\n",
              "      <td>0.379461</td>\n",
              "      <td>2.895652</td>\n",
              "      <td>0.386139</td>\n",
              "      <td>3.355248</td>\n",
              "      <td>0.342563</td>\n",
              "      <td>1.173183</td>\n",
              "      <td>0.678359</td>\n",
              "      <td>0.019306</td>\n",
              "      <td>0.012448</td>\n",
              "      <td>0.000809</td>\n",
              "      <td>0.000029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>False</td>\n",
              "      <td>401.640476</td>\n",
              "      <td>2.052212</td>\n",
              "      <td>400.852097</td>\n",
              "      <td>2.884182</td>\n",
              "      <td>402.276032</td>\n",
              "      <td>2.138372</td>\n",
              "      <td>399.988095</td>\n",
              "      <td>3.766850</td>\n",
              "      <td>23.973636</td>\n",
              "      <td>15.873459</td>\n",
              "      <td>7.282063</td>\n",
              "      <td>0.124475</td>\n",
              "      <td>7.255968</td>\n",
              "      <td>0.109056</td>\n",
              "      <td>7.276667</td>\n",
              "      <td>0.186175</td>\n",
              "      <td>7.234286</td>\n",
              "      <td>0.089798</td>\n",
              "      <td>7.264444</td>\n",
              "      <td>0.080217</td>\n",
              "      <td>7.280952</td>\n",
              "      <td>0.156584</td>\n",
              "      <td>25.789554</td>\n",
              "      <td>20.438398</td>\n",
              "      <td>0.075882</td>\n",
              "      <td>0.098817</td>\n",
              "      <td>0.077612</td>\n",
              "      <td>0.120140</td>\n",
              "      <td>0.055882</td>\n",
              "      <td>0.071367</td>\n",
              "      <td>0.076324</td>\n",
              "      <td>0.095977</td>\n",
              "      <td>0.079706</td>\n",
              "      <td>0.107578</td>\n",
              "      <td>0.056029</td>\n",
              "      <td>0.075846</td>\n",
              "      <td>2.464559</td>\n",
              "      <td>0.992695</td>\n",
              "      <td>2.363134</td>\n",
              "      <td>...</td>\n",
              "      <td>50.787027</td>\n",
              "      <td>32.389768</td>\n",
              "      <td>0.007641</td>\n",
              "      <td>0.009717</td>\n",
              "      <td>4.949853</td>\n",
              "      <td>2.818664</td>\n",
              "      <td>93.052698</td>\n",
              "      <td>0.459285</td>\n",
              "      <td>93.185323</td>\n",
              "      <td>1.067821</td>\n",
              "      <td>92.862540</td>\n",
              "      <td>0.672007</td>\n",
              "      <td>92.602381</td>\n",
              "      <td>1.663037</td>\n",
              "      <td>93.300952</td>\n",
              "      <td>2.637512</td>\n",
              "      <td>92.714762</td>\n",
              "      <td>0.494714</td>\n",
              "      <td>4.368133</td>\n",
              "      <td>3.959107</td>\n",
              "      <td>0.043235</td>\n",
              "      <td>0.083227</td>\n",
              "      <td>907.428571</td>\n",
              "      <td>0.503953</td>\n",
              "      <td>3.229828</td>\n",
              "      <td>0.263632</td>\n",
              "      <td>3.259558</td>\n",
              "      <td>0.399445</td>\n",
              "      <td>3.190246</td>\n",
              "      <td>0.131051</td>\n",
              "      <td>3.131204</td>\n",
              "      <td>0.248498</td>\n",
              "      <td>3.287346</td>\n",
              "      <td>0.327367</td>\n",
              "      <td>1.978373</td>\n",
              "      <td>1.107727</td>\n",
              "      <td>0.050131</td>\n",
              "      <td>0.030889</td>\n",
              "      <td>0.002569</td>\n",
              "      <td>0.005078</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>430 rows Ã— 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     partlybad  CO2168.mean  CO2168.std  ...  UV_B.std   CS.mean    CS.std\n",
              "0        False   380.528120    0.802001  ...  0.123402  0.002546  0.000686\n",
              "1        False   373.128684    1.096617  ...  0.239981  0.000662  0.000210\n",
              "2        False   372.363293    0.626329  ...  0.344386  0.000541  0.000072\n",
              "3        False   381.437442    7.281159  ...  0.192014  0.003710  0.001209\n",
              "4        False   375.426310    3.264246  ...  0.476821  0.003680  0.002160\n",
              "..         ...          ...         ...  ...       ...       ...       ...\n",
              "425      False   389.310533    1.384881  ...  0.011991  0.006578  0.001036\n",
              "426      False   380.048926    6.127866  ...  0.368811  0.004581  0.000499\n",
              "427      False   392.901308    2.236589  ...  0.616226  0.002233  0.000316\n",
              "428      False   387.960192    0.409426  ...  0.012448  0.000809  0.000029\n",
              "429      False   401.640476    2.052212  ...  0.030889  0.002569  0.005078\n",
              "\n",
              "[430 rows x 101 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ahx40AwZk6s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f11473b-539e-432f-8a9e-feb24a62d87c"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      nonevent\n",
              "1         event\n",
              "2         event\n",
              "3      nonevent\n",
              "4         event\n",
              "         ...   \n",
              "425    nonevent\n",
              "426    nonevent\n",
              "427       event\n",
              "428    nonevent\n",
              "429    nonevent\n",
              "Name: class2, Length: 430, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVsAGZZw7kE4"
      },
      "source": [
        "## Part 2: Binary Classification (class2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FprRFaF7bV9G"
      },
      "source": [
        "### 1. Random forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mD3vG6m0bRyf"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)# Train the model on training data\n",
        "rf.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0orgDVx0cQ_q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c33ebc38-86ec-404b-9261-e5231ea55a2b"
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "\n",
        "print('Accuracy using Random Forest:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Random Forest: 0.8837209302325582 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYoUQZ9Tj2s1"
      },
      "source": [
        "#### Cross validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIUHnmrqeiLi",
        "outputId": "713df57d-5661-452b-b601-fbedf132dbe0"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "model = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "cv = cross_validate(model, X, y, cv=5)\n",
        "print(cv['test_score'])\n",
        "print('CV mean:', cv['test_score'].mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.87209302 0.8372093  0.90697674 0.89534884 0.88372093]\n",
            "CV mean: 0.8790697674418604\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiW4mf6Hktd2",
        "outputId": "06414b5e-87aa-4cec-e677-388d49bddd3a"
      },
      "source": [
        "cv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([2.39680147, 2.59758091, 2.4092412 , 2.39882398, 2.40196157]),\n",
              " 'score_time': array([0.077492  , 0.08913946, 0.07984233, 0.08653617, 0.07825947]),\n",
              " 'test_score': array([0.87209302, 0.8372093 , 0.90697674, 0.89534884, 0.88372093])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKdtYDUskeJL"
      },
      "source": [
        "### 2. SVM \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8c6d9OnXj7mU",
        "outputId": "bacf51b7-b778-45af-87be-ca0e9736ff0a"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVe0_Y0_kN-l",
        "outputId": "50e7a668-c1d7-4f76-9453-98f9cc115b45"
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = clf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "\n",
        "print('Accuracy using SVM:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using SVM: 0.7364341085271318 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxbpAcgjlAip"
      },
      "source": [
        "### 3. K nearest neighbour (k=3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkEGFOY-lDyD",
        "outputId": "dfec6d9a-1f03-42bf-86ca-5a15b197ac4f"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, y_train);\n",
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "print('Accuracy using 3 Nearest Neighbours:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using 3 Nearest Neighbours: 0.8837209302325582 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62AJZ8xAlhMs",
        "outputId": "22cdf2b2-380b-4b58-f40a-26d8ad62f6bb"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg_clf = LogisticRegression()\n",
        "logreg_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LH8CrmKanzy9",
        "outputId": "759bd5ac-a42f-48f4-9951-c534cd26b135"
      },
      "source": [
        "predictions = logreg_clf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "\n",
        "print('Accuracy using Logistic Regression:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Logistic Regression: 0.8682170542635659 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diuvrIux8lHZ"
      },
      "source": [
        "### 4. Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xD29yDSy95Ba",
        "outputId": "63e7f604-126d-4c2c-cd26-44b0d5343ee7"
      },
      "source": [
        "predictions = logreg_clf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "\n",
        "print('Accuracy using Logistic Regression:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Logistic Regression: 0.8682170542635659 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD6HgdYcqXHx"
      },
      "source": [
        "### 5. Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSpoUdPJqUNv",
        "outputId": "afc43c97-b34f-4aa2-e98a-4f4729fef7b8"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "predicitionsNB = gnb.predict(X_val)\n",
        "Accuracy = sum(predicitionsNB == y_val) / len(y_val)\n",
        "print('Accuracy using Naive Bayes:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Naive Bayes: 0.7596899224806202 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnpF3MGLr2Xt"
      },
      "source": [
        "#### Automated TPOT: \n",
        "TPOT does the tuning for us, trying out different models and different hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "cbc9ed05c6e146fb8943dbd4de897cbd",
            "8d79ef30a34c4c1b9da64701b46baa05",
            "79a719b7fc4f482a84ae421571913429",
            "da2dc85624a34867ae98a072cb00c99f",
            "5a6ae734fc35481d8f0e7244e9a8cee6",
            "93093641b42841bba062d4770440d839",
            "8976a6e2a8a9425fa602dd018cd10dba",
            "d0de6b9d8e2246faaa9db00847589f34"
          ]
        },
        "id": "PJgxSmIursDd",
        "outputId": "ae4ba2b3-fefd-46d5-8fa6-188822df1787"
      },
      "source": [
        "!pip install tpot\n",
        "from tpot import TPOTClassifier\n",
        "tpot = TPOTClassifier(generations=3, population_size=3, verbosity=2, max_eval_time_mins=1)\n",
        "tpot.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tpot in /usr/local/lib/python3.6/dist-packages (0.11.6.post2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.17.0)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.22.2.post1)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.41.1)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.90)\n",
            "Requirement already satisfied: update-checker>=0.16 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.18.0)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.1.4)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.4.1)\n",
            "Requirement already satisfied: deap>=1.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.3.1)\n",
            "Requirement already satisfied: stopit>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.1.2)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->tpot) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.11.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbc9ed05c6e146fb8943dbd4de897cbd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=12.0, style=ProgressStyle(desâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Generation 1 - Current best internal CV score: 0.867103825136612\n",
            "\n",
            "Generation 2 - Current best internal CV score: 0.867103825136612\n",
            "\n",
            "Generation 3 - Current best internal CV score: 0.8771584699453552\n",
            "\n",
            "Best pipeline: ExtraTreesClassifier(input_matrix, bootstrap=False, criterion=entropy, max_features=0.6500000000000001, min_samples_leaf=9, min_samples_split=13, n_estimators=100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "               disable_update_check=False, early_stop=None, generations=3,\n",
              "               log_file=None, max_eval_time_mins=1, max_time_mins=None,\n",
              "               memory=None, mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
              "               periodic_checkpoint_folder=None, population_size=3,\n",
              "               random_state=None, scoring=None, subsample=1.0, template=None,\n",
              "               use_dask=False, verbosity=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Auz4bOuvuYbn"
      },
      "source": [
        "#tpotPredictions = tpot.predict(X_val, y_val)\n",
        "#Accuracy = sum(tpotPredictions == y_val) / len(y_val)\n",
        "#print('Accuracy using tpot:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT0XlEyks3aw"
      },
      "source": [
        "### 6. Gradient boosting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1bZXUv80K_C"
      },
      "source": [
        "The gradient boosting classifier is not one that we have talked about in class. However, it was very useful in exploring this dataset and performed well against other classifiers. Gradient boosting produces a prediction model in the form of an ensemble of weaker prediction models. It builds this model in steps, generalizing them by allowing the optimization of a differentiable loss function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0MDjDPLis_Od",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1dbf1c7-2b97-4e14-9fb0-7f864103c35c"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GBOOSTmodel = GradientBoostingClassifier(learning_rate=0.5, max_depth=5, max_features=0.3, min_samples_leaf=9, min_samples_split=12, n_estimators=100, subsample=1.0)\n",
        "GBOOSTmodel.fit(X_train,y_train)\n",
        "predicitionsGBOOST = GBOOSTmodel.predict(X_val)\n",
        "Accuracy = sum(predicitionsGBOOST == y_val) / len(y_val)\n",
        "print('Accuracy using GradientBoosting:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using GradientBoosting: 0.9069767441860465 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-lW6JnwhTvs"
      },
      "source": [
        "#### Perplexity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBzKuRRMfjI3"
      },
      "source": [
        "# in R: perp <- function(p,y=data_test$y) exp(-mean(log(ifelse(y==1,p,1-p))))\n",
        "\n",
        "def perp(y): \n",
        "  math.exp(-stat.mean(math.log(y))) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "ew6jV8D5M8Si",
        "outputId": "c2421806-9b71-4b55-b4d5-003df965370b"
      },
      "source": [
        "list = [1, 2, 3]\n",
        "perp(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-465c3c6a240f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mperp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-f1975955a3b8>\u001b[0m in \u001b[0;36mperp\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: must be real number, not DataFrame"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFxWp3Pr-JER"
      },
      "source": [
        "#### Cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "851nfDaitzFM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "46bad331-e9ab-493e-8694-7ef84030a367"
      },
      "source": [
        "cv = cross_validate(GBOOSTmodel, X, y, cv=5)\n",
        "print(cv['test_score'])\n",
        "print('CV mean:', cv['test_score'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-45c2ae738b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGBOOSTmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV mean:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cross_validate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VohfAFfFSSCc"
      },
      "source": [
        "colNames_bin = X.columns\n",
        "predicitionsTEST = GBOOSTmodel.predict(df_test[colNames_bin])\n",
        "predicitionsTEST\n",
        "\n",
        "predictionsTest_prob = predicitionsTEST = GBOOSTmodel.predict_prob(df_test[colNames_bin])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEJCYYUrT3-U"
      },
      "source": [
        "## Part 3: Models for Multiclass Classification (class4) with forward boosting and PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn4bXiZL_Bv3"
      },
      "source": [
        "### Prepare dataset  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDGGuQkbTxn2"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "y = df_train[\"class4\"]\n",
        "X = df_train.drop([\"class4\",\"class2\",\"id\",\"date\"],axis = 1)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdZtq85klHFU"
      },
      "source": [
        "### K Best"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3iz3z3clVkz"
      },
      "source": [
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "ScaledX = X\n",
        "\n",
        "# build the scaler model\n",
        "scaler = MinMaxScaler()# fit using the train set\n",
        "scaler.fit(X)# transform the test\n",
        "X_scaled = scaler.transform(X)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-KexeKVqAlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03abbb7a-d39f-4ee0-f86a-7ce18894e493"
      },
      "source": [
        "X_scaled.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(430, 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR2GCK0bk9Kv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8220c287-4d12-4148-d4f7-803cfcb70149"
      },
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "X_new = SelectKBest(chi2, k=20).fit_transform(X_scaled, y)\n",
        "X_new.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(430, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWjj36t-Njd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec401f33-9c07-4989-fdfb-e8f293a4ac30"
      },
      "source": [
        "X_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.55150733, 0.45005321, 0.3977923 , ..., 0.0753645 , 0.36205052,\n",
              "        0.26177986],\n",
              "       [0.58910155, 0.43044118, 0.42267815, ..., 0.65118395, 0.56640982,\n",
              "        0.41112005],\n",
              "       [0.63054695, 0.625048  , 0.63488195, ..., 0.58873745, 0.62836782,\n",
              "        0.56422951],\n",
              "       ...,\n",
              "       [0.69593904, 0.68875742, 0.71615023, ..., 0.54209957, 0.73947074,\n",
              "        0.68292683],\n",
              "       [0.01571471, 0.01433313, 0.03562683, ..., 0.03463302, 0.03940765,\n",
              "        0.0302327 ],\n",
              "       [0.04796486, 0.04361971, 0.06924125, ..., 0.01086989, 0.07557193,\n",
              "        0.05601174]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqYncKPCxFCd"
      },
      "source": [
        "### PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5GwCrRpxCu3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5df63fe-1ac9-4f80-97e8-a07217b75806"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=10)\n",
        "fit = pca.fit(X)\n",
        "\n",
        "print(fit.components_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-8.60943804e-19 -1.43152400e-02  2.80409733e-03 ...  7.44393169e-04\n",
            "   8.42598717e-07  3.96058720e-07]\n",
            " [-4.11661774e-17 -4.08457770e-02  2.32214259e-02 ...  1.01431038e-03\n",
            "   4.28467848e-06  2.15087986e-06]\n",
            " [-1.22667664e-17  5.57286407e-02 -6.95684429e-03 ... -2.65887307e-04\n",
            "   3.95288157e-08  5.08145646e-07]\n",
            " ...\n",
            " [ 2.79703890e-16 -2.35853850e-01 -3.82608854e-02 ... -1.29678141e-03\n",
            "  -1.81546004e-05 -3.22584376e-06]\n",
            " [ 3.91091146e-17 -5.31806242e-02  4.72512763e-02 ...  9.96437602e-04\n",
            "   6.01978920e-05  6.91726251e-06]\n",
            " [-4.58120419e-16 -6.48907625e-02 -5.24364056e-02 ... -4.44916928e-04\n",
            "  -7.09187104e-05 -1.40604761e-05]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lm1Xg63UhJKC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53168989-5637-43cd-fe73-a3d36bd902bd"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      nonevent\n",
              "1            Ib\n",
              "2            Ib\n",
              "3      nonevent\n",
              "4            II\n",
              "         ...   \n",
              "425    nonevent\n",
              "426    nonevent\n",
              "427          Ib\n",
              "428    nonevent\n",
              "429    nonevent\n",
              "Name: class4, Length: 430, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDGWwUZOyvPI"
      },
      "source": [
        "### Collect accuracies after feature selection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1Pv7c0trjSO"
      },
      "source": [
        "### Function that will be used in order to get accuracies for a model with selected features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoeuHEfdibCk"
      },
      "source": [
        "# Build full model with selected features\n",
        "def GetAccuracies(model,SelectedFeatures):\n",
        "  clf = model\n",
        "  feat_cols = SelectedFeatures\n",
        "  clf.fit(X_train.iloc[:, feat_cols], y_train)\n",
        "\n",
        "  y_train_pred = clf.predict(X_train.iloc[:, feat_cols])\n",
        "  TrainAcc = acc(y_train, y_train_pred)\n",
        "\n",
        "  print('Train Accuracy using RF with forward features selection:',TrainAcc,'%')\n",
        "\n",
        "  predictions = clf.predict(X_val.iloc[:, feat_cols])# Calculate the absolute errors\n",
        "  ValAccuracy = sum(predictions == y_val) / len(y_val)\n",
        "\n",
        "  print('Val Accuracy with forward features selection:',ValAccuracy,'%')\n",
        "\n",
        "  #Cross Validation\n",
        "  cv = cross_validate(model, X.iloc[:, feat_cols], y, cv=5)\n",
        "  print(\"Cross validation test scores: \",cv['test_score'])\n",
        "  print('CV mean:', cv['test_score'].mean())\n",
        "  return ([TrainAcc,ValAccuracy,cv['test_score'].mean()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9TjsE8RUG2E"
      },
      "source": [
        "### 1. Random forest\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2TlQhvfUG2F"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier# Instantiate model with 1000 decision trees\n",
        "rf = RandomForestClassifier(n_estimators = 1000, random_state = 42)# Train the model on training data\n",
        "rf.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbvexMWvUG2G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687fab89-fbb2-43ae-a0f7-c5f14b2063e1"
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = rf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "\n",
        "print('Accuracy using Random Forest:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Random Forest: 0.6434108527131783 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYjJqr-RUG2M"
      },
      "source": [
        "#### Cross validation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFov7xpZUG2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a860b4-33f3-4df2-9acf-29387aedfead"
      },
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "model = RandomForestClassifier(n_estimators = 1000, random_state = 42)\n",
        "cv = cross_validate(model, X, y, cv=5)\n",
        "print(cv['test_score'])\n",
        "print('CV mean:', cv['test_score'].mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.62790698 0.65116279 0.68604651 0.6627907  0.6627907 ]\n",
            "CV mean: 0.6581395348837209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqwT4J_PsZqD"
      },
      "source": [
        "#### Forward features selection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8RPdMwzNglY",
        "outputId": "e8e06781-23af-4fca-f3e2-908422fa5a76"
      },
      "source": [
        "from sklearn.metrics import accuracy_score as acc\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
        "\n",
        "# Build RF classifier to use in feature selection\n",
        "clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs1 = sfs(clf,\n",
        "           k_features=7,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs1 = sfs1.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 101 out of 101 | elapsed:  2.7min finished\n",
            "\n",
            "[2020-12-06 12:31:25] Features: 1/7 -- score: 0.5446448087431695[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.7s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  2.7min finished\n",
            "\n",
            "[2020-12-06 12:34:04] Features: 2/7 -- score: 0.6545355191256831[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:  2.6min finished\n",
            "\n",
            "[2020-12-06 12:36:40] Features: 3/7 -- score: 0.6776502732240437[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:  2.6min finished\n",
            "\n",
            "[2020-12-06 12:39:18] Features: 4/7 -- score: 0.68775956284153[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:  2.6min finished\n",
            "\n",
            "[2020-12-06 12:41:55] Features: 5/7 -- score: 0.6975956284153005[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:  2.6min finished\n",
            "\n",
            "[2020-12-06 12:44:29] Features: 6/7 -- score: 0.6975956284153005[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.6s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  95 out of  95 | elapsed:  2.5min finished\n",
            "\n",
            "[2020-12-06 12:47:02] Features: 7/7 -- score: 0.7143169398907104"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4ZQ03M5t1wC",
        "outputId": "181d426c-7e8e-4bff-b68e-4cd6c72d6260"
      },
      "source": [
        "pd.DataFrame.from_dict(sfs1.get_metric_dict()).T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_idx</th>\n",
              "      <th>cv_scores</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>feature_names</th>\n",
              "      <th>ci_bound</th>\n",
              "      <th>std_dev</th>\n",
              "      <th>std_err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(95,)</td>\n",
              "      <td>[0.6065573770491803, 0.5166666666666667, 0.566...</td>\n",
              "      <td>0.544645</td>\n",
              "      <td>(UV_A.mean,)</td>\n",
              "      <td>0.0620849</td>\n",
              "      <td>0.0483042</td>\n",
              "      <td>0.0241521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(21, 95)</td>\n",
              "      <td>[0.639344262295082, 0.65, 0.75, 0.583333333333...</td>\n",
              "      <td>0.654536</td>\n",
              "      <td>(H2O84.mean, UV_A.mean)</td>\n",
              "      <td>0.0691079</td>\n",
              "      <td>0.0537683</td>\n",
              "      <td>0.0268841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(21, 75, 95)</td>\n",
              "      <td>[0.7049180327868853, 0.7166666666666667, 0.733...</td>\n",
              "      <td>0.67765</td>\n",
              "      <td>(H2O84.mean, RHIRGA672.mean, UV_A.mean)</td>\n",
              "      <td>0.0766973</td>\n",
              "      <td>0.0596731</td>\n",
              "      <td>0.0298366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(17, 21, 75, 95)</td>\n",
              "      <td>[0.6721311475409836, 0.7, 0.75, 0.65, 0.666666...</td>\n",
              "      <td>0.68776</td>\n",
              "      <td>(H2O504.mean, H2O84.mean, RHIRGA672.mean, UV_A...</td>\n",
              "      <td>0.0450353</td>\n",
              "      <td>0.035039</td>\n",
              "      <td>0.0175195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(17, 21, 70, 75, 95)</td>\n",
              "      <td>[0.7213114754098361, 0.75, 0.7166666666666667,...</td>\n",
              "      <td>0.697596</td>\n",
              "      <td>(H2O504.mean, H2O84.mean, RHIRGA336.std, RHIRG...</td>\n",
              "      <td>0.053794</td>\n",
              "      <td>0.0418536</td>\n",
              "      <td>0.0209268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(17, 21, 25, 70, 75, 95)</td>\n",
              "      <td>[0.7213114754098361, 0.7666666666666667, 0.733...</td>\n",
              "      <td>0.697596</td>\n",
              "      <td>(H2O504.mean, H2O84.mean, NO168.mean, RHIRGA33...</td>\n",
              "      <td>0.0713893</td>\n",
              "      <td>0.0555433</td>\n",
              "      <td>0.0277716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(17, 18, 21, 25, 70, 75, 95)</td>\n",
              "      <td>[0.7049180327868853, 0.8166666666666667, 0.716...</td>\n",
              "      <td>0.714317</td>\n",
              "      <td>(H2O504.mean, H2O504.std, H2O84.mean, NO168.me...</td>\n",
              "      <td>0.081513</td>\n",
              "      <td>0.0634199</td>\n",
              "      <td>0.03171</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    feature_idx  ...    std_err\n",
              "1                         (95,)  ...  0.0241521\n",
              "2                      (21, 95)  ...  0.0268841\n",
              "3                  (21, 75, 95)  ...  0.0298366\n",
              "4              (17, 21, 75, 95)  ...  0.0175195\n",
              "5          (17, 21, 70, 75, 95)  ...  0.0209268\n",
              "6      (17, 21, 25, 70, 75, 95)  ...  0.0277716\n",
              "7  (17, 18, 21, 25, 70, 75, 95)  ...    0.03171\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rffVvH6ymsQ0",
        "outputId": "3ee781fe-5eba-4c60-c00e-07010f2bcc11"
      },
      "source": [
        "feat_cols_RF_Forward = list(sfs1.k_feature_idx_)\n",
        "print(feat_cols_RF_Forward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[17, 18, 21, 25, 70, 75, 95]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kND9x44GpNly",
        "outputId": "3fd79889-7f8c-4b4a-c68a-e4bc3b25fc17"
      },
      "source": [
        "# Get Accuracy with Forward Selection\n",
        "RF = RandomForestClassifier(n_estimators=100, random_state=100)\n",
        "GetAccuracies(RF,feat_cols_RF_Forward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy using RF with forward features selection: 1.0 %\n",
            "Val Accuracy with forward features selection: 0.6511627906976745 %\n",
            "Cross validation test scores:  [0.61627907 0.6627907  0.61627907 0.6744186  0.69767442]\n",
            "CV mean: 0.6534883720930232\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0, 0.6511627906976745, 0.6534883720930232]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOOl7dc8UrXF"
      },
      "source": [
        "### 2. SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNQDtY2xUrXG",
        "outputId": "c08dcfb6-72e3-4ef3-cc8a-ce639e16dd83"
      },
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
              "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
              "    tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ho7-DB2UrXH",
        "outputId": "7a5f1d9e-3fff-478f-e4b4-132ec4b5e8af"
      },
      "source": [
        "# Use the forest's predict method on the test data\n",
        "predictions = clf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "\n",
        "print('Accuracy using SVM:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using SVM: 0.5581395348837209 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z88e7g_f_yV2"
      },
      "source": [
        "#### Forward selection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_G1zB6azHlI",
        "outputId": "0c0f2e99-1d92-4003-8ba5-1a8cf3cdd128"
      },
      "source": [
        "from sklearn.metrics import accuracy_score as acc\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
        "\n",
        "# Build SVM classifier to use in feature selection\n",
        "clf =  svm.SVC()\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs1 = sfs(clf,\n",
        "           k_features=20,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs1 = sfs1.fit(X_train, y_train)\n",
        "pd.DataFrame.from_dict(sfs1.get_metric_dict()).T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 101 out of 101 | elapsed:    3.0s finished\n",
            "\n",
            "[2020-12-06 12:47:06] Features: 1/20 -- score: 0.5981420765027321[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.5s finished\n",
            "\n",
            "[2020-12-06 12:47:08] Features: 2/20 -- score: 0.6314207650273225[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:    2.4s finished\n",
            "\n",
            "[2020-12-06 12:47:11] Features: 3/20 -- score: 0.6680327868852458[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:    2.4s finished\n",
            "\n",
            "[2020-12-06 12:47:13] Features: 4/20 -- score: 0.6746994535519126[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:    2.4s finished\n",
            "\n",
            "[2020-12-06 12:47:15] Features: 5/20 -- score: 0.6744808743169399[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:    2.5s finished\n",
            "\n",
            "[2020-12-06 12:47:18] Features: 6/20 -- score: 0.67775956284153[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  95 out of  95 | elapsed:    2.4s finished\n",
            "\n",
            "[2020-12-06 12:47:20] Features: 7/20 -- score: 0.67775956284153[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  94 out of  94 | elapsed:    2.4s finished\n",
            "\n",
            "[2020-12-06 12:47:23] Features: 8/20 -- score: 0.6744262295081968[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  93 out of  93 | elapsed:    2.5s finished\n",
            "\n",
            "[2020-12-06 12:47:25] Features: 9/20 -- score: 0.6744262295081968[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  92 out of  92 | elapsed:    2.5s finished\n",
            "\n",
            "[2020-12-06 12:47:28] Features: 10/20 -- score: 0.6777049180327869[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  91 out of  91 | elapsed:    2.6s finished\n",
            "\n",
            "[2020-12-06 12:47:30] Features: 11/20 -- score: 0.6743715846994535[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:    2.5s finished\n",
            "\n",
            "[2020-12-06 12:47:33] Features: 12/20 -- score: 0.6776502732240436[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  89 out of  89 | elapsed:    2.6s finished\n",
            "\n",
            "[2020-12-06 12:47:36] Features: 13/20 -- score: 0.6743715846994536[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  88 out of  88 | elapsed:    2.6s finished\n",
            "\n",
            "[2020-12-06 12:47:38] Features: 14/20 -- score: 0.6710382513661203[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  87 out of  87 | elapsed:    2.6s finished\n",
            "\n",
            "[2020-12-06 12:47:41] Features: 15/20 -- score: 0.6710382513661203[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  86 out of  86 | elapsed:    2.7s finished\n",
            "\n",
            "[2020-12-06 12:47:43] Features: 16/20 -- score: 0.6710382513661202[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  85 out of  85 | elapsed:    2.7s finished\n",
            "\n",
            "[2020-12-06 12:47:46] Features: 17/20 -- score: 0.6743715846994535[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  84 out of  84 | elapsed:    2.7s finished\n",
            "\n",
            "[2020-12-06 12:47:49] Features: 18/20 -- score: 0.6743715846994535[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  83 out of  83 | elapsed:    2.6s finished\n",
            "\n",
            "[2020-12-06 12:47:51] Features: 19/20 -- score: 0.6743715846994535[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  82 out of  82 | elapsed:    2.6s finished\n",
            "\n",
            "[2020-12-06 12:47:54] Features: 20/20 -- score: 0.6710928961748633"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_idx</th>\n",
              "      <th>cv_scores</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>feature_names</th>\n",
              "      <th>ci_bound</th>\n",
              "      <th>std_dev</th>\n",
              "      <th>std_err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(72,)</td>\n",
              "      <td>[0.5573770491803278, 0.5833333333333334, 0.533...</td>\n",
              "      <td>0.598142</td>\n",
              "      <td>(RHIRGA42.std,)</td>\n",
              "      <td>0.0667018</td>\n",
              "      <td>0.0518963</td>\n",
              "      <td>0.0259481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(72, 85)</td>\n",
              "      <td>[0.5737704918032787, 0.7, 0.65, 0.583333333333...</td>\n",
              "      <td>0.631421</td>\n",
              "      <td>(RHIRGA42.std, T168.mean)</td>\n",
              "      <td>0.0603661</td>\n",
              "      <td>0.0469669</td>\n",
              "      <td>0.0234834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(66, 72, 85)</td>\n",
              "      <td>[0.5901639344262295, 0.7333333333333333, 0.683...</td>\n",
              "      <td>0.668033</td>\n",
              "      <td>(RGlob.std, RHIRGA42.std, T168.mean)</td>\n",
              "      <td>0.0606165</td>\n",
              "      <td>0.0471617</td>\n",
              "      <td>0.0235808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(66, 72, 78, 85)</td>\n",
              "      <td>[0.5901639344262295, 0.7333333333333333, 0.683...</td>\n",
              "      <td>0.674699</td>\n",
              "      <td>(RGlob.std, RHIRGA42.std, RHIRGA84.std, T168.m...</td>\n",
              "      <td>0.0597565</td>\n",
              "      <td>0.0464926</td>\n",
              "      <td>0.0232463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(66, 72, 78, 79, 85)</td>\n",
              "      <td>[0.6557377049180327, 0.7, 0.65, 0.633333333333...</td>\n",
              "      <td>0.674481</td>\n",
              "      <td>(RGlob.std, RHIRGA42.std, RHIRGA84.std, RPAR.m...</td>\n",
              "      <td>0.0472546</td>\n",
              "      <td>0.0367657</td>\n",
              "      <td>0.0183828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(0, 66, 72, 78, 79, 85)</td>\n",
              "      <td>[0.6721311475409836, 0.7166666666666667, 0.65,...</td>\n",
              "      <td>0.67776</td>\n",
              "      <td>(partlybad, RGlob.std, RHIRGA42.std, RHIRGA84....</td>\n",
              "      <td>0.0549432</td>\n",
              "      <td>0.0427477</td>\n",
              "      <td>0.0213738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(0, 56, 66, 72, 78, 79, 85)</td>\n",
              "      <td>[0.6721311475409836, 0.7166666666666667, 0.65,...</td>\n",
              "      <td>0.67776</td>\n",
              "      <td>(partlybad, O3672.std, RGlob.std, RHIRGA42.std...</td>\n",
              "      <td>0.0437886</td>\n",
              "      <td>0.034069</td>\n",
              "      <td>0.0170345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(0, 2, 56, 66, 72, 78, 79, 85)</td>\n",
              "      <td>[0.6721311475409836, 0.7166666666666667, 0.633...</td>\n",
              "      <td>0.674426</td>\n",
              "      <td>(partlybad, CO2168.std, O3672.std, RGlob.std, ...</td>\n",
              "      <td>0.0479227</td>\n",
              "      <td>0.0372855</td>\n",
              "      <td>0.0186427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(0, 2, 54, 56, 66, 72, 78, 79, 85)</td>\n",
              "      <td>[0.6721311475409836, 0.7166666666666667, 0.633...</td>\n",
              "      <td>0.674426</td>\n",
              "      <td>(partlybad, CO2168.std, O3504.std, O3672.std, ...</td>\n",
              "      <td>0.0479227</td>\n",
              "      <td>0.0372855</td>\n",
              "      <td>0.0186427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(0, 2, 54, 56, 66, 72, 78, 79, 85, 96)</td>\n",
              "      <td>[0.6885245901639344, 0.7166666666666667, 0.633...</td>\n",
              "      <td>0.677705</td>\n",
              "      <td>(partlybad, CO2168.std, O3504.std, O3672.std, ...</td>\n",
              "      <td>0.048402</td>\n",
              "      <td>0.0376584</td>\n",
              "      <td>0.0188292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(0, 2, 50, 54, 56, 66, 72, 78, 79, 85, 96)</td>\n",
              "      <td>[0.6885245901639344, 0.7166666666666667, 0.633...</td>\n",
              "      <td>0.674372</td>\n",
              "      <td>(partlybad, CO2168.std, O3168.std, O3504.std, ...</td>\n",
              "      <td>0.0445767</td>\n",
              "      <td>0.0346822</td>\n",
              "      <td>0.0173411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(0, 2, 50, 54, 56, 66, 72, 78, 79, 85, 95, 96)</td>\n",
              "      <td>[0.7049180327868853, 0.7166666666666667, 0.633...</td>\n",
              "      <td>0.67765</td>\n",
              "      <td>(partlybad, CO2168.std, O3168.std, O3504.std, ...</td>\n",
              "      <td>0.0470259</td>\n",
              "      <td>0.0365877</td>\n",
              "      <td>0.0182939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(0, 2, 50, 54, 56, 66, 68, 72, 78, 79, 85, 95,...</td>\n",
              "      <td>[0.6885245901639344, 0.7, 0.6333333333333333, ...</td>\n",
              "      <td>0.674372</td>\n",
              "      <td>(partlybad, CO2168.std, O3168.std, O3504.std, ...</td>\n",
              "      <td>0.0445767</td>\n",
              "      <td>0.0346822</td>\n",
              "      <td>0.0173411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(0, 2, 37, 50, 54, 56, 66, 68, 72, 78, 79, 85,...</td>\n",
              "      <td>[0.6885245901639344, 0.6833333333333333, 0.633...</td>\n",
              "      <td>0.671038</td>\n",
              "      <td>(partlybad, CO2168.std, NOx168.mean, O3168.std...</td>\n",
              "      <td>0.0421694</td>\n",
              "      <td>0.0328092</td>\n",
              "      <td>0.0164046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(0, 2, 37, 50, 54, 56, 66, 68, 72, 78, 79, 85,...</td>\n",
              "      <td>[0.6885245901639344, 0.6833333333333333, 0.633...</td>\n",
              "      <td>0.671038</td>\n",
              "      <td>(partlybad, CO2168.std, NOx168.mean, O3168.std...</td>\n",
              "      <td>0.0421694</td>\n",
              "      <td>0.0328092</td>\n",
              "      <td>0.0164046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(0, 2, 37, 50, 54, 56, 66, 68, 72, 78, 79, 85,...</td>\n",
              "      <td>[0.6885245901639344, 0.7, 0.6333333333333333, ...</td>\n",
              "      <td>0.671038</td>\n",
              "      <td>(partlybad, CO2168.std, NOx168.mean, O3168.std...</td>\n",
              "      <td>0.0399337</td>\n",
              "      <td>0.0310698</td>\n",
              "      <td>0.0155349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(0, 2, 4, 37, 50, 54, 56, 66, 68, 72, 78, 79, ...</td>\n",
              "      <td>[0.6885245901639344, 0.7, 0.65, 0.633333333333...</td>\n",
              "      <td>0.674372</td>\n",
              "      <td>(partlybad, CO2168.std, CO2336.std, NOx168.mea...</td>\n",
              "      <td>0.0353959</td>\n",
              "      <td>0.0275392</td>\n",
              "      <td>0.0137696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(0, 2, 4, 37, 39, 50, 54, 56, 66, 68, 72, 78, ...</td>\n",
              "      <td>[0.6885245901639344, 0.7, 0.65, 0.633333333333...</td>\n",
              "      <td>0.674372</td>\n",
              "      <td>(partlybad, CO2168.std, CO2336.std, NOx168.mea...</td>\n",
              "      <td>0.0353959</td>\n",
              "      <td>0.0275392</td>\n",
              "      <td>0.0137696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>(0, 2, 4, 37, 39, 50, 52, 54, 56, 66, 68, 72, ...</td>\n",
              "      <td>[0.6885245901639344, 0.7, 0.65, 0.633333333333...</td>\n",
              "      <td>0.674372</td>\n",
              "      <td>(partlybad, CO2168.std, CO2336.std, NOx168.mea...</td>\n",
              "      <td>0.0353959</td>\n",
              "      <td>0.0275392</td>\n",
              "      <td>0.0137696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>(0, 2, 4, 12, 37, 39, 50, 52, 54, 56, 66, 68, ...</td>\n",
              "      <td>[0.6721311475409836, 0.7, 0.65, 0.633333333333...</td>\n",
              "      <td>0.671093</td>\n",
              "      <td>(partlybad, CO2168.std, CO2336.std, H2O168.std...</td>\n",
              "      <td>0.0342139</td>\n",
              "      <td>0.0266196</td>\n",
              "      <td>0.0133098</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          feature_idx  ...    std_err\n",
              "1                                               (72,)  ...  0.0259481\n",
              "2                                            (72, 85)  ...  0.0234834\n",
              "3                                        (66, 72, 85)  ...  0.0235808\n",
              "4                                    (66, 72, 78, 85)  ...  0.0232463\n",
              "5                                (66, 72, 78, 79, 85)  ...  0.0183828\n",
              "6                             (0, 66, 72, 78, 79, 85)  ...  0.0213738\n",
              "7                         (0, 56, 66, 72, 78, 79, 85)  ...  0.0170345\n",
              "8                      (0, 2, 56, 66, 72, 78, 79, 85)  ...  0.0186427\n",
              "9                  (0, 2, 54, 56, 66, 72, 78, 79, 85)  ...  0.0186427\n",
              "10             (0, 2, 54, 56, 66, 72, 78, 79, 85, 96)  ...  0.0188292\n",
              "11         (0, 2, 50, 54, 56, 66, 72, 78, 79, 85, 96)  ...  0.0173411\n",
              "12     (0, 2, 50, 54, 56, 66, 72, 78, 79, 85, 95, 96)  ...  0.0182939\n",
              "13  (0, 2, 50, 54, 56, 66, 68, 72, 78, 79, 85, 95,...  ...  0.0173411\n",
              "14  (0, 2, 37, 50, 54, 56, 66, 68, 72, 78, 79, 85,...  ...  0.0164046\n",
              "15  (0, 2, 37, 50, 54, 56, 66, 68, 72, 78, 79, 85,...  ...  0.0164046\n",
              "16  (0, 2, 37, 50, 54, 56, 66, 68, 72, 78, 79, 85,...  ...  0.0155349\n",
              "17  (0, 2, 4, 37, 50, 54, 56, 66, 68, 72, 78, 79, ...  ...  0.0137696\n",
              "18  (0, 2, 4, 37, 39, 50, 54, 56, 66, 68, 72, 78, ...  ...  0.0137696\n",
              "19  (0, 2, 4, 37, 39, 50, 52, 54, 56, 66, 68, 72, ...  ...  0.0137696\n",
              "20  (0, 2, 4, 12, 37, 39, 50, 52, 54, 56, 66, 68, ...  ...  0.0133098\n",
              "\n",
              "[20 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upSsKCK90Aq3",
        "outputId": "b00fb2ff-a877-4497-8792-ccae29cd606f"
      },
      "source": [
        "# Get Accuracy with Forward Selection\n",
        "feat_cols_SVM_Forward = list(sfs1.k_feature_idx_)\n",
        "SVM_Model = clf =  svm.SVC()\n",
        "GetAccuracies(SVM_Model,feat_cols_SVM_Forward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy using RF with forward features selection: 0.6976744186046512 %\n",
            "Val Accuracy with forward features selection: 0.627906976744186 %\n",
            "Cross validation test scores:  [0.65116279 0.75581395 0.6744186  0.59302326 0.62790698]\n",
            "CV mean: 0.6604651162790699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6976744186046512, 0.627906976744186, 0.6604651162790699]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSnp2VlKU0jr"
      },
      "source": [
        "### 3. K nearest neighbour"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da5bHXO_U0js",
        "outputId": "cc8813a8-7f9d-4a94-d1fd-b3f5e2dac924"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "neigh.fit(X_train, y_train);\n",
        "# predict on the test data\n",
        "predictions = rf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "print('Accuracy using 3 Nearest Neighbours:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using 3 Nearest Neighbours: 0.6434108527131783 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prPey0Nh2IIw"
      },
      "source": [
        "### 4. Logistric regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlfcA7byU0jt",
        "outputId": "3213be81-a7d7-47f3-83f8-d1c813f9ae59"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg_clf = LogisticRegression()\n",
        "logreg_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning:\n",
            "\n",
            "lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H-Jcj5EU0ju",
        "outputId": "9969b230-c6ad-4bf1-9aa3-542579c89217"
      },
      "source": [
        "predictions = logreg_clf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "\n",
        "print('Accuracy using Logistic Regression:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Logistic Regression: 0.6434108527131783 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pltsOd-BBQjM"
      },
      "source": [
        "#### Forward selection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knH7mqSW1DDU",
        "outputId": "da7a7cfd-d81d-406c-ca19-6a6557e1e8d0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score as acc\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
        "\n",
        "# Build Kneighbours classifier to use in feature selection\n",
        "clf = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs1 = sfs(clf,\n",
        "           k_features=5,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs1 = sfs1.fit(X_train, y_train)\n",
        "pd.DataFrame.from_dict(sfs1.get_metric_dict()).T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 101 out of 101 | elapsed:    2.0s finished\n",
            "\n",
            "[2020-12-06 12:47:56] Features: 1/5 -- score: 0.5845901639344262[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    2.1s finished\n",
            "\n",
            "[2020-12-06 12:47:59] Features: 2/5 -- score: 0.6247540983606557[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:    2.1s finished\n",
            "\n",
            "[2020-12-06 12:48:01] Features: 3/5 -- score: 0.6379781420765027[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:    2.1s finished\n",
            "\n",
            "[2020-12-06 12:48:03] Features: 4/5 -- score: 0.6413114754098361[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:    2.1s finished\n",
            "\n",
            "[2020-12-06 12:48:05] Features: 5/5 -- score: 0.6413114754098361"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_idx</th>\n",
              "      <th>cv_scores</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>feature_names</th>\n",
              "      <th>ci_bound</th>\n",
              "      <th>std_dev</th>\n",
              "      <th>std_err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(69,)</td>\n",
              "      <td>[0.6229508196721312, 0.5833333333333334, 0.516...</td>\n",
              "      <td>0.58459</td>\n",
              "      <td>(RHIRGA336.mean,)</td>\n",
              "      <td>0.0465611</td>\n",
              "      <td>0.0362261</td>\n",
              "      <td>0.018113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(69, 83)</td>\n",
              "      <td>[0.5737704918032787, 0.5666666666666667, 0.633...</td>\n",
              "      <td>0.624754</td>\n",
              "      <td>(RHIRGA336.mean, SWS.mean)</td>\n",
              "      <td>0.0638684</td>\n",
              "      <td>0.0496918</td>\n",
              "      <td>0.0248459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(41, 69, 83)</td>\n",
              "      <td>[0.6065573770491803, 0.5666666666666667, 0.633...</td>\n",
              "      <td>0.637978</td>\n",
              "      <td>(NOx42.mean, RHIRGA336.mean, SWS.mean)</td>\n",
              "      <td>0.0629608</td>\n",
              "      <td>0.0489856</td>\n",
              "      <td>0.0244928</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(40, 41, 69, 83)</td>\n",
              "      <td>[0.6065573770491803, 0.5666666666666667, 0.65,...</td>\n",
              "      <td>0.641311</td>\n",
              "      <td>(NOx336.std, NOx42.mean, RHIRGA336.mean, SWS.m...</td>\n",
              "      <td>0.0631374</td>\n",
              "      <td>0.049123</td>\n",
              "      <td>0.0245615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(0, 40, 41, 69, 83)</td>\n",
              "      <td>[0.6065573770491803, 0.5666666666666667, 0.65,...</td>\n",
              "      <td>0.641311</td>\n",
              "      <td>(partlybad, NOx336.std, NOx42.mean, RHIRGA336....</td>\n",
              "      <td>0.0631374</td>\n",
              "      <td>0.049123</td>\n",
              "      <td>0.0245615</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           feature_idx  ...    std_err\n",
              "1                (69,)  ...   0.018113\n",
              "2             (69, 83)  ...  0.0248459\n",
              "3         (41, 69, 83)  ...  0.0244928\n",
              "4     (40, 41, 69, 83)  ...  0.0245615\n",
              "5  (0, 40, 41, 69, 83)  ...  0.0245615\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5G7UTEmh1zRI",
        "outputId": "5f987961-f200-48ae-f07e-29f81cd25042"
      },
      "source": [
        "# Get Accuracy with Forward Selection\n",
        "feat_cols_KNegihb_Forward = list(sfs1.k_feature_idx_)\n",
        "SVM_Model  =  KNeighborsClassifier(n_neighbors=3)\n",
        "GetAccuracies(SVM_Model,feat_cols_KNegihb_Forward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy using RF with forward features selection: 0.770764119601329 %\n",
            "Val Accuracy with forward features selection: 0.5503875968992248 %\n",
            "Cross validation test scores:  [0.61627907 0.58139535 0.60465116 0.51162791 0.61627907]\n",
            "CV mean: 0.586046511627907\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.770764119601329, 0.5503875968992248, 0.586046511627907]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Ai8RyqU9Hh"
      },
      "source": [
        "### 5. Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTtYZQHxU9Hh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8392706f-b9c0-4d2c-d2cd-7857f02a72ee"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "predicitionsNB = gnb.predict(X_val)\n",
        "Accuracy = sum(predicitionsNB == y_val) / len(y_val)\n",
        "print('Accuracy using Naive Bayes:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using Naive Bayes: 0.4806201550387597 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbE6cr_ZBXH7"
      },
      "source": [
        "#### Forward selection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqtS2vEBVAhD",
        "outputId": "640f3897-00bf-4493-d1f7-2b7eb3d16fc9"
      },
      "source": [
        "from sklearn.metrics import accuracy_score as acc\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
        "\n",
        "# Build Kneighbours classifier to use in feature selection\n",
        "clf = GaussianNB()\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs1 = sfs(clf,\n",
        "           k_features=7,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs1 = sfs1.fit(X_train, y_train)\n",
        "pd.DataFrame.from_dict(sfs1.get_metric_dict()).T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:450: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:452: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:450: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:452: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:450: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:452: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:450: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:452: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:450: RuntimeWarning:\n",
            "\n",
            "divide by zero encountered in log\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:452: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in true_divide\n",
            "\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 101 out of 101 | elapsed:    1.0s finished\n",
            "\n",
            "[2020-12-06 12:48:06] Features: 1/7 -- score: 0.5947540983606557[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    1.0s finished\n",
            "\n",
            "[2020-12-06 12:48:07] Features: 2/7 -- score: 0.6146994535519126[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  99 out of  99 | elapsed:    1.1s finished\n",
            "\n",
            "[2020-12-06 12:48:08] Features: 3/7 -- score: 0.6345901639344262[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  98 out of  98 | elapsed:    1.1s finished\n",
            "\n",
            "[2020-12-06 12:48:09] Features: 4/7 -- score: 0.63775956284153[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  97 out of  97 | elapsed:    1.1s finished\n",
            "\n",
            "[2020-12-06 12:48:10] Features: 5/7 -- score: 0.6411475409836066[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  96 out of  96 | elapsed:    1.0s finished\n",
            "\n",
            "[2020-12-06 12:48:11] Features: 6/7 -- score: 0.65775956284153[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  95 out of  95 | elapsed:    1.0s finished\n",
            "\n",
            "[2020-12-06 12:48:12] Features: 7/7 -- score: 0.65775956284153"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature_idx</th>\n",
              "      <th>cv_scores</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>feature_names</th>\n",
              "      <th>ci_bound</th>\n",
              "      <th>std_dev</th>\n",
              "      <th>std_err</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(78,)</td>\n",
              "      <td>[0.5737704918032787, 0.6, 0.5166666666666667, ...</td>\n",
              "      <td>0.594754</td>\n",
              "      <td>(RHIRGA84.std,)</td>\n",
              "      <td>0.0605751</td>\n",
              "      <td>0.0471295</td>\n",
              "      <td>0.0235647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(78, 79)</td>\n",
              "      <td>[0.5901639344262295, 0.65, 0.5833333333333334,...</td>\n",
              "      <td>0.614699</td>\n",
              "      <td>(RHIRGA84.std, RPAR.mean)</td>\n",
              "      <td>0.0324293</td>\n",
              "      <td>0.0252311</td>\n",
              "      <td>0.0126156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(78, 79, 99)</td>\n",
              "      <td>[0.6229508196721312, 0.6833333333333333, 0.666...</td>\n",
              "      <td>0.63459</td>\n",
              "      <td>(RHIRGA84.std, RPAR.mean, CS.mean)</td>\n",
              "      <td>0.0463018</td>\n",
              "      <td>0.0360244</td>\n",
              "      <td>0.0180122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(5, 78, 79, 99)</td>\n",
              "      <td>[0.6721311475409836, 0.65, 0.6166666666666667,...</td>\n",
              "      <td>0.63776</td>\n",
              "      <td>(CO242.mean, RHIRGA84.std, RPAR.mean, CS.mean)</td>\n",
              "      <td>0.0332777</td>\n",
              "      <td>0.0258911</td>\n",
              "      <td>0.0129456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(5, 63, 78, 79, 99)</td>\n",
              "      <td>[0.6557377049180327, 0.6666666666666666, 0.683...</td>\n",
              "      <td>0.641148</td>\n",
              "      <td>(CO242.mean, PTG.mean, RHIRGA84.std, RPAR.mean...</td>\n",
              "      <td>0.0466457</td>\n",
              "      <td>0.036292</td>\n",
              "      <td>0.018146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(5, 19, 63, 78, 79, 99)</td>\n",
              "      <td>[0.6721311475409836, 0.7, 0.7, 0.6333333333333...</td>\n",
              "      <td>0.65776</td>\n",
              "      <td>(CO242.mean, H2O672.mean, PTG.mean, RHIRGA84.s...</td>\n",
              "      <td>0.0572235</td>\n",
              "      <td>0.0445218</td>\n",
              "      <td>0.0222609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(0, 5, 19, 63, 78, 79, 99)</td>\n",
              "      <td>[0.6721311475409836, 0.7, 0.7, 0.6333333333333...</td>\n",
              "      <td>0.65776</td>\n",
              "      <td>(partlybad, CO242.mean, H2O672.mean, PTG.mean,...</td>\n",
              "      <td>0.0572235</td>\n",
              "      <td>0.0445218</td>\n",
              "      <td>0.0222609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  feature_idx  ...    std_err\n",
              "1                       (78,)  ...  0.0235647\n",
              "2                    (78, 79)  ...  0.0126156\n",
              "3                (78, 79, 99)  ...  0.0180122\n",
              "4             (5, 78, 79, 99)  ...  0.0129456\n",
              "5         (5, 63, 78, 79, 99)  ...   0.018146\n",
              "6     (5, 19, 63, 78, 79, 99)  ...  0.0222609\n",
              "7  (0, 5, 19, 63, 78, 79, 99)  ...  0.0222609\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8z2JDac3ogj",
        "outputId": "ba25ee76-eae4-4638-c722-f6e481d3ac37"
      },
      "source": [
        "# Get Accuracy with Forward Selection\n",
        "feat_cols_NB_Forward = list(sfs1.k_feature_idx_)\n",
        "NB_Model  =   GaussianNB()\n",
        "GetAccuracies(NB_Model,feat_cols_NB_Forward)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy using RF with forward features selection: 0.6677740863787376 %\n",
            "Val Accuracy with forward features selection: 0.627906976744186 %\n",
            "Cross validation test scores:  [0.61627907 0.59302326 0.62790698 0.58139535 0.54651163]\n",
            "CV mean: 0.5930232558139534\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6677740863787376, 0.627906976744186, 0.5930232558139534]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfAIA9F9VAwq"
      },
      "source": [
        "#### Automated TPOT \n",
        "TPOT does the tuning for us, trying out different models and different hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650,
          "referenced_widgets": [
            "0dcce498317b4309a86bca2484b9f366",
            "1256fb41e5574fa5a8912e55f39cc3b4",
            "fd8af728e358495885827d5f45b9e494",
            "52f4766dcaa54e8c92c434d9b98c1dd8",
            "f5b8a5fa313b46e39fa51654019c12d6",
            "8e74bf8ecce247c0b7e8816ad07ee22d",
            "546744817c7247ec91c4d202155c6d29",
            "c1d91d24886843b4a7372132b6659b71"
          ]
        },
        "id": "-XKp05mpVAwq",
        "outputId": "4f9d016f-38d6-40b2-87ba-e48c19d5a7a5"
      },
      "source": [
        "!pip install tpot\n",
        "from tpot import TPOTClassifier\n",
        "tpot = TPOTClassifier(generations=3, population_size=3, verbosity=2, max_eval_time_mins=1)\n",
        "tpot.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tpot in /usr/local/lib/python3.6/dist-packages (0.11.6.post2)\n",
            "Requirement already satisfied: tqdm>=4.36.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (4.41.1)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.17.0)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.1.4)\n",
            "Requirement already satisfied: stopit>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.1.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.22.2.post1)\n",
            "Requirement already satisfied: update-checker>=0.16 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.18.0)\n",
            "Requirement already satisfied: deap>=1.2 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.3.1)\n",
            "Requirement already satisfied: xgboost>=0.90 in /usr/local/lib/python3.6/dist-packages (from tpot) (0.90)\n",
            "Requirement already satisfied: numpy>=1.16.3 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from tpot) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->tpot) (2018.9)\n",
            "Requirement already satisfied: requests>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from update-checker>=0.16->tpot) (2.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.2->tpot) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2020.11.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.10)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dcce498317b4309a86bca2484b9f366",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=12.0, style=ProgressStyle(desâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r\n",
            "Generation 1 - Current best internal CV score: 0.6610928961748634\n",
            "\n",
            "Generation 2 - Current best internal CV score: 0.6678688524590164\n",
            "\n",
            "Generation 3 - Current best internal CV score: 0.6743715846994535\n",
            "\n",
            "Best pipeline: RandomForestClassifier(ZeroCount(input_matrix), bootstrap=True, criterion=gini, max_features=0.9000000000000001, min_samples_leaf=5, min_samples_split=15, n_estimators=100)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TPOTClassifier(config_dict=None, crossover_rate=0.1, cv=5,\n",
              "               disable_update_check=False, early_stop=None, generations=3,\n",
              "               log_file=None, max_eval_time_mins=1, max_time_mins=None,\n",
              "               memory=None, mutation_rate=0.9, n_jobs=1, offspring_size=None,\n",
              "               periodic_checkpoint_folder=None, population_size=3,\n",
              "               random_state=None, scoring=None, subsample=1.0, template=None,\n",
              "               use_dask=False, verbosity=2, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "m56nQRUgVAws",
        "outputId": "0f84b84a-5fa0-4353-91f0-ba36a7e849b1"
      },
      "source": [
        "tpotPredictions = tpot.predict(X_val, y_val)\n",
        "Accuracy = sum(tpotPredictions == y_val) / len(y_val)\n",
        "print('Accuracy using tpot:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-155-713aea3f8eb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtpotPredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtpotPredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy using tpot:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: predict() takes 2 positional arguments but 3 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAjiRNjFVAws"
      },
      "source": [
        "### 6. Gradient boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkcPxHBjVAws",
        "outputId": "c4d146c9-9764-4ae2-fde4-ee505ed9bba8"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GBOOSTmodel = GradientBoostingClassifier(learning_rate=0.5, max_depth=5, max_features=0.3, min_samples_leaf=9, min_samples_split=12, n_estimators=100, subsample=1.0)\n",
        "GBOOSTmodel.fit(X_train,y_train)\n",
        "predicitionsGBOOST = GBOOSTmodel.predict(X_val)\n",
        "Accuracy = sum(predicitionsGBOOST == y_val) / len(y_val)\n",
        "print('Accuracy using GradientBoosting:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy using GradientBoosting: 0.689922480620155 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "DKpgHPP-VAwt",
        "outputId": "bef89ba7-4d2e-4995-d319-4f0263218f21"
      },
      "source": [
        "cv = cross_validate(GBOOSTmodel, X, y, cv=5)\n",
        "print(cv['test_score'])\n",
        "print('CV mean:', cv['test_score'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-45c2ae738b91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGBOOSTmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'CV mean:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'cross_validate' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQGMgRqbBqMd"
      },
      "source": [
        "#### Forward selection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP4pNX7yaKmT"
      },
      "source": [
        "from sklearn.metrics import accuracy_score as acc\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector as sfs\n",
        "\n",
        "# Build Kneighbours classifier to use in feature selection\n",
        "clf = GradientBoostingClassifier(learning_rate=0.1, max_depth=5, min_samples_leaf=9, min_samples_split=12, n_estimators=100, subsample=1.0)\n",
        "\n",
        "# Build step forward feature selection\n",
        "sfs1 = sfs(clf,\n",
        "           k_features = 7,\n",
        "           forward=True,\n",
        "           floating=False,\n",
        "           verbose=2,\n",
        "           scoring='accuracy',\n",
        "           cv=5)\n",
        "\n",
        "# Perform SFFS\n",
        "sfs1 = sfs1.fit(X_train, y_train)\n",
        "pd.DataFrame.from_dict(sfs1.get_metric_dict()).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo6eGr0MPW2E"
      },
      "source": [
        "Features : (1, 7, 17, 51, 68, 74, 96)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbrBsez8efO0"
      },
      "source": [
        "\n",
        "# Get Accuracy with Forward Selection\n",
        "feat_cols_GradBoost_Forward = list(sfs1.k_feature_idx_)\n",
        "GradBoost_Model  = GradientBoostingClassifier(learning_rate=0.5, max_depth=5, min_samples_leaf=9, min_samples_split=12, n_estimators=100, subsample=1.0)\n",
        "\n",
        "GetAccuracies(GradBoost_Model,feat_cols_GradBoost_Forward)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fyd7LslJr4o"
      },
      "source": [
        "### 7. Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEyDWBqUXGSJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "f0da8990-2a5d-4465-8f93-cb9ec4d27893"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "clf = make_pipeline(StandardScaler(),LinearSVC(random_state=0, tol=1e-5))\n",
        "clf.fit(X_train, y_train)\n",
        "predictions = rf.predict(X_val)# Calculate the absolute errors\n",
        "Accuracy = sum(predictions == y_val) / len(y_val)\n",
        "print('Accuracy using  Linear SVC:', Accuracy, '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning:\n",
            "\n",
            "Liblinear failed to converge, increase the number of iterations.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-d956f7b3e261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Calculate the absolute errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mAccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy using  Linear SVC:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'rf' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4iSSABM4-4"
      },
      "source": [
        "## Part 4: Predictions with the Gradient Boosting classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ric7X62DNgBJ"
      },
      "source": [
        "Because the gradient boosting classifier performed so well in the tests above, we decided to make our predictions using this model.  \n",
        "\n",
        "Binary classification accuracy: 0.91  \n",
        "Multiclass classification accuracy: 0.65  \n",
        "Multiclass classification with forward selection: 0.70  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPUj09r9OHHT"
      },
      "source": [
        "### Binary classification prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChgGuWzcPqeC"
      },
      "source": [
        "#### Abdallah"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzQCP-ewQ3Tj",
        "outputId": "907a6aab-b97d-4986-d970-8e933853fac1"
      },
      "source": [
        "colNames = X_train.iloc[:, [1, 7, 17, 51, 68, 74, 96]].columns\n",
        "df_test[colNames]\n",
        "predictions = GradBoost_Model.predict(df_test[colNames])# Calculate the absolute errors\n",
        "predictions[0:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['nonevent', 'Ia', 'nonevent', 'II', 'Ia', 'Ib', 'nonevent',\n",
              "       'nonevent', 'II', 'II'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0-WztfnR883",
        "outputId": "28a20496-50b2-43d0-c6c0-a35691099c46"
      },
      "source": [
        "df = pd.DataFrame({'Bin':predicitionsTEST, 'Multi':predictions})\n",
        "df[df.Bin == 'nonevent'][df.Multi != 'nonevent'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning:\n",
            "\n",
            "Boolean Series key will be reindexed to match DataFrame index.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "37AG7LzJPtjZ",
        "outputId": "9cd08bca-4ed0-4f8b-b96d-abeb3819fe0c"
      },
      "source": [
        "df_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>class4</th>\n",
              "      <th>partlybad</th>\n",
              "      <th>CO2168.mean</th>\n",
              "      <th>CO2168.std</th>\n",
              "      <th>CO2336.mean</th>\n",
              "      <th>CO2336.std</th>\n",
              "      <th>CO242.mean</th>\n",
              "      <th>CO242.std</th>\n",
              "      <th>CO2504.mean</th>\n",
              "      <th>CO2504.std</th>\n",
              "      <th>Glob.mean</th>\n",
              "      <th>Glob.std</th>\n",
              "      <th>H2O168.mean</th>\n",
              "      <th>H2O168.std</th>\n",
              "      <th>H2O336.mean</th>\n",
              "      <th>H2O336.std</th>\n",
              "      <th>H2O42.mean</th>\n",
              "      <th>H2O42.std</th>\n",
              "      <th>H2O504.mean</th>\n",
              "      <th>H2O504.std</th>\n",
              "      <th>H2O672.mean</th>\n",
              "      <th>H2O672.std</th>\n",
              "      <th>H2O84.mean</th>\n",
              "      <th>H2O84.std</th>\n",
              "      <th>NET.mean</th>\n",
              "      <th>NET.std</th>\n",
              "      <th>NO168.mean</th>\n",
              "      <th>NO168.std</th>\n",
              "      <th>NO336.mean</th>\n",
              "      <th>NO336.std</th>\n",
              "      <th>NO42.mean</th>\n",
              "      <th>NO42.std</th>\n",
              "      <th>NO504.mean</th>\n",
              "      <th>NO504.std</th>\n",
              "      <th>NO672.mean</th>\n",
              "      <th>NO672.std</th>\n",
              "      <th>NO84.mean</th>\n",
              "      <th>NO84.std</th>\n",
              "      <th>...</th>\n",
              "      <th>PAR.mean</th>\n",
              "      <th>PAR.std</th>\n",
              "      <th>PTG.mean</th>\n",
              "      <th>PTG.std</th>\n",
              "      <th>RGlob.mean</th>\n",
              "      <th>RGlob.std</th>\n",
              "      <th>RHIRGA168.mean</th>\n",
              "      <th>RHIRGA168.std</th>\n",
              "      <th>RHIRGA336.mean</th>\n",
              "      <th>RHIRGA336.std</th>\n",
              "      <th>RHIRGA42.mean</th>\n",
              "      <th>RHIRGA42.std</th>\n",
              "      <th>RHIRGA504.mean</th>\n",
              "      <th>RHIRGA504.std</th>\n",
              "      <th>RHIRGA672.mean</th>\n",
              "      <th>RHIRGA672.std</th>\n",
              "      <th>RHIRGA84.mean</th>\n",
              "      <th>RHIRGA84.std</th>\n",
              "      <th>RPAR.mean</th>\n",
              "      <th>RPAR.std</th>\n",
              "      <th>SO2168.mean</th>\n",
              "      <th>SO2168.std</th>\n",
              "      <th>SWS.mean</th>\n",
              "      <th>SWS.std</th>\n",
              "      <th>T168.mean</th>\n",
              "      <th>T168.std</th>\n",
              "      <th>T42.mean</th>\n",
              "      <th>T42.std</th>\n",
              "      <th>T504.mean</th>\n",
              "      <th>T504.std</th>\n",
              "      <th>T672.mean</th>\n",
              "      <th>T672.std</th>\n",
              "      <th>T84.mean</th>\n",
              "      <th>T84.std</th>\n",
              "      <th>UV_A.mean</th>\n",
              "      <th>UV_A.std</th>\n",
              "      <th>UV_B.mean</th>\n",
              "      <th>UV_B.std</th>\n",
              "      <th>CS.mean</th>\n",
              "      <th>CS.std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>431</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>377.448880</td>\n",
              "      <td>2.920241</td>\n",
              "      <td>377.632640</td>\n",
              "      <td>2.666835</td>\n",
              "      <td>377.908080</td>\n",
              "      <td>3.440430</td>\n",
              "      <td>377.708240</td>\n",
              "      <td>2.543418</td>\n",
              "      <td>210.851946</td>\n",
              "      <td>179.668211</td>\n",
              "      <td>13.516160</td>\n",
              "      <td>0.503071</td>\n",
              "      <td>13.448640</td>\n",
              "      <td>0.496249</td>\n",
              "      <td>13.674790</td>\n",
              "      <td>0.530696</td>\n",
              "      <td>13.394640</td>\n",
              "      <td>0.498479</td>\n",
              "      <td>13.363040</td>\n",
              "      <td>0.497949</td>\n",
              "      <td>13.594444</td>\n",
              "      <td>0.521267</td>\n",
              "      <td>150.196036</td>\n",
              "      <td>150.388580</td>\n",
              "      <td>0.027333</td>\n",
              "      <td>0.059314</td>\n",
              "      <td>0.025333</td>\n",
              "      <td>0.060505</td>\n",
              "      <td>0.013309</td>\n",
              "      <td>0.055271</td>\n",
              "      <td>0.026444</td>\n",
              "      <td>0.060477</td>\n",
              "      <td>0.031630</td>\n",
              "      <td>0.059778</td>\n",
              "      <td>0.012059</td>\n",
              "      <td>0.059952</td>\n",
              "      <td>...</td>\n",
              "      <td>462.288867</td>\n",
              "      <td>395.186100</td>\n",
              "      <td>-0.002204</td>\n",
              "      <td>0.004148</td>\n",
              "      <td>27.684027</td>\n",
              "      <td>24.408845</td>\n",
              "      <td>61.929200</td>\n",
              "      <td>8.972139</td>\n",
              "      <td>62.429200</td>\n",
              "      <td>9.055263</td>\n",
              "      <td>62.922101</td>\n",
              "      <td>9.302637</td>\n",
              "      <td>62.818960</td>\n",
              "      <td>9.081988</td>\n",
              "      <td>63.571440</td>\n",
              "      <td>9.160430</td>\n",
              "      <td>62.301746</td>\n",
              "      <td>9.121943</td>\n",
              "      <td>16.461909</td>\n",
              "      <td>14.679380</td>\n",
              "      <td>0.462741</td>\n",
              "      <td>0.196812</td>\n",
              "      <td>911.833333</td>\n",
              "      <td>24.361855</td>\n",
              "      <td>19.019520</td>\n",
              "      <td>2.306049</td>\n",
              "      <td>19.033461</td>\n",
              "      <td>2.316664</td>\n",
              "      <td>18.649187</td>\n",
              "      <td>2.278480</td>\n",
              "      <td>18.421232</td>\n",
              "      <td>2.267065</td>\n",
              "      <td>19.059027</td>\n",
              "      <td>2.320316</td>\n",
              "      <td>12.572064</td>\n",
              "      <td>9.623161</td>\n",
              "      <td>0.645959</td>\n",
              "      <td>0.558320</td>\n",
              "      <td>0.006159</td>\n",
              "      <td>0.000797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>369.589091</td>\n",
              "      <td>0.210402</td>\n",
              "      <td>369.632955</td>\n",
              "      <td>0.201409</td>\n",
              "      <td>369.904200</td>\n",
              "      <td>0.252167</td>\n",
              "      <td>369.601600</td>\n",
              "      <td>0.184727</td>\n",
              "      <td>25.017625</td>\n",
              "      <td>15.296680</td>\n",
              "      <td>4.339091</td>\n",
              "      <td>0.035360</td>\n",
              "      <td>4.307045</td>\n",
              "      <td>0.037203</td>\n",
              "      <td>4.376000</td>\n",
              "      <td>0.045535</td>\n",
              "      <td>4.299600</td>\n",
              "      <td>0.034639</td>\n",
              "      <td>4.290400</td>\n",
              "      <td>0.033317</td>\n",
              "      <td>4.334400</td>\n",
              "      <td>0.040816</td>\n",
              "      <td>2.613875</td>\n",
              "      <td>15.499577</td>\n",
              "      <td>0.003396</td>\n",
              "      <td>0.036052</td>\n",
              "      <td>0.016481</td>\n",
              "      <td>0.037121</td>\n",
              "      <td>0.012642</td>\n",
              "      <td>0.075706</td>\n",
              "      <td>0.008519</td>\n",
              "      <td>0.036879</td>\n",
              "      <td>0.018679</td>\n",
              "      <td>0.046162</td>\n",
              "      <td>0.006226</td>\n",
              "      <td>0.049077</td>\n",
              "      <td>...</td>\n",
              "      <td>46.884312</td>\n",
              "      <td>26.235043</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.799594</td>\n",
              "      <td>3.225846</td>\n",
              "      <td>67.663636</td>\n",
              "      <td>1.291898</td>\n",
              "      <td>68.085682</td>\n",
              "      <td>1.441290</td>\n",
              "      <td>68.073200</td>\n",
              "      <td>1.258270</td>\n",
              "      <td>68.340600</td>\n",
              "      <td>1.344173</td>\n",
              "      <td>69.213400</td>\n",
              "      <td>1.354032</td>\n",
              "      <td>67.448000</td>\n",
              "      <td>1.359301</td>\n",
              "      <td>3.155625</td>\n",
              "      <td>2.131279</td>\n",
              "      <td>0.026038</td>\n",
              "      <td>0.061530</td>\n",
              "      <td>922.333333</td>\n",
              "      <td>0.577350</td>\n",
              "      <td>0.462844</td>\n",
              "      <td>0.194671</td>\n",
              "      <td>0.480250</td>\n",
              "      <td>0.195631</td>\n",
              "      <td>0.178000</td>\n",
              "      <td>0.185177</td>\n",
              "      <td>-0.036312</td>\n",
              "      <td>0.180361</td>\n",
              "      <td>0.476219</td>\n",
              "      <td>0.192571</td>\n",
              "      <td>1.479447</td>\n",
              "      <td>0.640776</td>\n",
              "      <td>0.028665</td>\n",
              "      <td>0.013506</td>\n",
              "      <td>0.000361</td>\n",
              "      <td>0.000031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>433</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>380.338929</td>\n",
              "      <td>0.928028</td>\n",
              "      <td>380.315833</td>\n",
              "      <td>0.917636</td>\n",
              "      <td>380.550119</td>\n",
              "      <td>0.936683</td>\n",
              "      <td>380.301446</td>\n",
              "      <td>0.916970</td>\n",
              "      <td>8.283964</td>\n",
              "      <td>5.107894</td>\n",
              "      <td>6.543333</td>\n",
              "      <td>0.191992</td>\n",
              "      <td>6.497143</td>\n",
              "      <td>0.197768</td>\n",
              "      <td>6.629167</td>\n",
              "      <td>0.184255</td>\n",
              "      <td>6.479639</td>\n",
              "      <td>0.198681</td>\n",
              "      <td>6.528193</td>\n",
              "      <td>0.204993</td>\n",
              "      <td>6.592143</td>\n",
              "      <td>0.181520</td>\n",
              "      <td>11.419841</td>\n",
              "      <td>4.875628</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.026155</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.027060</td>\n",
              "      <td>0.013810</td>\n",
              "      <td>0.027061</td>\n",
              "      <td>0.011084</td>\n",
              "      <td>0.027542</td>\n",
              "      <td>0.006988</td>\n",
              "      <td>0.023098</td>\n",
              "      <td>0.011429</td>\n",
              "      <td>0.026304</td>\n",
              "      <td>...</td>\n",
              "      <td>18.128247</td>\n",
              "      <td>11.574338</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.065139</td>\n",
              "      <td>0.646427</td>\n",
              "      <td>92.853214</td>\n",
              "      <td>0.804013</td>\n",
              "      <td>93.415238</td>\n",
              "      <td>0.760399</td>\n",
              "      <td>93.546786</td>\n",
              "      <td>0.760492</td>\n",
              "      <td>93.668072</td>\n",
              "      <td>0.758113</td>\n",
              "      <td>95.544337</td>\n",
              "      <td>1.356642</td>\n",
              "      <td>93.334524</td>\n",
              "      <td>0.738239</td>\n",
              "      <td>0.028685</td>\n",
              "      <td>0.212517</td>\n",
              "      <td>0.112143</td>\n",
              "      <td>0.100697</td>\n",
              "      <td>770.735294</td>\n",
              "      <td>142.420698</td>\n",
              "      <td>1.705657</td>\n",
              "      <td>0.363461</td>\n",
              "      <td>1.790637</td>\n",
              "      <td>0.364509</td>\n",
              "      <td>1.453287</td>\n",
              "      <td>0.372461</td>\n",
              "      <td>1.284980</td>\n",
              "      <td>0.379219</td>\n",
              "      <td>1.737849</td>\n",
              "      <td>0.365878</td>\n",
              "      <td>0.720849</td>\n",
              "      <td>0.427279</td>\n",
              "      <td>0.015179</td>\n",
              "      <td>0.010471</td>\n",
              "      <td>0.002334</td>\n",
              "      <td>0.000347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>434</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>381.047644</td>\n",
              "      <td>1.290080</td>\n",
              "      <td>381.231149</td>\n",
              "      <td>1.245494</td>\n",
              "      <td>381.358678</td>\n",
              "      <td>1.817869</td>\n",
              "      <td>381.290057</td>\n",
              "      <td>1.228278</td>\n",
              "      <td>380.881093</td>\n",
              "      <td>280.914521</td>\n",
              "      <td>4.668851</td>\n",
              "      <td>0.491710</td>\n",
              "      <td>4.614138</td>\n",
              "      <td>0.502501</td>\n",
              "      <td>4.777586</td>\n",
              "      <td>0.471760</td>\n",
              "      <td>4.584253</td>\n",
              "      <td>0.504107</td>\n",
              "      <td>4.575402</td>\n",
              "      <td>0.506836</td>\n",
              "      <td>4.707803</td>\n",
              "      <td>0.477075</td>\n",
              "      <td>258.773200</td>\n",
              "      <td>255.404065</td>\n",
              "      <td>0.023046</td>\n",
              "      <td>0.055061</td>\n",
              "      <td>0.029080</td>\n",
              "      <td>0.057393</td>\n",
              "      <td>0.018161</td>\n",
              "      <td>0.044241</td>\n",
              "      <td>0.028678</td>\n",
              "      <td>0.057390</td>\n",
              "      <td>0.030805</td>\n",
              "      <td>0.104026</td>\n",
              "      <td>0.015145</td>\n",
              "      <td>0.046887</td>\n",
              "      <td>...</td>\n",
              "      <td>737.638006</td>\n",
              "      <td>552.083805</td>\n",
              "      <td>-0.004765</td>\n",
              "      <td>0.011049</td>\n",
              "      <td>44.519942</td>\n",
              "      <td>29.039158</td>\n",
              "      <td>37.320172</td>\n",
              "      <td>14.072622</td>\n",
              "      <td>37.765230</td>\n",
              "      <td>14.381162</td>\n",
              "      <td>38.171149</td>\n",
              "      <td>14.546789</td>\n",
              "      <td>37.941034</td>\n",
              "      <td>14.479086</td>\n",
              "      <td>38.472069</td>\n",
              "      <td>14.667392</td>\n",
              "      <td>37.383699</td>\n",
              "      <td>14.093502</td>\n",
              "      <td>25.116117</td>\n",
              "      <td>18.469726</td>\n",
              "      <td>0.082414</td>\n",
              "      <td>0.091126</td>\n",
              "      <td>921.094919</td>\n",
              "      <td>0.777319</td>\n",
              "      <td>11.050729</td>\n",
              "      <td>3.357004</td>\n",
              "      <td>11.124573</td>\n",
              "      <td>3.594004</td>\n",
              "      <td>10.553749</td>\n",
              "      <td>3.306069</td>\n",
              "      <td>10.298284</td>\n",
              "      <td>3.281097</td>\n",
              "      <td>11.148552</td>\n",
              "      <td>3.478676</td>\n",
              "      <td>19.568691</td>\n",
              "      <td>14.480491</td>\n",
              "      <td>0.783038</td>\n",
              "      <td>0.703191</td>\n",
              "      <td>0.001868</td>\n",
              "      <td>0.000594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>435</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>371.620857</td>\n",
              "      <td>8.552564</td>\n",
              "      <td>371.245461</td>\n",
              "      <td>7.605137</td>\n",
              "      <td>373.101151</td>\n",
              "      <td>10.027695</td>\n",
              "      <td>370.722624</td>\n",
              "      <td>6.804409</td>\n",
              "      <td>130.514702</td>\n",
              "      <td>79.959508</td>\n",
              "      <td>8.012000</td>\n",
              "      <td>0.288332</td>\n",
              "      <td>7.910426</td>\n",
              "      <td>0.297674</td>\n",
              "      <td>8.253669</td>\n",
              "      <td>0.292860</td>\n",
              "      <td>7.840709</td>\n",
              "      <td>0.312222</td>\n",
              "      <td>7.800922</td>\n",
              "      <td>0.334021</td>\n",
              "      <td>8.121571</td>\n",
              "      <td>0.305228</td>\n",
              "      <td>76.969244</td>\n",
              "      <td>76.217402</td>\n",
              "      <td>0.245857</td>\n",
              "      <td>0.226719</td>\n",
              "      <td>0.245035</td>\n",
              "      <td>0.231694</td>\n",
              "      <td>0.176403</td>\n",
              "      <td>0.180611</td>\n",
              "      <td>0.233617</td>\n",
              "      <td>0.240188</td>\n",
              "      <td>0.229007</td>\n",
              "      <td>0.235100</td>\n",
              "      <td>0.229714</td>\n",
              "      <td>0.225299</td>\n",
              "      <td>...</td>\n",
              "      <td>245.163722</td>\n",
              "      <td>148.015357</td>\n",
              "      <td>0.004779</td>\n",
              "      <td>0.014287</td>\n",
              "      <td>16.476847</td>\n",
              "      <td>9.827836</td>\n",
              "      <td>72.190000</td>\n",
              "      <td>7.093067</td>\n",
              "      <td>71.302553</td>\n",
              "      <td>6.441438</td>\n",
              "      <td>73.911151</td>\n",
              "      <td>8.208471</td>\n",
              "      <td>70.836738</td>\n",
              "      <td>5.686469</td>\n",
              "      <td>71.447518</td>\n",
              "      <td>5.128026</td>\n",
              "      <td>72.549786</td>\n",
              "      <td>7.327851</td>\n",
              "      <td>8.901041</td>\n",
              "      <td>5.641202</td>\n",
              "      <td>0.341500</td>\n",
              "      <td>0.294371</td>\n",
              "      <td>919.106383</td>\n",
              "      <td>7.904963</td>\n",
              "      <td>8.672297</td>\n",
              "      <td>1.846648</td>\n",
              "      <td>8.744422</td>\n",
              "      <td>1.998833</td>\n",
              "      <td>8.609743</td>\n",
              "      <td>1.630543</td>\n",
              "      <td>8.398302</td>\n",
              "      <td>1.479949</td>\n",
              "      <td>8.798417</td>\n",
              "      <td>1.900331</td>\n",
              "      <td>7.591540</td>\n",
              "      <td>4.579817</td>\n",
              "      <td>0.319340</td>\n",
              "      <td>0.247098</td>\n",
              "      <td>0.002649</td>\n",
              "      <td>0.000701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>960</th>\n",
              "      <td>1391</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>364.421203</td>\n",
              "      <td>3.304977</td>\n",
              "      <td>365.024254</td>\n",
              "      <td>3.207384</td>\n",
              "      <td>365.610602</td>\n",
              "      <td>4.414990</td>\n",
              "      <td>365.129179</td>\n",
              "      <td>3.108141</td>\n",
              "      <td>283.362372</td>\n",
              "      <td>177.050893</td>\n",
              "      <td>7.268195</td>\n",
              "      <td>0.445958</td>\n",
              "      <td>7.132687</td>\n",
              "      <td>0.462166</td>\n",
              "      <td>7.442481</td>\n",
              "      <td>0.543690</td>\n",
              "      <td>7.069403</td>\n",
              "      <td>0.438447</td>\n",
              "      <td>7.007537</td>\n",
              "      <td>0.419759</td>\n",
              "      <td>7.436090</td>\n",
              "      <td>0.472966</td>\n",
              "      <td>173.727375</td>\n",
              "      <td>158.361215</td>\n",
              "      <td>0.057895</td>\n",
              "      <td>0.082756</td>\n",
              "      <td>0.062239</td>\n",
              "      <td>0.076823</td>\n",
              "      <td>0.037045</td>\n",
              "      <td>0.050520</td>\n",
              "      <td>0.052985</td>\n",
              "      <td>0.077256</td>\n",
              "      <td>0.062985</td>\n",
              "      <td>0.085805</td>\n",
              "      <td>0.042331</td>\n",
              "      <td>0.069292</td>\n",
              "      <td>...</td>\n",
              "      <td>541.188177</td>\n",
              "      <td>343.313703</td>\n",
              "      <td>0.001925</td>\n",
              "      <td>0.013370</td>\n",
              "      <td>40.219563</td>\n",
              "      <td>21.383539</td>\n",
              "      <td>59.285865</td>\n",
              "      <td>10.156638</td>\n",
              "      <td>58.833881</td>\n",
              "      <td>9.480599</td>\n",
              "      <td>62.634812</td>\n",
              "      <td>14.210094</td>\n",
              "      <td>58.586940</td>\n",
              "      <td>8.857457</td>\n",
              "      <td>58.479627</td>\n",
              "      <td>8.295433</td>\n",
              "      <td>61.738722</td>\n",
              "      <td>13.380511</td>\n",
              "      <td>21.475006</td>\n",
              "      <td>12.974913</td>\n",
              "      <td>0.102481</td>\n",
              "      <td>0.080344</td>\n",
              "      <td>922.264151</td>\n",
              "      <td>0.445099</td>\n",
              "      <td>10.165556</td>\n",
              "      <td>2.024125</td>\n",
              "      <td>9.830387</td>\n",
              "      <td>3.007462</td>\n",
              "      <td>9.882834</td>\n",
              "      <td>1.880273</td>\n",
              "      <td>9.758613</td>\n",
              "      <td>1.791942</td>\n",
              "      <td>10.027765</td>\n",
              "      <td>2.612431</td>\n",
              "      <td>13.790441</td>\n",
              "      <td>8.748891</td>\n",
              "      <td>0.578576</td>\n",
              "      <td>0.453514</td>\n",
              "      <td>0.002154</td>\n",
              "      <td>0.000541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>961</th>\n",
              "      <td>1392</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>363.722787</td>\n",
              "      <td>5.818945</td>\n",
              "      <td>363.644809</td>\n",
              "      <td>5.421855</td>\n",
              "      <td>364.529615</td>\n",
              "      <td>5.998013</td>\n",
              "      <td>363.332363</td>\n",
              "      <td>4.622540</td>\n",
              "      <td>264.393114</td>\n",
              "      <td>212.908024</td>\n",
              "      <td>10.067268</td>\n",
              "      <td>1.907993</td>\n",
              "      <td>9.952295</td>\n",
              "      <td>1.911232</td>\n",
              "      <td>10.174341</td>\n",
              "      <td>1.921897</td>\n",
              "      <td>9.913626</td>\n",
              "      <td>1.924354</td>\n",
              "      <td>9.870385</td>\n",
              "      <td>1.924666</td>\n",
              "      <td>10.157978</td>\n",
              "      <td>1.942537</td>\n",
              "      <td>162.846249</td>\n",
              "      <td>184.288207</td>\n",
              "      <td>0.053880</td>\n",
              "      <td>0.097782</td>\n",
              "      <td>0.060383</td>\n",
              "      <td>0.078323</td>\n",
              "      <td>0.043681</td>\n",
              "      <td>0.066964</td>\n",
              "      <td>0.055604</td>\n",
              "      <td>0.087988</td>\n",
              "      <td>0.056868</td>\n",
              "      <td>0.083769</td>\n",
              "      <td>0.035519</td>\n",
              "      <td>0.073684</td>\n",
              "      <td>...</td>\n",
              "      <td>528.430356</td>\n",
              "      <td>429.081634</td>\n",
              "      <td>-0.001324</td>\n",
              "      <td>0.015493</td>\n",
              "      <td>33.969123</td>\n",
              "      <td>26.267446</td>\n",
              "      <td>64.050383</td>\n",
              "      <td>16.102945</td>\n",
              "      <td>64.208415</td>\n",
              "      <td>15.651493</td>\n",
              "      <td>64.674945</td>\n",
              "      <td>17.319626</td>\n",
              "      <td>64.278077</td>\n",
              "      <td>15.533502</td>\n",
              "      <td>64.797473</td>\n",
              "      <td>15.545398</td>\n",
              "      <td>64.464918</td>\n",
              "      <td>17.336019</td>\n",
              "      <td>17.682164</td>\n",
              "      <td>14.560968</td>\n",
              "      <td>0.058743</td>\n",
              "      <td>0.098008</td>\n",
              "      <td>907.369863</td>\n",
              "      <td>40.419848</td>\n",
              "      <td>14.027169</td>\n",
              "      <td>2.123606</td>\n",
              "      <td>14.128338</td>\n",
              "      <td>2.617287</td>\n",
              "      <td>13.661196</td>\n",
              "      <td>1.732995</td>\n",
              "      <td>13.460119</td>\n",
              "      <td>1.602013</td>\n",
              "      <td>14.151279</td>\n",
              "      <td>2.442529</td>\n",
              "      <td>15.466702</td>\n",
              "      <td>12.041102</td>\n",
              "      <td>0.674690</td>\n",
              "      <td>0.621847</td>\n",
              "      <td>0.003541</td>\n",
              "      <td>0.000983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>1393</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>393.455333</td>\n",
              "      <td>0.302987</td>\n",
              "      <td>393.546800</td>\n",
              "      <td>0.269284</td>\n",
              "      <td>393.167200</td>\n",
              "      <td>0.349871</td>\n",
              "      <td>393.569867</td>\n",
              "      <td>0.241787</td>\n",
              "      <td>37.890000</td>\n",
              "      <td>32.840078</td>\n",
              "      <td>3.938400</td>\n",
              "      <td>0.108466</td>\n",
              "      <td>3.929333</td>\n",
              "      <td>0.109017</td>\n",
              "      <td>3.987200</td>\n",
              "      <td>0.116359</td>\n",
              "      <td>3.920000</td>\n",
              "      <td>0.113756</td>\n",
              "      <td>3.903158</td>\n",
              "      <td>0.108655</td>\n",
              "      <td>3.953600</td>\n",
              "      <td>0.110706</td>\n",
              "      <td>18.146618</td>\n",
              "      <td>21.357279</td>\n",
              "      <td>0.034000</td>\n",
              "      <td>0.059632</td>\n",
              "      <td>0.030375</td>\n",
              "      <td>0.075598</td>\n",
              "      <td>0.016543</td>\n",
              "      <td>0.052516</td>\n",
              "      <td>0.030250</td>\n",
              "      <td>0.053980</td>\n",
              "      <td>0.034198</td>\n",
              "      <td>0.062727</td>\n",
              "      <td>0.020125</td>\n",
              "      <td>0.054645</td>\n",
              "      <td>...</td>\n",
              "      <td>79.935809</td>\n",
              "      <td>66.561472</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.362033</td>\n",
              "      <td>4.790831</td>\n",
              "      <td>71.794533</td>\n",
              "      <td>2.423855</td>\n",
              "      <td>72.896000</td>\n",
              "      <td>2.422644</td>\n",
              "      <td>72.103200</td>\n",
              "      <td>2.487154</td>\n",
              "      <td>73.353867</td>\n",
              "      <td>2.504992</td>\n",
              "      <td>74.495921</td>\n",
              "      <td>2.468291</td>\n",
              "      <td>71.648933</td>\n",
              "      <td>2.455264</td>\n",
              "      <td>2.552386</td>\n",
              "      <td>2.704267</td>\n",
              "      <td>0.105500</td>\n",
              "      <td>0.070278</td>\n",
              "      <td>903.062500</td>\n",
              "      <td>0.877588</td>\n",
              "      <td>-1.520705</td>\n",
              "      <td>0.293127</td>\n",
              "      <td>-1.402075</td>\n",
              "      <td>0.286401</td>\n",
              "      <td>-1.884959</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-2.141411</td>\n",
              "      <td>0.279000</td>\n",
              "      <td>-1.439793</td>\n",
              "      <td>0.292972</td>\n",
              "      <td>2.817411</td>\n",
              "      <td>1.925849</td>\n",
              "      <td>0.081280</td>\n",
              "      <td>0.060592</td>\n",
              "      <td>0.002573</td>\n",
              "      <td>0.000181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>963</th>\n",
              "      <td>1394</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>399.839114</td>\n",
              "      <td>1.041056</td>\n",
              "      <td>399.891266</td>\n",
              "      <td>1.053666</td>\n",
              "      <td>399.902564</td>\n",
              "      <td>1.003625</td>\n",
              "      <td>399.874177</td>\n",
              "      <td>1.066815</td>\n",
              "      <td>90.880496</td>\n",
              "      <td>65.676063</td>\n",
              "      <td>3.047595</td>\n",
              "      <td>0.211109</td>\n",
              "      <td>3.031392</td>\n",
              "      <td>0.206458</td>\n",
              "      <td>3.247051</td>\n",
              "      <td>0.207547</td>\n",
              "      <td>3.014430</td>\n",
              "      <td>0.206849</td>\n",
              "      <td>3.011392</td>\n",
              "      <td>0.216444</td>\n",
              "      <td>3.071139</td>\n",
              "      <td>0.205501</td>\n",
              "      <td>62.486716</td>\n",
              "      <td>108.680115</td>\n",
              "      <td>0.208214</td>\n",
              "      <td>0.212258</td>\n",
              "      <td>0.216190</td>\n",
              "      <td>0.241471</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.234299</td>\n",
              "      <td>0.194167</td>\n",
              "      <td>0.215749</td>\n",
              "      <td>0.178929</td>\n",
              "      <td>0.175465</td>\n",
              "      <td>0.195595</td>\n",
              "      <td>0.229191</td>\n",
              "      <td>...</td>\n",
              "      <td>183.751032</td>\n",
              "      <td>131.599798</td>\n",
              "      <td>-0.000694</td>\n",
              "      <td>0.002696</td>\n",
              "      <td>21.254861</td>\n",
              "      <td>14.360352</td>\n",
              "      <td>66.392911</td>\n",
              "      <td>8.066433</td>\n",
              "      <td>67.210633</td>\n",
              "      <td>8.222117</td>\n",
              "      <td>70.428590</td>\n",
              "      <td>7.663879</td>\n",
              "      <td>67.414810</td>\n",
              "      <td>8.389609</td>\n",
              "      <td>68.743165</td>\n",
              "      <td>8.772446</td>\n",
              "      <td>66.781899</td>\n",
              "      <td>7.673590</td>\n",
              "      <td>13.527276</td>\n",
              "      <td>9.465847</td>\n",
              "      <td>0.265357</td>\n",
              "      <td>0.117529</td>\n",
              "      <td>913.411765</td>\n",
              "      <td>1.458884</td>\n",
              "      <td>-4.146250</td>\n",
              "      <td>0.753259</td>\n",
              "      <td>-4.099385</td>\n",
              "      <td>0.671492</td>\n",
              "      <td>-4.492837</td>\n",
              "      <td>0.784467</td>\n",
              "      <td>-4.762440</td>\n",
              "      <td>0.786920</td>\n",
              "      <td>-4.118829</td>\n",
              "      <td>0.703377</td>\n",
              "      <td>5.073407</td>\n",
              "      <td>3.041730</td>\n",
              "      <td>0.094426</td>\n",
              "      <td>0.062122</td>\n",
              "      <td>0.001528</td>\n",
              "      <td>0.000230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>1395</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>False</td>\n",
              "      <td>389.879062</td>\n",
              "      <td>1.527755</td>\n",
              "      <td>389.982062</td>\n",
              "      <td>1.508768</td>\n",
              "      <td>389.834526</td>\n",
              "      <td>1.458823</td>\n",
              "      <td>390.080309</td>\n",
              "      <td>1.496588</td>\n",
              "      <td>41.936860</td>\n",
              "      <td>28.661904</td>\n",
              "      <td>6.265729</td>\n",
              "      <td>0.352007</td>\n",
              "      <td>6.255155</td>\n",
              "      <td>0.341660</td>\n",
              "      <td>6.380526</td>\n",
              "      <td>0.402858</td>\n",
              "      <td>6.250928</td>\n",
              "      <td>0.342950</td>\n",
              "      <td>6.250309</td>\n",
              "      <td>0.329575</td>\n",
              "      <td>6.343196</td>\n",
              "      <td>0.395813</td>\n",
              "      <td>36.423025</td>\n",
              "      <td>26.426058</td>\n",
              "      <td>0.289700</td>\n",
              "      <td>0.208339</td>\n",
              "      <td>0.320198</td>\n",
              "      <td>0.227974</td>\n",
              "      <td>0.187327</td>\n",
              "      <td>0.134387</td>\n",
              "      <td>0.332277</td>\n",
              "      <td>0.225517</td>\n",
              "      <td>0.329307</td>\n",
              "      <td>0.244627</td>\n",
              "      <td>0.244653</td>\n",
              "      <td>0.188773</td>\n",
              "      <td>...</td>\n",
              "      <td>92.412165</td>\n",
              "      <td>60.804078</td>\n",
              "      <td>0.003223</td>\n",
              "      <td>0.004677</td>\n",
              "      <td>10.767041</td>\n",
              "      <td>7.053971</td>\n",
              "      <td>93.462708</td>\n",
              "      <td>0.719061</td>\n",
              "      <td>94.457938</td>\n",
              "      <td>0.783127</td>\n",
              "      <td>95.324211</td>\n",
              "      <td>0.904538</td>\n",
              "      <td>94.489897</td>\n",
              "      <td>0.694401</td>\n",
              "      <td>95.556701</td>\n",
              "      <td>1.312070</td>\n",
              "      <td>94.583608</td>\n",
              "      <td>0.761437</td>\n",
              "      <td>15.453471</td>\n",
              "      <td>10.544803</td>\n",
              "      <td>0.082400</td>\n",
              "      <td>0.084652</td>\n",
              "      <td>874.625000</td>\n",
              "      <td>87.651901</td>\n",
              "      <td>0.679868</td>\n",
              "      <td>0.835910</td>\n",
              "      <td>0.664479</td>\n",
              "      <td>0.799483</td>\n",
              "      <td>0.505438</td>\n",
              "      <td>0.820787</td>\n",
              "      <td>0.358347</td>\n",
              "      <td>0.807392</td>\n",
              "      <td>0.688876</td>\n",
              "      <td>0.838297</td>\n",
              "      <td>3.388481</td>\n",
              "      <td>2.056792</td>\n",
              "      <td>0.099177</td>\n",
              "      <td>0.071050</td>\n",
              "      <td>0.001565</td>\n",
              "      <td>0.000487</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>965 rows Ã— 104 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  date  class4  partlybad  ...  UV_B.mean  UV_B.std   CS.mean    CS.std\n",
              "0     431   NaN     NaN      False  ...   0.645959  0.558320  0.006159  0.000797\n",
              "1     432   NaN     NaN      False  ...   0.028665  0.013506  0.000361  0.000031\n",
              "2     433   NaN     NaN      False  ...   0.015179  0.010471  0.002334  0.000347\n",
              "3     434   NaN     NaN      False  ...   0.783038  0.703191  0.001868  0.000594\n",
              "4     435   NaN     NaN      False  ...   0.319340  0.247098  0.002649  0.000701\n",
              "..    ...   ...     ...        ...  ...        ...       ...       ...       ...\n",
              "960  1391   NaN     NaN      False  ...   0.578576  0.453514  0.002154  0.000541\n",
              "961  1392   NaN     NaN      False  ...   0.674690  0.621847  0.003541  0.000983\n",
              "962  1393   NaN     NaN      False  ...   0.081280  0.060592  0.002573  0.000181\n",
              "963  1394   NaN     NaN      False  ...   0.094426  0.062122  0.001528  0.000230\n",
              "964  1395   NaN     NaN      False  ...   0.099177  0.071050  0.001565  0.000487\n",
              "\n",
              "[965 rows x 104 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "Q3NBKPkTQN4j",
        "outputId": "11e9f137-0e3b-4e56-ada3-f083d00142a0"
      },
      "source": [
        "\n",
        "predictions = GradBoost_Model.predict(df_test)# Calculate the absolute errors"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-169-0d9b2162ab0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradBoost_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# Calculate the absolute errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2164\u001b[0m         \"\"\"\n\u001b[0;32m-> 2165\u001b[0;31m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2166\u001b[0m         \u001b[0mencoded_labels\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2167\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_prediction_to_decision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   2118\u001b[0m             \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m         \"\"\"\n\u001b[0;32m-> 2120\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2121\u001b[0m         \u001b[0mraw_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 578\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1_MnAiNPuNS"
      },
      "source": [
        "##################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "gbmn9moQSLap",
        "outputId": "f407eac9-78e9-4c57-907e-2a65223a82e5"
      },
      "source": [
        "#train binary model \n",
        "model = GradBoost_Model\n",
        "model.fit(X_train, y_val[\"class2\"])\n",
        "\n",
        "#make prediction \n",
        "bi_test_prob = pd.DataFrame(model.predict_proba(X_val))\n",
        "bi_test_cl = pd.DataFrame(model.predict(X_val))\n",
        "bi_test_pred = pd.merge(bi_test_cl, bi_test_prob, left_index=True, right_index=True)\n",
        "bi_y = y_val.copy()\n",
        "bi_test_pred.columns = [\"predicted_class\", \"actual_class\", \"p(event)\", \"p(nonevent)\"]\n",
        "numcorrect = bi_test_pred[bi_test_pred[\"predicted_class\"] == bi_test_pred[\"actual_class\"]].shape[0]\n",
        "print(bi_test_pred)\n",
        "print(\"Predicted accuracy:\", accuracy_score(y_val[\"class2\"], model.predict(X_val)))\n",
        "print(\"Actual accuracy:\", numcorrect/y_val.shape[0])\n",
        "\n",
        "#write to csv \n",
        "bi_predict = pd.DataFrame()\n",
        "bi_predict.to_csv(\"bi_predict.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class2'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-34048205f1aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train binary model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"class2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#make prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class2'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgcB9HhVOJK5"
      },
      "source": [
        "### Multiclass classification prediction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWplEgtNSMUV"
      },
      "source": [
        "#train multiclass model \n",
        "model = GradBoost_Model\n",
        "model.fit(X_train, y_val[\"class2\"])\n",
        "\n",
        "#make prediction \n",
        "mu_test_prob = pd.DataFrame(model.predict_proba(X_val))\n",
        "mu_test_cl = pd.DataFrame(model.predict(X_val))\n",
        "mu_test_pred = pd.merge(mu_test_cl, mu_test_prob, left_index=True, right_index=True)\n",
        "mu_y = y_val.copy()\n",
        "mu-y = mu_y.reset_index()\n",
        "mu_test_pred.columns = [\"predicted_class\", \"actual_class\", \"p(event)\", \"p(nonevent)\"]\n",
        "numcorrect = mu_test_pred[mu_test_pred[\"predicted_class\"] == mu_test_pred[\"actual_class\"]].shape[0]\n",
        "print(mu_test_pred)\n",
        "print(\"Predicted accuracy:\", accuracy_score(y_val[\"class2\"], model.predict(X_val)))\n",
        "print(\"Actual accuracy:\", numcorrect/y_val.shape[0])\n",
        "\n",
        "#write to csv \n",
        "mu_predict = pd.DataFrame()\n",
        "mu_predict.to_csv(\"mu_predict.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rvxt-QI_7DlN"
      },
      "source": [
        "## Part 5: Overview and Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQNVaIoT6TpK"
      },
      "source": [
        "### Overview of our approach  \n",
        "To build the best classifier for the given dataset, first we had to determine the appropriate learning method to evaluate this specific set of values. We chose supervised learning methods to evaluate. The dataset was split into training and validation sets and run through each of the classifiers twice to obtain their accuracies. The first set of runs used the class2 column to predict events as events or nonevents. The second set used the class4 column. Then we investigated the results of both sets of classifiers and chose the highest performing classifier to make predictions on. After evaluating our predictions, we made conclusions on what we saw.    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1nQ-ud8vzhT-"
      },
      "source": [
        "### Classification algorithms chosen  \n",
        "We chose six supervised learning models to test. Five of the models were those talked about in class, and one was a new model. The methods chosen to explore were the random forest model, SVM, 3 nearest neighbor, logistic regerssion, Naive Bayes, and gradient boosting. These 6 classifiers were run twice: once to classify events as \"event\" or \"nonevent,\" and then to predict each event as one of the four types from the original dataset. After testing the algorithms, we chose gradient boosting to make our predictions on.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M99SgXQ0zcZ9"
      },
      "source": [
        "### Steps to select good features and model parameters  \n",
        "To select the best model parameters, we implemented a Python library that performs automatic machine learning called TPOT. Using a global search proceedure, it can efficiently find the best performing pipeline for the given dataset. In other words, it can do the model tuning for us. TPOT prepares the data and uses a tree-based structure to represent a pipeline including the model parameters. It performs an optimization proceedure to find a tree structure that best performs. The output of TPOT can be implemented in the project script to bypass trial and error of selecting good model features.  \n",
        "\n",
        "Half of the original dataset is nonevents, therefore a large portion of the test data is nonevents. Because of this, the variance of nonevents differs from other predictors and has the possibility to overshadow other predictors and influence the outcome of a run more effectively. Scaling (normalizing) the data removes this detriment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuIWP2vAzaXY"
      },
      "source": [
        "### Summary of results  \n",
        "The accuracies of all of the classifiers for both class2 and class4 are presented in the table below.  \n",
        "\n",
        "**class2**  \n",
        "The classification algorithm with the lowest error is gradient boosting with accuracy of 0.91. The algorithm with the highest error is SVM with accuracy 0.7364. \n",
        "\n",
        "**class4**  \n",
        "\n",
        "**class4 with forward selection**   \n",
        "Feature selection gave worst accuracy in Kneighbours case. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wTo9S3r2_A5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0453819-1cb5-4361-c959-fff0ba04e921"
      },
      "source": [
        "x = PrettyTable()\n",
        "x.field_names = [\"Classifier\", \"Class2 Accuracy\", \"Class4 Accuracy\", \"Class4 Accuracy w/ Forward Selection\"]\n",
        "x.add_row([\"Random forest\", 0.8837, 0.6434, \"-\"])\n",
        "x.add_row([\"SVM\", 0.7364, 0.5581, 0.6279])\n",
        "x.add_row([\"3-NN\", 0.8837, 0.6434, 0.6202])\n",
        "x.add_row([\"Logistic regression\", 0.8682, 0.6434, \"-\"])\n",
        "x.add_row([\"Naive Bayes\", 0.7597, 0.4806, 0.5194])\n",
        "x.add_row([\"Gradient boosting\", 0.9147, 0.6667, 0.6124])\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---------------------+-----------------+-----------------+--------------------------------------+\n",
            "|      Classifier     | Class2 Accuracy | Class4 Accuracy | Class4 Accuracy w/ Forward Selection |\n",
            "+---------------------+-----------------+-----------------+--------------------------------------+\n",
            "|    Random forest    |      0.8837     |      0.6434     |                  -                   |\n",
            "|         SVM         |      0.7364     |      0.5581     |                0.6279                |\n",
            "|         3-NN        |      0.8837     |      0.6434     |                0.6202                |\n",
            "| Logistic regression |      0.8682     |      0.6434     |                  -                   |\n",
            "|     Naive Bayes     |      0.7597     |      0.4806     |                0.5194                |\n",
            "|  Gradient boosting  |      0.9147     |      0.6667     |                0.6124                |\n",
            "+---------------------+-----------------+-----------------+--------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKS5QYBxzMfq"
      },
      "source": [
        "### Insights  \n",
        "One thing we noticed about the results was that the discriminative models performed significantly better than the generative model. SVM is not really generative or discriminative, and it resulted in an accuracy of 0.7364 on class2, 0.5581 on class4, and 0.6279 with forward selection. For class2: the generative model Naive Bayes, had a low accuracy around that of SVM. For class4 with and without forward selection, SVM's accuracy was even worse. The discriminative models all performed with accuracies in the high 0.80s and low 0.90s for class2 and in the 0.60s for class4. This makes sense because discriminative models are conditional models that are used for regression and classification. The problem to solve for this project was to predict the classification of event type, in which we had to distinguish decision boundaries. Discriminative models are more useful for this task. For class4 this remained true. \n",
        "\n",
        "We also see that supervised learning was the better choice to make instead of unsupervised learning methods. We chose to investigate supervised learning methods because we want to find specific relationships and structure in the input data instead of doing a more general analysis. Supervised learning methods are equiped to handle labeled data like our dataset, whereas unsupervised methods produce unlabeled data that the algorithm tries to make sense of. Supervised learning works here because we are able to train the model on data that is already providing the \"answer\" of its classification. Most of the models selected provided high accuracies that would be practical in the analysis of the dataset.  \n",
        "\n",
        "There can be a significant difference in the output of a classifier depending on if the data has been normalized or not. When normalized, the data resides in the same range. Unnormalized data can lead to one larger predictor overshadowing others.   \n",
        "\n",
        "pca  "
      ]
    }
  ]
}